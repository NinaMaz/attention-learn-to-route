{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1995cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliceperse/miniconda3/envs/attention/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from run import run\n",
    "from options import get_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbe1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \"--graph_size 20 --baseline rollout --run_name 'tsp20_rollout' --no_tensorboard\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cef02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = get_options(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df9546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(problem='tsp', graph_size=20, batch_size=512, epoch_size=1280000, val_size=10000, val_dataset=None, model='attention', embedding_dim=128, hidden_dim=128, n_encode_layers=3, tanh_clipping=10.0, normalization='batch', lr_model=0.0001, lr_critic=0.0001, lr_decay=1.0, eval_only=False, n_epochs=100, seed=1234, max_grad_norm=1.0, no_cuda=False, exp_beta=0.8, baseline='rollout', bl_alpha=0.05, bl_warmup_epochs=1, eval_batch_size=1024, checkpoint_encoder=False, shrink_size=None, data_distribution=None, log_step=50, log_dir='logs', run_name=\"'tsp20_rollout'_20220830T234830\", output_dir='outputs', epoch_start=0, checkpoint_epochs=1, load_path=None, resume=None, no_tensorboard=True, no_progress_bar=False, use_cuda=False, save_dir=\"outputs/tsp_20/'tsp20_rollout'_20220830T234830\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91bbe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline': 'rollout',\n",
      " 'batch_size': 512,\n",
      " 'bl_alpha': 0.05,\n",
      " 'bl_warmup_epochs': 1,\n",
      " 'checkpoint_encoder': False,\n",
      " 'checkpoint_epochs': 1,\n",
      " 'data_distribution': None,\n",
      " 'embedding_dim': 128,\n",
      " 'epoch_size': 1280000,\n",
      " 'epoch_start': 0,\n",
      " 'eval_batch_size': 1024,\n",
      " 'eval_only': False,\n",
      " 'exp_beta': 0.8,\n",
      " 'graph_size': 20,\n",
      " 'hidden_dim': 128,\n",
      " 'load_path': None,\n",
      " 'log_dir': 'logs',\n",
      " 'log_step': 50,\n",
      " 'lr_critic': 0.0001,\n",
      " 'lr_decay': 1.0,\n",
      " 'lr_model': 0.0001,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'model': 'attention',\n",
      " 'n_encode_layers': 3,\n",
      " 'n_epochs': 100,\n",
      " 'no_cuda': False,\n",
      " 'no_progress_bar': False,\n",
      " 'no_tensorboard': True,\n",
      " 'normalization': 'batch',\n",
      " 'output_dir': 'outputs',\n",
      " 'problem': 'tsp',\n",
      " 'resume': None,\n",
      " 'run_name': \"'tsp20_rollout'_20220830T234830\",\n",
      " 'save_dir': \"outputs/tsp_20/'tsp20_rollout'_20220830T234830\",\n",
      " 'seed': 1234,\n",
      " 'shrink_size': None,\n",
      " 'tanh_clipping': 10.0,\n",
      " 'use_cuda': False,\n",
      " 'val_dataset': None,\n",
      " 'val_size': 10000}\n",
      "Evaluating baseline model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:03<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train epoch 0, lr=0.0001 for run 'tsp20_rollout'_20220830T234830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 1/2500 [01:26<59:58:12, 86.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 0, avg_cost: 10.052973747253418\n",
      "grad_norm: 25.03532600402832, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                        | 51/2500 [01:48<19:32,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 50, avg_cost: 4.790637016296387\n",
      "grad_norm: 3.6637656688690186, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                      | 101/2500 [02:12<18:58,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 100, avg_cost: 4.56561279296875\n",
      "grad_norm: 3.4818990230560303, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                     | 151/2500 [02:36<19:05,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 150, avg_cost: 4.442076206207275\n",
      "grad_norm: 4.206906795501709, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                    | 201/2500 [03:00<18:31,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 200, avg_cost: 4.40846061706543\n",
      "grad_norm: 3.6400704383850098, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 251/2500 [03:23<17:55,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 250, avg_cost: 4.323901176452637\n",
      "grad_norm: 3.2838871479034424, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▊                                   | 301/2500 [03:47<17:29,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 300, avg_cost: 4.2987823486328125\n",
      "grad_norm: 2.717310905456543, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▌                                  | 351/2500 [04:11<16:53,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 350, avg_cost: 4.293211936950684\n",
      "grad_norm: 3.1846392154693604, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▍                                 | 401/2500 [04:35<16:49,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 400, avg_cost: 4.195064067840576\n",
      "grad_norm: 2.921323537826538, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▏                                | 451/2500 [04:59<16:22,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 450, avg_cost: 4.164606094360352\n",
      "grad_norm: 2.7436461448669434, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 501/2500 [05:23<15:47,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 500, avg_cost: 4.153465270996094\n",
      "grad_norm: 2.6966848373413086, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▊                               | 551/2500 [05:47<15:37,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 550, avg_cost: 4.08051872253418\n",
      "grad_norm: 2.9323909282684326, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▌                              | 601/2500 [06:11<15:01,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 600, avg_cost: 4.117249488830566\n",
      "grad_norm: 2.7878410816192627, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▍                             | 651/2500 [06:35<14:56,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 650, avg_cost: 4.103997230529785\n",
      "grad_norm: 3.3363873958587646, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▏                            | 701/2500 [06:59<14:27,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 700, avg_cost: 4.052146911621094\n",
      "grad_norm: 3.5758867263793945, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                            | 751/2500 [07:23<13:45,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 750, avg_cost: 4.085056304931641\n",
      "grad_norm: 13.81078815460205, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▊                           | 801/2500 [07:47<13:45,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 800, avg_cost: 4.078217506408691\n",
      "grad_norm: 3.2455332279205322, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████▌                          | 851/2500 [08:11<13:08,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 850, avg_cost: 4.06187105178833\n",
      "grad_norm: 3.1981446743011475, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▍                         | 901/2500 [08:34<12:37,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 900, avg_cost: 4.0965495109558105\n",
      "grad_norm: 2.96237850189209, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████▏                        | 951/2500 [08:58<12:18,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 950, avg_cost: 4.060207843780518\n",
      "grad_norm: 2.952073574066162, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▌                       | 1001/2500 [09:22<12:10,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1000, avg_cost: 4.066221237182617\n",
      "grad_norm: 2.9696552753448486, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████▍                      | 1051/2500 [09:46<11:35,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1050, avg_cost: 4.05625057220459\n",
      "grad_norm: 2.379671096801758, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▏                     | 1101/2500 [10:10<11:05,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1100, avg_cost: 4.051095962524414\n",
      "grad_norm: 2.656273365020752, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████▉                     | 1151/2500 [10:34<10:55,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1150, avg_cost: 4.083445072174072\n",
      "grad_norm: 4.331392765045166, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████▋                    | 1201/2500 [10:58<10:22,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1200, avg_cost: 4.046498775482178\n",
      "grad_norm: 2.396160125732422, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████▌                   | 1251/2500 [11:22<10:08,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1250, avg_cost: 4.086853504180908\n",
      "grad_norm: 3.9994044303894043, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████▎                  | 1301/2500 [11:46<09:31,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1300, avg_cost: 4.0315680503845215\n",
      "grad_norm: 2.595945119857788, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████                  | 1351/2500 [12:10<09:02,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1350, avg_cost: 4.0372772216796875\n",
      "grad_norm: 2.3594350814819336, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████▊                 | 1401/2500 [12:34<08:44,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1400, avg_cost: 3.9978437423706055\n",
      "grad_norm: 2.5543100833892822, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████▋                | 1451/2500 [12:58<08:15,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1450, avg_cost: 4.024295806884766\n",
      "grad_norm: 2.5557918548583984, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████▍               | 1501/2500 [13:22<08:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1500, avg_cost: 4.026859283447266\n",
      "grad_norm: 2.1232550144195557, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████▏              | 1551/2500 [13:46<07:36,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1550, avg_cost: 4.044167518615723\n",
      "grad_norm: 3.504685163497925, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████▉              | 1601/2500 [14:10<07:15,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1600, avg_cost: 4.050235748291016\n",
      "grad_norm: 2.6004116535186768, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████▊             | 1651/2500 [14:34<06:43,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1650, avg_cost: 4.042129993438721\n",
      "grad_norm: 2.507507562637329, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████▌            | 1701/2500 [14:58<06:22,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1700, avg_cost: 4.0241899490356445\n",
      "grad_norm: 2.681861639022827, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████▎           | 1751/2500 [15:22<05:59,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1750, avg_cost: 3.9648194313049316\n",
      "grad_norm: 2.82524037361145, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████           | 1801/2500 [15:46<05:38,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1800, avg_cost: 4.009598731994629\n",
      "grad_norm: 4.045599937438965, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████▉          | 1851/2500 [16:09<05:13,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1850, avg_cost: 4.051384449005127\n",
      "grad_norm: 2.7626962661743164, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████▋         | 1901/2500 [16:33<04:43,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1900, avg_cost: 4.021153450012207\n",
      "grad_norm: 2.2319231033325195, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████▍        | 1951/2500 [16:57<04:19,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 1950, avg_cost: 4.012548446655273\n",
      "grad_norm: 2.5879318714141846, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████▏       | 2001/2500 [17:21<03:57,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2000, avg_cost: 4.0298004150390625\n",
      "grad_norm: 3.960124969482422, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████▉       | 2051/2500 [17:45<03:39,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2050, avg_cost: 4.010394096374512\n",
      "grad_norm: 2.9851558208465576, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████▊      | 2101/2500 [18:09<03:09,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2100, avg_cost: 4.006901264190674\n",
      "grad_norm: 2.4591434001922607, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▌     | 2151/2500 [18:33<02:47,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2150, avg_cost: 4.010006427764893\n",
      "grad_norm: 2.910271167755127, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████▎    | 2201/2500 [18:57<02:21,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2200, avg_cost: 3.9779584407806396\n",
      "grad_norm: 2.7470271587371826, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████    | 2251/2500 [19:21<01:59,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2250, avg_cost: 3.9926064014434814\n",
      "grad_norm: 2.045478343963623, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████▉   | 2301/2500 [19:45<01:34,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2300, avg_cost: 4.013192176818848\n",
      "grad_norm: 2.713728427886963, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████▋  | 2351/2500 [20:09<01:10,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2350, avg_cost: 4.000735759735107\n",
      "grad_norm: 2.2459542751312256, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▍ | 2401/2500 [20:33<00:48,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2400, avg_cost: 4.032010078430176\n",
      "grad_norm: 2.9885573387145996, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████▏| 2451/2500 [20:57<00:23,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 2450, avg_cost: 3.972247838973999\n",
      "grad_norm: 2.585543394088745, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [21:27<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, took 00:21:30 s\n",
      "Saving model and state...\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:03<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 3.959139108657837 +- 0.0034682867117226124\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:03<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 candidate mean 3.964857339859009, baseline epoch 0 mean 7.2039923667907715, difference -3.2391350269317627\n",
      "p-value: 0.0\n",
      "Update baseline\n",
      "Evaluating baseline model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:03<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set warmup alpha = 1.0\n",
      "Start train epoch 1, lr=0.0001 for run 'tsp20_rollout'_20220830T234830\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1250/1250 [06:52<00:00,  3.03it/s]\n",
      "  0%|                                      | 1/2500 [01:49<76:14:02, 109.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_batch_id: 0, avg_cost: 3.995185375213623\n",
      "grad_norm: 1.2614898681640625, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                        | 22/2500 [01:59<20:32,  2.01it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x10b083d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aliceperse/miniconda3/envs/attention/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/aliceperse/miniconda3/envs/attention/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1474, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/aliceperse/miniconda3/envs/attention/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/aliceperse/miniconda3/envs/attention/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/aliceperse/miniconda3/envs/attention/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/aliceperse/miniconda3/envs/attention/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "  1%|▎                                      | 22/2500 [02:00<3:45:56,  5.47s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bac68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pi = torch.rand(512, 20, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22670bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70af2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a90936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7ef7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discr = (\n",
    "    torch.nn.Sequential(torch.nn.Linear(20 * 128, 2 * 20 * 128)),\n",
    "    torch.nn.Linear(2 * 128, 128),\n",
    "    torch.nn.Linear(128, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b24ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    glimpse = discr(pi.flatten(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47f0e73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 2560])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.flatten(-2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "807b7584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 20, 128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.flatten(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43df65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(512, 1)\n",
    "t1 = torch.rand(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc7f13ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([int(i[0] == i[1]) for i in zip(t, t1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941cb27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(t, t1.).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a094fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4358983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [16:54<01:52, 112.77s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not float"
     ]
    }
   ],
   "source": [
    "torch.mean((torch0.-0.)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42319644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets.attention_model import AttentionModel\n",
    "from utils.replay_buffer import ReplayBuffer\n",
    "from utils import load_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f1a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = problem = load_problem(opts.problem)\n",
    "buffer = ReplayBuffer(\n",
    "    120,\n",
    "    (opts.graph_size, opts.embedding_dim),\n",
    "    (opts.graph_size, opts.embedding_dim),\n",
    "    None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65a0699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = AttentionModel(\n",
    "    opts.embedding_dim,\n",
    "    opts.hidden_dim,\n",
    "    problem,\n",
    "    n_encode_layers=opts.n_encode_layers,\n",
    "    mask_inner=True,\n",
    "    mask_logits=True,\n",
    "    normalization=opts.normalization,\n",
    "    tanh_clipping=opts.tanh_clipping,\n",
    "    checkpoint_encoder=opts.checkpoint_encoder,\n",
    "    shrink_size=opts.shrink_size,\n",
    "    buffer=buffer,\n",
    "    graph_size=opts.graph_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b2ab49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.set_decode_type(\"greedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3565ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e96982be",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = m(torch.rand(2, 20, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fdbc4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d094cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_copy(model):\n",
    "    weights_path = \"weights_temp.pt\"\n",
    "    torch.save(model.state_dict(), weights_path)\n",
    "    return torch.load(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "484f0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "copyed_model = pickle.loads(pickle.dumps(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab4d549d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionModel(\n",
       "  (init_embed): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (embedder): GraphAttentionEncoder(\n",
       "    (layers): Sequential(\n",
       "      (0): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedder_act): GraphAttentionEncoder(\n",
       "    (layers): Sequential(\n",
       "      (0): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MultiHeadAttentionLayer(\n",
       "        (0): SkipConnection(\n",
       "          (module): MultiHeadAttention()\n",
       "        )\n",
       "        (1): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): SkipConnection(\n",
       "          (module): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Normalization(\n",
       "          (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (project_node_embeddings): Linear(in_features=128, out_features=384, bias=False)\n",
       "  (project_fixed_context): Linear(in_features=128, out_features=128, bias=False)\n",
       "  (project_step_context): Linear(in_features=256, out_features=128, bias=False)\n",
       "  (project_out): Linear(in_features=128, out_features=128, bias=False)\n",
       "  (discriminator): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2560, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copyed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d5553c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/attention/lib/python3.9/site-packages/torch/_tensor.py:89\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__deepcopy__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, memo)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly Tensors created explicitly by the user \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(graph leaves) support the deepcopy protocol at the moment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
     ]
    }
   ],
   "source": [
    "t = copy.deepcopy(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4efa0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('W_placeholder',\n",
       "              tensor([-1.4715e-01, -3.8451e-01, -6.7359e-01, -3.9540e-01, -8.9171e-01,\n",
       "                       6.6598e-01,  4.7596e-01, -5.5203e-01,  3.5326e-01, -9.1851e-01,\n",
       "                       8.3335e-01,  9.3352e-01, -6.9981e-01, -6.4756e-01, -4.2164e-01,\n",
       "                      -2.3503e-01, -8.8591e-01, -3.5869e-01,  3.8501e-01,  3.5460e-02,\n",
       "                      -6.2774e-01,  7.9665e-01, -7.7243e-02, -2.5556e-01, -5.8307e-02,\n",
       "                      -8.1423e-02,  8.5035e-01, -1.1437e-01, -8.0009e-01, -9.1953e-01,\n",
       "                       1.8560e-01, -1.5036e-01,  4.6146e-01,  9.3423e-01, -3.1048e-01,\n",
       "                       7.2536e-01, -7.6531e-01, -2.7632e-01, -3.0110e-01,  7.6366e-01,\n",
       "                      -3.3252e-02, -5.5026e-01, -2.2444e-01, -3.9533e-01, -5.8351e-02,\n",
       "                      -1.0893e-01, -9.1063e-01,  7.7446e-01, -4.2327e-01, -5.7691e-01,\n",
       "                       9.1500e-01,  7.3603e-01, -8.4482e-02, -2.8418e-01,  1.0463e-01,\n",
       "                      -3.9603e-02, -1.4796e-01, -3.1609e-01, -2.8337e-02, -8.2797e-01,\n",
       "                       3.2130e-01, -1.7228e-01,  3.6148e-01, -8.3124e-01,  1.0096e-01,\n",
       "                       7.6106e-01,  7.5811e-01,  4.5616e-01, -3.6171e-01,  3.3777e-01,\n",
       "                      -3.1124e-01,  9.8756e-01,  3.3879e-01,  9.2941e-02,  6.6136e-01,\n",
       "                      -9.8325e-01, -3.9275e-01,  8.8349e-01, -8.1542e-01,  8.8848e-01,\n",
       "                      -5.4380e-01,  5.7513e-01, -8.2062e-01, -5.6260e-01, -1.1831e-01,\n",
       "                      -5.2026e-01,  7.3911e-01,  4.6525e-01,  6.3017e-01,  4.9927e-01,\n",
       "                      -9.5149e-01,  8.1077e-01, -2.2617e-01, -1.0022e-01, -5.3917e-01,\n",
       "                       3.9474e-01, -5.3950e-01,  1.6531e-01, -7.9122e-01, -8.3522e-01,\n",
       "                       1.8304e-01,  2.7484e-01,  1.8945e-02, -1.8355e-01, -8.3936e-01,\n",
       "                      -2.2438e-01, -4.2096e-01, -2.7656e-01, -7.0806e-01, -5.5424e-01,\n",
       "                      -5.0533e-02,  1.4179e-01, -2.4746e-01, -6.7753e-01,  1.1286e-01,\n",
       "                       7.2416e-02, -9.4729e-01, -1.6655e-01,  2.5695e-01,  2.0788e-01,\n",
       "                      -5.2594e-01,  3.3929e-01,  8.8627e-01, -3.4122e-01, -8.7972e-03,\n",
       "                      -8.4491e-01, -5.6843e-01,  3.1989e-01,  5.6769e-01, -2.8101e-01,\n",
       "                       9.8875e-01,  7.7304e-02, -9.9452e-01,  7.4565e-01, -2.6103e-01,\n",
       "                      -9.6045e-01, -3.0823e-01,  3.1650e-02, -1.1275e-01,  1.7305e-01,\n",
       "                      -7.8538e-01, -1.0241e-01,  7.6687e-01, -3.7876e-01, -6.2414e-01,\n",
       "                       4.7890e-01, -7.9207e-01,  2.4255e-01, -8.5380e-01,  6.5717e-01,\n",
       "                      -9.3164e-01, -3.1424e-01,  7.4383e-01, -9.0799e-01, -8.4213e-01,\n",
       "                       2.7901e-01, -7.3605e-01,  7.9002e-01, -8.5470e-01, -3.6681e-02,\n",
       "                       8.1322e-01,  5.8030e-01,  9.9509e-01,  2.5463e-01,  8.6649e-01,\n",
       "                       9.2142e-02,  5.9694e-02,  1.1659e-01, -7.6154e-01, -3.3335e-01,\n",
       "                       9.7694e-01, -1.5138e-01, -4.6982e-01,  3.1587e-01, -2.2796e-01,\n",
       "                       3.8478e-02,  9.8853e-01, -3.5042e-01,  4.7667e-01, -9.9343e-01,\n",
       "                      -5.7562e-01,  5.0211e-02,  5.6300e-01, -7.0163e-01, -5.0749e-01,\n",
       "                      -3.2519e-01,  8.9384e-01, -4.3228e-01, -1.6926e-01,  3.8292e-01,\n",
       "                       3.1240e-01,  4.9178e-01,  5.4382e-01,  3.2263e-01, -6.4250e-01,\n",
       "                       4.2666e-01,  7.4241e-01,  2.8608e-01,  6.9536e-01, -9.4646e-01,\n",
       "                      -1.3956e-01,  8.4424e-04, -6.3143e-01,  5.2129e-01, -8.7080e-01,\n",
       "                       3.9410e-01,  5.3712e-01,  8.4742e-01,  6.2327e-01, -1.4816e-01,\n",
       "                      -1.5583e-01, -5.0614e-01, -3.3633e-01,  6.7252e-01, -8.1633e-01,\n",
       "                      -9.6250e-01, -2.4037e-01,  2.3539e-01,  6.0364e-01, -1.7718e-01,\n",
       "                      -9.2351e-01, -8.9289e-01, -7.7986e-01,  3.2825e-01, -1.7088e-01,\n",
       "                       7.1905e-01,  5.4330e-01,  9.7520e-02,  5.8139e-01,  3.8134e-01,\n",
       "                      -6.2435e-01, -4.5037e-01,  8.1112e-01, -9.7996e-01, -6.3964e-01,\n",
       "                       2.4718e-01,  8.6461e-01, -8.7583e-01, -9.4795e-02,  7.2498e-01,\n",
       "                      -8.3922e-01, -9.5204e-01,  4.8769e-01,  2.0238e-01,  3.6920e-01,\n",
       "                       9.6753e-01, -4.1545e-01,  8.5721e-01, -2.0059e-01,  3.6591e-02,\n",
       "                       5.3475e-03, -6.1633e-01, -5.9284e-01, -8.5863e-02,  3.2631e-01,\n",
       "                      -5.0240e-01])),\n",
       "             ('init_embed.weight',\n",
       "              tensor([[ 6.6261e-01, -4.1093e-01],\n",
       "                      [-6.6090e-01,  1.8719e-01],\n",
       "                      [ 2.2015e-02,  4.7142e-01],\n",
       "                      [ 4.9417e-01,  3.6085e-02],\n",
       "                      [-4.0224e-01,  3.3927e-01],\n",
       "                      [-2.0666e-01,  2.1716e-01],\n",
       "                      [ 1.7203e-01, -3.3806e-01],\n",
       "                      [ 5.1436e-01,  1.0916e-01],\n",
       "                      [-2.1822e-01,  2.7197e-02],\n",
       "                      [ 1.1733e-01,  4.3091e-01],\n",
       "                      [-1.9024e-01,  6.6303e-01],\n",
       "                      [-5.3378e-01,  9.6423e-02],\n",
       "                      [-4.5954e-01,  8.7791e-02],\n",
       "                      [ 6.6557e-01, -2.9205e-02],\n",
       "                      [-2.1242e-01, -6.6039e-01],\n",
       "                      [ 2.6558e-02,  1.4155e-02],\n",
       "                      [-3.6169e-01,  3.2378e-01],\n",
       "                      [ 3.5255e-01,  7.9885e-02],\n",
       "                      [-1.1077e-01,  9.9455e-02],\n",
       "                      [ 3.5014e-01,  1.4728e-01],\n",
       "                      [-4.3992e-01,  6.4841e-01],\n",
       "                      [-6.0007e-01,  6.6325e-01],\n",
       "                      [-4.9374e-01, -9.7885e-02],\n",
       "                      [ 5.3744e-01,  1.9084e-01],\n",
       "                      [-4.4117e-01,  4.0693e-01],\n",
       "                      [-6.3886e-01, -4.1239e-02],\n",
       "                      [-5.0525e-01, -5.5867e-01],\n",
       "                      [ 1.3394e-01, -1.1843e-01],\n",
       "                      [-5.5319e-01,  2.8898e-01],\n",
       "                      [ 2.4251e-01,  3.9217e-01],\n",
       "                      [ 2.5519e-01,  2.1790e-01],\n",
       "                      [-4.5927e-01,  3.3851e-01],\n",
       "                      [-2.7350e-01,  2.1346e-02],\n",
       "                      [-5.6975e-01,  4.5289e-01],\n",
       "                      [-4.7952e-01, -1.8372e-01],\n",
       "                      [ 4.3323e-01,  5.8480e-01],\n",
       "                      [ 6.5615e-01,  5.3905e-01],\n",
       "                      [-4.4165e-01,  4.8890e-01],\n",
       "                      [-3.0144e-01, -2.8251e-02],\n",
       "                      [ 3.4454e-01, -6.0701e-01],\n",
       "                      [-4.9389e-01, -2.8113e-01],\n",
       "                      [-3.4982e-01,  1.4175e-01],\n",
       "                      [-4.1963e-01,  3.7893e-01],\n",
       "                      [ 1.6220e-01,  3.3207e-01],\n",
       "                      [ 2.4050e-01, -5.8373e-01],\n",
       "                      [ 8.3706e-02,  5.0598e-01],\n",
       "                      [-4.0620e-01, -1.5589e-01],\n",
       "                      [-3.3320e-01,  4.0948e-01],\n",
       "                      [ 5.0099e-01, -5.6033e-01],\n",
       "                      [ 8.9878e-02, -2.1790e-01],\n",
       "                      [-6.0110e-01,  1.4686e-01],\n",
       "                      [ 1.4790e-01, -6.4924e-01],\n",
       "                      [-1.6449e-01,  2.3421e-01],\n",
       "                      [ 1.9068e-01, -1.5683e-01],\n",
       "                      [-2.3339e-02, -1.7403e-01],\n",
       "                      [-6.9801e-01, -6.7978e-01],\n",
       "                      [ 2.4071e-01,  5.8584e-01],\n",
       "                      [ 5.4123e-01, -4.9408e-01],\n",
       "                      [ 2.7810e-01, -2.8813e-01],\n",
       "                      [ 3.9263e-01,  4.0024e-01],\n",
       "                      [-5.1062e-01,  2.0963e-01],\n",
       "                      [-4.9152e-01, -4.3808e-01],\n",
       "                      [ 2.7290e-01, -4.2713e-01],\n",
       "                      [-5.9441e-01,  3.6149e-02],\n",
       "                      [ 2.3140e-01,  6.6447e-01],\n",
       "                      [-1.5328e-01, -4.6806e-01],\n",
       "                      [-3.4260e-02,  4.2769e-01],\n",
       "                      [ 5.8203e-01, -1.4563e-01],\n",
       "                      [ 1.5412e-01,  2.2038e-01],\n",
       "                      [-1.9387e-01,  6.3237e-02],\n",
       "                      [-6.3152e-01,  4.0615e-01],\n",
       "                      [ 3.2655e-01, -6.2746e-01],\n",
       "                      [-3.8278e-01,  6.2909e-01],\n",
       "                      [ 3.4650e-01,  6.3534e-01],\n",
       "                      [ 5.6439e-01,  4.7701e-01],\n",
       "                      [ 5.9026e-01,  2.1488e-01],\n",
       "                      [ 3.9999e-01, -5.8079e-01],\n",
       "                      [-4.2259e-01,  1.9503e-01],\n",
       "                      [ 1.9115e-02,  5.2807e-01],\n",
       "                      [-4.2582e-02, -6.3107e-01],\n",
       "                      [ 3.6640e-01, -5.1584e-01],\n",
       "                      [ 2.5958e-01,  4.3871e-01],\n",
       "                      [-7.1203e-03,  9.9994e-02],\n",
       "                      [ 6.4970e-01, -5.7870e-01],\n",
       "                      [ 2.0117e-01,  6.4350e-01],\n",
       "                      [ 4.5145e-01, -1.2948e-01],\n",
       "                      [-8.1269e-02,  1.6767e-01],\n",
       "                      [-7.8174e-03, -6.2603e-01],\n",
       "                      [-1.4390e-01, -4.0260e-01],\n",
       "                      [ 2.7557e-02, -2.7894e-02],\n",
       "                      [ 2.2259e-01,  1.3714e-01],\n",
       "                      [ 3.8215e-01, -5.9037e-01],\n",
       "                      [ 1.9374e-01, -1.4270e-01],\n",
       "                      [-3.5064e-02, -2.8152e-01],\n",
       "                      [ 4.1358e-01, -6.3002e-01],\n",
       "                      [-1.6005e-01, -1.6097e-01],\n",
       "                      [ 5.2034e-01,  3.2601e-01],\n",
       "                      [ 2.7234e-01, -1.7671e-01],\n",
       "                      [-3.7014e-01, -5.5580e-01],\n",
       "                      [-3.0135e-01, -6.5013e-01],\n",
       "                      [ 1.0561e-01, -5.7208e-01],\n",
       "                      [ 5.1337e-01,  1.3291e-01],\n",
       "                      [-1.4362e-01, -4.9255e-01],\n",
       "                      [-5.1302e-02, -8.8797e-02],\n",
       "                      [ 2.5866e-02, -1.9884e-01],\n",
       "                      [-4.9768e-02, -6.7023e-01],\n",
       "                      [ 3.8946e-02,  3.9109e-01],\n",
       "                      [-5.9843e-01, -6.7079e-01],\n",
       "                      [-9.0184e-03,  6.4525e-01],\n",
       "                      [ 4.1633e-01,  2.2352e-01],\n",
       "                      [-1.0051e-01,  3.9089e-04],\n",
       "                      [-3.7458e-01,  3.8738e-01],\n",
       "                      [-3.2885e-01, -1.5123e-01],\n",
       "                      [ 9.1951e-02, -2.8102e-01],\n",
       "                      [ 4.3503e-02, -1.4089e-01],\n",
       "                      [-5.4456e-01, -1.4782e-01],\n",
       "                      [-6.2943e-01,  3.3372e-01],\n",
       "                      [ 4.5597e-01, -1.0413e-01],\n",
       "                      [-4.2857e-02, -3.5309e-01],\n",
       "                      [ 4.0800e-01, -1.0202e-02],\n",
       "                      [-4.1762e-01, -4.7623e-01],\n",
       "                      [ 3.0601e-01,  5.1562e-01],\n",
       "                      [ 5.6035e-01, -4.5745e-01],\n",
       "                      [-4.7444e-01, -9.9078e-02],\n",
       "                      [ 6.9432e-01,  3.9669e-01],\n",
       "                      [ 7.1371e-02,  2.6716e-01],\n",
       "                      [ 1.5356e-01, -3.9821e-03],\n",
       "                      [ 3.2859e-01,  3.4558e-01]])),\n",
       "             ('init_embed.bias',\n",
       "              tensor([-0.4869, -0.5333,  0.2807,  0.6421,  0.4852,  0.4551, -0.6092, -0.4952,\n",
       "                      -0.5493,  0.0792, -0.3693,  0.0241, -0.0129,  0.2981, -0.5354, -0.6714,\n",
       "                      -0.0276, -0.5789, -0.6045, -0.0977, -0.3564,  0.0239,  0.2237, -0.1330,\n",
       "                      -0.3067,  0.1560,  0.5969,  0.2029,  0.2660, -0.5145,  0.5512, -0.3226,\n",
       "                       0.1299, -0.5166,  0.1634,  0.2773,  0.6369,  0.1069, -0.7049, -0.5774,\n",
       "                      -0.0188, -0.2648, -0.6678, -0.0444, -0.3151,  0.6314, -0.2023, -0.1144,\n",
       "                      -0.3504,  0.0721,  0.5283, -0.2572, -0.1167,  0.1059,  0.3261,  0.0582,\n",
       "                      -0.1090,  0.0443,  0.6603, -0.0029,  0.2320, -0.7024,  0.3963, -0.5382,\n",
       "                       0.6396, -0.4512,  0.4857, -0.2339,  0.6358,  0.1847,  0.4707, -0.6200,\n",
       "                       0.2565,  0.1905, -0.2491, -0.1569,  0.6313,  0.0140,  0.6934, -0.3705,\n",
       "                      -0.3757, -0.0299,  0.6093,  0.1655,  0.4250,  0.6744,  0.2462,  0.4912,\n",
       "                       0.1535, -0.4236,  0.0771,  0.3886,  0.6194, -0.2250, -0.1841,  0.6985,\n",
       "                       0.4730, -0.6844,  0.1747, -0.0310, -0.6314, -0.3205,  0.4837,  0.4268,\n",
       "                      -0.6812,  0.6566, -0.7018, -0.5631,  0.3795,  0.3486,  0.3668, -0.1355,\n",
       "                      -0.6084,  0.0331,  0.0854, -0.0543,  0.6905, -0.2657,  0.3075,  0.3127,\n",
       "                      -0.3277,  0.1070,  0.0702, -0.3823,  0.4450, -0.3474, -0.0916, -0.6261])),\n",
       "             ('embedder.layers.0.0.module.W_query',\n",
       "              tensor([[[ 0.2113,  0.0458,  0.0868,  ...,  0.0878, -0.2178,  0.1266],\n",
       "                       [-0.0673,  0.1800,  0.0900,  ...,  0.2228,  0.0524, -0.1685],\n",
       "                       [-0.0128, -0.2217,  0.0004,  ..., -0.1046, -0.2254,  0.1495],\n",
       "                       ...,\n",
       "                       [-0.1022,  0.1847, -0.0514,  ...,  0.1845,  0.1457,  0.0662],\n",
       "                       [ 0.0873,  0.2419,  0.1741,  ...,  0.2273,  0.1793, -0.0058],\n",
       "                       [-0.1684,  0.1824,  0.2016,  ..., -0.1883,  0.1271,  0.1333]],\n",
       "              \n",
       "                      [[ 0.1016, -0.0796, -0.2078,  ...,  0.0055, -0.1987,  0.0251],\n",
       "                       [ 0.1837, -0.1569, -0.1901,  ...,  0.0400,  0.2367, -0.0979],\n",
       "                       [-0.2214, -0.0331,  0.1260,  ..., -0.0651, -0.0185, -0.0165],\n",
       "                       ...,\n",
       "                       [ 0.1911, -0.1538, -0.0833,  ..., -0.1163, -0.0062, -0.1044],\n",
       "                       [-0.1669,  0.1504, -0.2256,  ..., -0.1528, -0.2236, -0.0381],\n",
       "                       [-0.1192,  0.1769, -0.0450,  ...,  0.0479,  0.0113,  0.0387]],\n",
       "              \n",
       "                      [[ 0.1562,  0.1274,  0.1762,  ...,  0.0827, -0.2026, -0.2256],\n",
       "                       [ 0.1608,  0.1162, -0.1235,  ..., -0.2003, -0.0542,  0.0817],\n",
       "                       [-0.1577, -0.0539, -0.2265,  ..., -0.2254,  0.0375,  0.2131],\n",
       "                       ...,\n",
       "                       [-0.0837, -0.0460, -0.0219,  ..., -0.0241, -0.1251,  0.1045],\n",
       "                       [-0.0158, -0.0413,  0.2467,  ..., -0.2305,  0.0219, -0.0978],\n",
       "                       [ 0.1548, -0.1035,  0.0236,  ...,  0.0542, -0.1447,  0.1761]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1005, -0.1668, -0.0244,  ..., -0.0961,  0.0710,  0.1253],\n",
       "                       [ 0.0369,  0.0465, -0.1126,  ..., -0.2160,  0.0749,  0.1232],\n",
       "                       [ 0.1711, -0.2351, -0.0497,  ..., -0.1960,  0.1580, -0.1187],\n",
       "                       ...,\n",
       "                       [ 0.0806, -0.1305, -0.0798,  ...,  0.1807, -0.2270,  0.0983],\n",
       "                       [-0.0675, -0.0008, -0.0529,  ...,  0.0113,  0.2296,  0.2106],\n",
       "                       [-0.2031, -0.1049, -0.2257,  ..., -0.0902, -0.2397, -0.1415]],\n",
       "              \n",
       "                      [[ 0.0334, -0.0953, -0.2273,  ...,  0.0785,  0.0364,  0.1316],\n",
       "                       [ 0.0134, -0.1010, -0.1140,  ..., -0.2097,  0.0931, -0.0597],\n",
       "                       [-0.1820, -0.1261, -0.1555,  ...,  0.0685,  0.2057, -0.1261],\n",
       "                       ...,\n",
       "                       [-0.0550,  0.1132,  0.1054,  ...,  0.0626,  0.1385,  0.1456],\n",
       "                       [ 0.1022,  0.0079, -0.1571,  ..., -0.0369,  0.0800,  0.0548],\n",
       "                       [-0.1574,  0.2012,  0.1398,  ...,  0.2444, -0.1371, -0.1284]],\n",
       "              \n",
       "                      [[ 0.0720, -0.1622, -0.1112,  ...,  0.1306, -0.0344, -0.0882],\n",
       "                       [ 0.0348, -0.0456,  0.1761,  ...,  0.1601, -0.1679, -0.0041],\n",
       "                       [-0.0012, -0.1903, -0.1233,  ..., -0.0617, -0.0698, -0.1103],\n",
       "                       ...,\n",
       "                       [ 0.1077, -0.0289,  0.2430,  ...,  0.0339, -0.1222, -0.1276],\n",
       "                       [-0.1313,  0.0540,  0.1342,  ...,  0.0572,  0.0276, -0.1667],\n",
       "                       [ 0.0139, -0.2029, -0.0434,  ..., -0.1362, -0.1191, -0.0406]]])),\n",
       "             ('embedder.layers.0.0.module.W_key',\n",
       "              tensor([[[-0.0714, -0.1300, -0.0543,  ..., -0.0915,  0.1058, -0.2190],\n",
       "                       [-0.1509, -0.1452, -0.0702,  ...,  0.1408, -0.1297,  0.1864],\n",
       "                       [ 0.0477,  0.1589, -0.2394,  ...,  0.2103,  0.1845, -0.1033],\n",
       "                       ...,\n",
       "                       [-0.1670,  0.2076, -0.0268,  ...,  0.2035,  0.0529,  0.0615],\n",
       "                       [-0.0546,  0.0180,  0.0499,  ..., -0.1593,  0.0942, -0.2486],\n",
       "                       [-0.0943,  0.1770,  0.1264,  ...,  0.1154, -0.0925, -0.0815]],\n",
       "              \n",
       "                      [[-0.2477,  0.0659,  0.1525,  ..., -0.2043, -0.0920,  0.0770],\n",
       "                       [-0.1050, -0.0376, -0.1414,  ...,  0.0216,  0.2227,  0.2439],\n",
       "                       [ 0.1029, -0.1165,  0.0528,  ...,  0.1014,  0.1080, -0.2160],\n",
       "                       ...,\n",
       "                       [-0.0960,  0.2420,  0.2312,  ..., -0.1444,  0.1689,  0.1525],\n",
       "                       [ 0.0622, -0.0182, -0.2196,  ..., -0.0150, -0.1632, -0.0676],\n",
       "                       [ 0.0929,  0.1324,  0.1392,  ...,  0.0786,  0.0831,  0.0505]],\n",
       "              \n",
       "                      [[-0.0098,  0.0517, -0.1155,  ..., -0.1024,  0.1174,  0.1557],\n",
       "                       [-0.2313,  0.2091, -0.2076,  ...,  0.1682, -0.1380, -0.2212],\n",
       "                       [-0.0295, -0.1847,  0.1476,  ...,  0.1198, -0.2327, -0.1614],\n",
       "                       ...,\n",
       "                       [ 0.0072,  0.1216, -0.1484,  ..., -0.0286,  0.1947,  0.1627],\n",
       "                       [-0.2256, -0.1220, -0.1931,  ..., -0.1616, -0.0697, -0.0340],\n",
       "                       [ 0.0747, -0.2350, -0.1145,  ..., -0.1382, -0.0945,  0.0592]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.2493,  0.0602, -0.0564,  ...,  0.1923,  0.0527, -0.1719],\n",
       "                       [-0.1812,  0.1837,  0.0709,  ..., -0.1339,  0.0771, -0.2491],\n",
       "                       [ 0.2064, -0.0040, -0.1883,  ..., -0.0276,  0.2119,  0.2119],\n",
       "                       ...,\n",
       "                       [-0.1372,  0.1371,  0.2230,  ...,  0.1388,  0.1424,  0.0496],\n",
       "                       [ 0.0389,  0.2229, -0.1821,  ...,  0.0158, -0.2378, -0.2429],\n",
       "                       [ 0.1604, -0.2104, -0.1257,  ...,  0.1811, -0.2323, -0.1989]],\n",
       "              \n",
       "                      [[ 0.1501, -0.1585,  0.0542,  ...,  0.0973,  0.1256, -0.0710],\n",
       "                       [ 0.1298,  0.0803, -0.0177,  ...,  0.1601, -0.1321, -0.1815],\n",
       "                       [-0.1610,  0.0428, -0.2216,  ..., -0.1146,  0.2433,  0.0259],\n",
       "                       ...,\n",
       "                       [ 0.1395,  0.1678,  0.1220,  ..., -0.1641,  0.1884,  0.0832],\n",
       "                       [-0.0067,  0.2478, -0.1588,  ...,  0.0028,  0.0234, -0.1201],\n",
       "                       [-0.2442, -0.0153,  0.0786,  ..., -0.0896,  0.1253, -0.1525]],\n",
       "              \n",
       "                      [[-0.2075,  0.1435, -0.0805,  ...,  0.0815, -0.1465, -0.0338],\n",
       "                       [ 0.0615, -0.1301, -0.2401,  ..., -0.0107, -0.0251,  0.0165],\n",
       "                       [ 0.2020, -0.2070,  0.0443,  ...,  0.0353, -0.1754, -0.0397],\n",
       "                       ...,\n",
       "                       [ 0.1169,  0.0565,  0.0685,  ...,  0.0640,  0.2416,  0.1504],\n",
       "                       [-0.0175,  0.2374, -0.0642,  ..., -0.0952, -0.2124, -0.2407],\n",
       "                       [ 0.1903,  0.1615,  0.2487,  ..., -0.0786,  0.0810,  0.0137]]])),\n",
       "             ('embedder.layers.0.0.module.W_val',\n",
       "              tensor([[[-0.1941,  0.0913,  0.2072,  ..., -0.2015,  0.0635, -0.0892],\n",
       "                       [-0.0603, -0.1320,  0.1012,  ...,  0.0359, -0.0514,  0.1961],\n",
       "                       [-0.0965,  0.2268,  0.0442,  ...,  0.1568,  0.0543, -0.0644],\n",
       "                       ...,\n",
       "                       [ 0.0816, -0.2292, -0.0270,  ...,  0.1420, -0.0181,  0.0156],\n",
       "                       [-0.1069,  0.0918, -0.1578,  ..., -0.1951,  0.1155, -0.0976],\n",
       "                       [-0.1019,  0.1354,  0.0058,  ..., -0.1963, -0.1010,  0.0805]],\n",
       "              \n",
       "                      [[ 0.1636,  0.0243,  0.0302,  ..., -0.1573, -0.2229,  0.1221],\n",
       "                       [-0.0265, -0.1157, -0.2057,  ...,  0.1567,  0.1731,  0.0067],\n",
       "                       [-0.0568, -0.1690, -0.1376,  ...,  0.0052, -0.0257,  0.0706],\n",
       "                       ...,\n",
       "                       [-0.1199,  0.2183, -0.0940,  ...,  0.0752,  0.1119, -0.2355],\n",
       "                       [ 0.2427,  0.1916, -0.1505,  ...,  0.0057,  0.1054,  0.0465],\n",
       "                       [-0.1893,  0.1209, -0.1844,  ..., -0.0143, -0.1097,  0.1952]],\n",
       "              \n",
       "                      [[ 0.0764, -0.1122,  0.1629,  ...,  0.0635, -0.0309, -0.1668],\n",
       "                       [-0.2476, -0.0675,  0.0719,  ..., -0.1190,  0.1072,  0.0612],\n",
       "                       [ 0.0952,  0.1931,  0.1015,  ..., -0.0354, -0.1260,  0.0888],\n",
       "                       ...,\n",
       "                       [-0.0214, -0.1819,  0.1822,  ..., -0.0087,  0.0964,  0.0444],\n",
       "                       [ 0.2132, -0.1134,  0.1078,  ..., -0.1484,  0.1364,  0.2053],\n",
       "                       [ 0.1635,  0.2141, -0.0251,  ...,  0.1617,  0.1338, -0.1167]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.2308,  0.2498, -0.2457,  ...,  0.1879,  0.0465,  0.1038],\n",
       "                       [ 0.1495,  0.0303,  0.0647,  ...,  0.2015,  0.1458,  0.2484],\n",
       "                       [ 0.1849,  0.1770,  0.1967,  ..., -0.2167, -0.1651,  0.0403],\n",
       "                       ...,\n",
       "                       [ 0.0194,  0.0229, -0.1415,  ..., -0.2182, -0.2238,  0.0565],\n",
       "                       [-0.1448, -0.0708, -0.0835,  ...,  0.0341, -0.0228,  0.1133],\n",
       "                       [ 0.2279, -0.0697, -0.1762,  ...,  0.2282,  0.0725,  0.1024]],\n",
       "              \n",
       "                      [[ 0.1238,  0.0208,  0.0509,  ..., -0.0329, -0.1342, -0.0837],\n",
       "                       [ 0.0127,  0.1924, -0.1786,  ...,  0.1587,  0.0301,  0.0180],\n",
       "                       [ 0.2450,  0.1800,  0.0473,  ...,  0.1476,  0.0751, -0.1860],\n",
       "                       ...,\n",
       "                       [ 0.1479,  0.1164,  0.0922,  ...,  0.2049, -0.2078, -0.0616],\n",
       "                       [ 0.1874,  0.0467,  0.1355,  ...,  0.1242,  0.1501,  0.1228],\n",
       "                       [ 0.1115,  0.0258, -0.1135,  ...,  0.0561, -0.2008, -0.0094]],\n",
       "              \n",
       "                      [[ 0.2204,  0.0259,  0.2476,  ..., -0.1660, -0.1997, -0.0940],\n",
       "                       [ 0.0049,  0.2268,  0.0634,  ...,  0.1966,  0.0316,  0.1215],\n",
       "                       [-0.0818, -0.2263,  0.1253,  ...,  0.2023, -0.0072,  0.0411],\n",
       "                       ...,\n",
       "                       [-0.0323,  0.0185,  0.2126,  ..., -0.1489, -0.2480, -0.0975],\n",
       "                       [-0.1189,  0.0457, -0.2367,  ...,  0.2026, -0.0729, -0.2208],\n",
       "                       [-0.1052, -0.1277,  0.1225,  ...,  0.2327, -0.2157,  0.2415]]])),\n",
       "             ('embedder.layers.0.0.module.W_out',\n",
       "              tensor([[[ 0.0014, -0.0700, -0.0765,  ..., -0.0303, -0.0141, -0.0817],\n",
       "                       [ 0.0817, -0.0523,  0.0138,  ...,  0.0395,  0.0530, -0.0637],\n",
       "                       [ 0.0121,  0.0243,  0.0522,  ...,  0.0828,  0.0627, -0.0208],\n",
       "                       ...,\n",
       "                       [ 0.0830,  0.0713, -0.0492,  ...,  0.0873, -0.0730, -0.0198],\n",
       "                       [-0.0257, -0.0388,  0.0444,  ..., -0.0216,  0.0193,  0.0141],\n",
       "                       [ 0.0568,  0.0646,  0.0084,  ..., -0.0519,  0.0215, -0.0298]],\n",
       "              \n",
       "                      [[-0.0871,  0.0752, -0.0751,  ...,  0.0533,  0.0119, -0.0113],\n",
       "                       [-0.0650,  0.0005,  0.0764,  ...,  0.0474, -0.0215,  0.0158],\n",
       "                       [-0.0442, -0.0047, -0.0393,  ...,  0.0355, -0.0016, -0.0837],\n",
       "                       ...,\n",
       "                       [ 0.0809, -0.0879,  0.0180,  ...,  0.0595,  0.0147, -0.0040],\n",
       "                       [-0.0783,  0.0293,  0.0842,  ..., -0.0874, -0.0337, -0.0587],\n",
       "                       [ 0.0854,  0.0244,  0.0473,  ...,  0.0155,  0.0195,  0.0234]],\n",
       "              \n",
       "                      [[-0.0096, -0.0445, -0.0300,  ...,  0.0179,  0.0484, -0.0769],\n",
       "                       [-0.0878,  0.0798, -0.0501,  ..., -0.0022,  0.0837, -0.0532],\n",
       "                       [ 0.0080,  0.0039, -0.0270,  ..., -0.0287, -0.0042,  0.0494],\n",
       "                       ...,\n",
       "                       [ 0.0827, -0.0343, -0.0785,  ...,  0.0619,  0.0115,  0.0606],\n",
       "                       [ 0.0846, -0.0289, -0.0431,  ..., -0.0804,  0.0832,  0.0307],\n",
       "                       [ 0.0210, -0.0621, -0.0540,  ..., -0.0748, -0.0016, -0.0733]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0023,  0.0258, -0.0092,  ..., -0.0252, -0.0071, -0.0760],\n",
       "                       [ 0.0835,  0.0163,  0.0466,  ...,  0.0496, -0.0090, -0.0213],\n",
       "                       [-0.0683,  0.0751,  0.0479,  ..., -0.0656, -0.0358,  0.0589],\n",
       "                       ...,\n",
       "                       [ 0.0179, -0.0490, -0.0453,  ...,  0.0337,  0.0563, -0.0055],\n",
       "                       [-0.0861,  0.0710, -0.0172,  ..., -0.0342,  0.0638, -0.0739],\n",
       "                       [-0.0097, -0.0371, -0.0087,  ..., -0.0871, -0.0638,  0.0509]],\n",
       "              \n",
       "                      [[-0.0273, -0.0113, -0.0622,  ...,  0.0221,  0.0349, -0.0115],\n",
       "                       [-0.0005,  0.0846, -0.0243,  ..., -0.0192,  0.0270,  0.0013],\n",
       "                       [ 0.0589, -0.0465,  0.0550,  ..., -0.0378,  0.0004, -0.0262],\n",
       "                       ...,\n",
       "                       [-0.0605, -0.0474, -0.0790,  ..., -0.0411, -0.0539, -0.0399],\n",
       "                       [-0.0812,  0.0183, -0.0196,  ..., -0.0273, -0.0466,  0.0217],\n",
       "                       [ 0.0473, -0.0220, -0.0301,  ..., -0.0376, -0.0840, -0.0115]],\n",
       "              \n",
       "                      [[-0.0254,  0.0501,  0.0204,  ...,  0.0797, -0.0812, -0.0038],\n",
       "                       [ 0.0235,  0.0116,  0.0629,  ...,  0.0732,  0.0637, -0.0635],\n",
       "                       [-0.0699, -0.0661,  0.0164,  ...,  0.0404, -0.0780, -0.0029],\n",
       "                       ...,\n",
       "                       [-0.0262, -0.0119, -0.0055,  ..., -0.0226, -0.0625, -0.0447],\n",
       "                       [-0.0399, -0.0721, -0.0744,  ...,  0.0008,  0.0324,  0.0053],\n",
       "                       [-0.0397, -0.0531,  0.0826,  ..., -0.0104,  0.0723, -0.0529]]])),\n",
       "             ('embedder.layers.0.1.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder.layers.0.1.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder.layers.0.1.normalizer.running_mean',\n",
       "              tensor([-0.0635, -0.0779,  0.1031,  0.1409,  0.0321,  0.0845, -0.1202, -0.0631,\n",
       "                      -0.1377,  0.0804, -0.0383,  0.0335, -0.0572,  0.0859, -0.1246, -0.1450,\n",
       "                       0.0309, -0.0614, -0.0238,  0.0992, -0.0543, -0.0414, -0.0127,  0.0716,\n",
       "                      -0.0454,  0.0827, -0.0177, -0.0536,  0.0101,  0.0088,  0.1615, -0.0134,\n",
       "                       0.1017, -0.1200,  0.0387,  0.0672,  0.0302,  0.1133, -0.0403, -0.0615,\n",
       "                      -0.0556, -0.0643, -0.0726,  0.0128, -0.0859,  0.0599, -0.1604,  0.0232,\n",
       "                       0.0253,  0.0127, -0.0711,  0.0115, -0.0428,  0.0123, -0.0265, -0.0907,\n",
       "                       0.0350,  0.0399,  0.0546,  0.0222,  0.0026, -0.1053,  0.1236, -0.0664,\n",
       "                       0.0458, -0.1795,  0.0588, -0.0502,  0.1487,  0.0466,  0.0156, -0.1836,\n",
       "                       0.0141,  0.0457,  0.0084,  0.0353,  0.0900,  0.0230,  0.0894, -0.1058,\n",
       "                      -0.0454,  0.0135,  0.0493, -0.0600,  0.0704,  0.0501, -0.0318,  0.0700,\n",
       "                      -0.0036,  0.0025,  0.0237, -0.0069,  0.0643, -0.1065, -0.0182,  0.0328,\n",
       "                       0.1083, -0.0604, -0.0800, -0.0475, -0.0140, -0.0368,  0.1146,  0.0479,\n",
       "                      -0.0062,  0.0325, -0.1154, -0.1847,  0.0186,  0.0719,  0.0128, -0.0244,\n",
       "                      -0.0328,  0.0929,  0.0070,  0.0609,  0.0681, -0.0141,  0.0251,  0.0698,\n",
       "                      -0.0248, -0.0116, -0.0263, -0.1061,  0.1132, -0.0246, -0.0342, -0.0593])),\n",
       "             ('embedder.layers.0.1.normalizer.running_var',\n",
       "              tensor([0.9043, 0.9035, 0.9022, 0.9018, 0.9019, 0.9007, 0.9013, 0.9029, 0.9005,\n",
       "                      0.9022, 0.9042, 0.9025, 0.9016, 0.9036, 0.9049, 0.9000, 0.9018, 0.9011,\n",
       "                      0.9002, 0.9015, 0.9049, 0.9055, 0.9023, 0.9029, 0.9026, 0.9036, 0.9062,\n",
       "                      0.9002, 0.9026, 0.9023, 0.9012, 0.9020, 0.9007, 0.9038, 0.9026, 0.9053,\n",
       "                      0.9082, 0.9035, 0.9007, 0.9037, 0.9037, 0.9011, 0.9019, 0.9014, 0.9031,\n",
       "                      0.9022, 0.9016, 0.9018, 0.9038, 0.9004, 0.9033, 0.9038, 0.9007, 0.9005,\n",
       "                      0.9003, 0.9103, 0.9045, 0.9038, 0.9013, 0.9036, 0.9024, 0.9044, 0.9021,\n",
       "                      0.9028, 0.9051, 0.9025, 0.9017, 0.9023, 0.9007, 0.9002, 0.9036, 0.9036,\n",
       "                      0.9041, 0.9060, 0.9055, 0.9031, 0.9034, 0.9015, 0.9028, 0.9037, 0.9027,\n",
       "                      0.9029, 0.9001, 0.9050, 0.9042, 0.9017, 0.9003, 0.9036, 0.9021, 0.9000,\n",
       "                      0.9007, 0.9035, 0.9004, 0.9010, 0.9047, 0.9006, 0.9041, 0.9007, 0.9050,\n",
       "                      0.9058, 0.9029, 0.9024, 0.9026, 0.9001, 0.9004, 0.9042, 0.9013, 0.9080,\n",
       "                      0.9041, 0.9021, 0.9002, 0.9020, 0.9014, 0.9007, 0.9003, 0.9028, 0.9035,\n",
       "                      0.9021, 0.9012, 0.9013, 0.9036, 0.9034, 0.9037, 0.9022, 0.9068, 0.9008,\n",
       "                      0.9002, 0.9026])),\n",
       "             ('embedder.layers.0.1.normalizer.num_batches_tracked', tensor(1)),\n",
       "             ('embedder.layers.0.2.module.0.weight',\n",
       "              tensor([[-0.0142,  0.0144,  0.0297,  ...,  0.0093, -0.0608,  0.0124],\n",
       "                      [ 0.0270,  0.0414, -0.0776,  ..., -0.0552, -0.0326,  0.0299],\n",
       "                      [-0.0155, -0.0688, -0.0470,  ..., -0.0391,  0.0515, -0.0605],\n",
       "                      ...,\n",
       "                      [-0.0098,  0.0179,  0.0042,  ...,  0.0120, -0.0159,  0.0335],\n",
       "                      [ 0.0028,  0.0178, -0.0586,  ...,  0.0696,  0.0850,  0.0405],\n",
       "                      [ 0.0565, -0.0255,  0.0151,  ...,  0.0234,  0.0507,  0.0801]])),\n",
       "             ('embedder.layers.0.2.module.0.bias',\n",
       "              tensor([ 0.0174,  0.0789, -0.0554, -0.0061, -0.0507, -0.0437, -0.0189,  0.0838,\n",
       "                       0.0685,  0.0233,  0.0224,  0.0120,  0.0046,  0.0286,  0.0353,  0.0267,\n",
       "                      -0.0782,  0.0513,  0.0609,  0.0401,  0.0756, -0.0167, -0.0098,  0.0245,\n",
       "                       0.0319,  0.0764,  0.0476, -0.0677,  0.0388, -0.0686, -0.0159, -0.0498,\n",
       "                       0.0122,  0.0400,  0.0027, -0.0028,  0.0660,  0.0424,  0.0339, -0.0150,\n",
       "                      -0.0210,  0.0660, -0.0735, -0.0210,  0.0697, -0.0805, -0.0305,  0.0213,\n",
       "                      -0.0770, -0.0680,  0.0824, -0.0165, -0.0536, -0.0417, -0.0056, -0.0004,\n",
       "                       0.0230,  0.0405,  0.0427, -0.0343,  0.0110, -0.0095,  0.0404, -0.0693,\n",
       "                       0.0782, -0.0852, -0.0268,  0.0663,  0.0368, -0.0725, -0.0878,  0.0301,\n",
       "                       0.0323, -0.0258, -0.0877, -0.0845, -0.0373, -0.0088, -0.0352, -0.0387,\n",
       "                      -0.0524,  0.0704,  0.0765,  0.0352,  0.0159,  0.0229,  0.0121,  0.0836,\n",
       "                      -0.0876,  0.0196,  0.0632, -0.0321, -0.0731, -0.0114,  0.0372,  0.0055,\n",
       "                      -0.0807,  0.0790,  0.0868, -0.0710,  0.0324, -0.0532, -0.0056, -0.0570,\n",
       "                       0.0731,  0.0154,  0.0015, -0.0771,  0.0309, -0.0228,  0.0380,  0.0309,\n",
       "                      -0.0792, -0.0241, -0.0099,  0.0420, -0.0219, -0.0127,  0.0280, -0.0185,\n",
       "                      -0.0663, -0.0607, -0.0708, -0.0689,  0.0320, -0.0505, -0.0426, -0.0002,\n",
       "                      -0.0436,  0.0274, -0.0162, -0.0516,  0.0512, -0.0604,  0.0280,  0.0231,\n",
       "                      -0.0712, -0.0102,  0.0258,  0.0788, -0.0732,  0.0013,  0.0610,  0.0358,\n",
       "                       0.0754,  0.0730, -0.0604,  0.0396,  0.0565,  0.0656,  0.0784,  0.0263,\n",
       "                       0.0207,  0.0206,  0.0815,  0.0511, -0.0198,  0.0526, -0.0476,  0.0156,\n",
       "                       0.0863, -0.0727,  0.0287, -0.0231,  0.0488, -0.0354,  0.0804, -0.0680,\n",
       "                      -0.0025,  0.0275, -0.0830,  0.0145, -0.0326,  0.0655, -0.0706,  0.0141,\n",
       "                      -0.0714, -0.0454,  0.0495,  0.0039, -0.0703,  0.0551,  0.0632,  0.0791,\n",
       "                      -0.0188,  0.0840,  0.0152,  0.0825,  0.0703, -0.0459,  0.0061,  0.0727,\n",
       "                      -0.0168,  0.0350,  0.0527, -0.0329,  0.0829, -0.0260, -0.0540, -0.0634,\n",
       "                      -0.0725,  0.0772, -0.0815,  0.0480, -0.0485, -0.0367, -0.0295, -0.0646,\n",
       "                       0.0150,  0.0785,  0.0542, -0.0607, -0.0203,  0.0120,  0.0193, -0.0810,\n",
       "                      -0.0504,  0.0643,  0.0824,  0.0686,  0.0175,  0.0811, -0.0528,  0.0440,\n",
       "                      -0.0350,  0.0734, -0.0724, -0.0177, -0.0101,  0.0378,  0.0445,  0.0644,\n",
       "                      -0.0804, -0.0631,  0.0304,  0.0472,  0.0445,  0.0763, -0.0444,  0.0136,\n",
       "                      -0.0513,  0.0349, -0.0372, -0.0767,  0.0862,  0.0805,  0.0417,  0.0117,\n",
       "                       0.0759,  0.0009, -0.0463,  0.0398, -0.0205,  0.0291, -0.0718,  0.0095,\n",
       "                       0.0774,  0.0577, -0.0801,  0.0457,  0.0036,  0.0176,  0.0859,  0.0686,\n",
       "                       0.0202,  0.0575, -0.0170,  0.0713,  0.0704,  0.0511,  0.0854,  0.0440,\n",
       "                      -0.0543, -0.0496,  0.0351, -0.0271, -0.0597, -0.0177, -0.0286, -0.0511,\n",
       "                      -0.0069,  0.0699, -0.0194, -0.0637, -0.0229, -0.0009,  0.0582,  0.0444,\n",
       "                      -0.0112,  0.0194, -0.0583,  0.0672, -0.0473,  0.0631,  0.0262, -0.0139,\n",
       "                       0.0610, -0.0361,  0.0578, -0.0625, -0.0862,  0.0371, -0.0859,  0.0569,\n",
       "                      -0.0523,  0.0279, -0.0240, -0.0439, -0.0702, -0.0686, -0.0037, -0.0103,\n",
       "                       0.0121,  0.0793,  0.0537,  0.0147, -0.0094,  0.0153,  0.0151, -0.0706,\n",
       "                      -0.0100,  0.0428, -0.0336,  0.0517, -0.0538, -0.0114,  0.0664,  0.0650,\n",
       "                      -0.0548, -0.0290,  0.0582,  0.0605, -0.0251, -0.0132, -0.0496,  0.0624,\n",
       "                      -0.0033, -0.0836,  0.0532,  0.0270, -0.0395,  0.0748, -0.0591,  0.0378,\n",
       "                      -0.0782, -0.0048,  0.0757, -0.0400, -0.0151,  0.0263,  0.0561,  0.0705,\n",
       "                       0.0716,  0.0701,  0.0870, -0.0479, -0.0145,  0.0018,  0.0401, -0.0309,\n",
       "                       0.0695,  0.0192, -0.0106,  0.0050, -0.0145, -0.0794,  0.0556, -0.0597,\n",
       "                      -0.0494,  0.0804,  0.0627, -0.0795, -0.0722,  0.0644, -0.0456, -0.0033,\n",
       "                       0.0340, -0.0193, -0.0514,  0.0753,  0.0810, -0.0154,  0.0741, -0.0511,\n",
       "                      -0.0788,  0.0181, -0.0332, -0.0455,  0.0207, -0.0858, -0.0621, -0.0163,\n",
       "                       0.0054, -0.0353, -0.0141,  0.0704,  0.0577,  0.0614,  0.0286, -0.0036,\n",
       "                      -0.0722,  0.0103,  0.0164,  0.0754,  0.0691, -0.0493, -0.0375,  0.0517,\n",
       "                       0.0344,  0.0286, -0.0823,  0.0409,  0.0323, -0.0525, -0.0108, -0.0011,\n",
       "                      -0.0124, -0.0332,  0.0224, -0.0382, -0.0062, -0.0476, -0.0478,  0.0780,\n",
       "                       0.0391,  0.0832,  0.0462,  0.0786, -0.0274,  0.0686, -0.0533,  0.0118,\n",
       "                       0.0337,  0.0855, -0.0263, -0.0547, -0.0697, -0.0530, -0.0305,  0.0048,\n",
       "                       0.0354,  0.0383,  0.0472, -0.0570,  0.0599,  0.0774,  0.0239, -0.0101,\n",
       "                       0.0882, -0.0224, -0.0304,  0.0595,  0.0780,  0.0103,  0.0191, -0.0819,\n",
       "                       0.0236,  0.0384,  0.0625, -0.0534,  0.0413, -0.0675, -0.0496,  0.0613,\n",
       "                      -0.0123, -0.0629, -0.0173,  0.0277, -0.0711, -0.0703, -0.0841, -0.0351,\n",
       "                       0.0181, -0.0019, -0.0335, -0.0364,  0.0194,  0.0591,  0.0393, -0.0822,\n",
       "                      -0.0357, -0.0478, -0.0171,  0.0682, -0.0443, -0.0756, -0.0784, -0.0546,\n",
       "                      -0.0660,  0.0492, -0.0208,  0.0836,  0.0606, -0.0038,  0.0301, -0.0432,\n",
       "                       0.0465, -0.0666,  0.0264,  0.0330,  0.0217,  0.0633, -0.0716, -0.0709,\n",
       "                      -0.0602,  0.0846, -0.0691, -0.0489, -0.0091, -0.0284, -0.0552,  0.0753])),\n",
       "             ('embedder.layers.0.2.module.2.weight',\n",
       "              tensor([[ 1.0771e-02, -1.2316e-05,  3.9334e-02,  ..., -6.7641e-03,\n",
       "                        6.4156e-03,  1.2187e-02],\n",
       "                      [ 3.5643e-02, -4.1013e-02,  3.0565e-02,  ..., -2.9612e-02,\n",
       "                       -6.1033e-03,  3.4981e-02],\n",
       "                      [ 7.4331e-03,  1.1598e-02, -1.4244e-02,  ...,  2.8066e-02,\n",
       "                       -2.2313e-02, -7.8578e-03],\n",
       "                      ...,\n",
       "                      [-1.8325e-02, -6.9867e-04, -4.3229e-02,  ...,  1.8593e-02,\n",
       "                       -2.3944e-02,  1.1261e-02],\n",
       "                      [-1.8718e-02, -3.8141e-03,  1.2875e-02,  ..., -1.0940e-02,\n",
       "                        1.4453e-02,  5.7539e-03],\n",
       "                      [ 2.8269e-02, -1.2435e-02, -2.6074e-02,  ..., -4.2052e-02,\n",
       "                        3.9147e-02, -2.2675e-02]])),\n",
       "             ('embedder.layers.0.2.module.2.bias',\n",
       "              tensor([-0.0324,  0.0250, -0.0277,  0.0319, -0.0120,  0.0391, -0.0258,  0.0102,\n",
       "                       0.0051,  0.0061,  0.0285,  0.0280, -0.0316,  0.0170, -0.0418,  0.0279,\n",
       "                      -0.0113, -0.0111, -0.0377, -0.0198,  0.0046, -0.0216, -0.0025, -0.0220,\n",
       "                      -0.0034,  0.0223, -0.0276,  0.0404, -0.0286,  0.0200, -0.0268,  0.0082,\n",
       "                       0.0398, -0.0411,  0.0191, -0.0318, -0.0030,  0.0298, -0.0355, -0.0440,\n",
       "                      -0.0245,  0.0335, -0.0333,  0.0164,  0.0377, -0.0175,  0.0006, -0.0435,\n",
       "                       0.0178,  0.0036,  0.0324,  0.0130, -0.0053,  0.0215, -0.0302,  0.0069,\n",
       "                      -0.0316, -0.0204,  0.0282, -0.0335, -0.0329,  0.0004,  0.0185, -0.0064,\n",
       "                       0.0339, -0.0038,  0.0273, -0.0303,  0.0119, -0.0212, -0.0230, -0.0412,\n",
       "                       0.0021,  0.0236,  0.0099, -0.0337, -0.0099, -0.0104,  0.0320,  0.0151,\n",
       "                      -0.0168,  0.0367,  0.0440, -0.0244,  0.0133,  0.0090,  0.0144, -0.0359,\n",
       "                      -0.0412, -0.0261, -0.0392, -0.0233, -0.0346,  0.0332, -0.0201,  0.0292,\n",
       "                      -0.0053, -0.0096,  0.0049, -0.0433, -0.0029,  0.0220, -0.0019,  0.0085,\n",
       "                       0.0442, -0.0319, -0.0116, -0.0370, -0.0140,  0.0170, -0.0213, -0.0331,\n",
       "                       0.0314,  0.0415,  0.0028, -0.0394,  0.0003, -0.0107, -0.0336, -0.0159,\n",
       "                      -0.0100,  0.0015, -0.0254,  0.0343, -0.0436,  0.0198,  0.0253, -0.0160])),\n",
       "             ('embedder.layers.0.3.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder.layers.0.3.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder.layers.0.3.normalizer.running_mean',\n",
       "              tensor([ 1.8492e-02,  2.7114e-02,  1.6456e-02, -1.1442e-02,  1.5526e-02,\n",
       "                      -1.2852e-02, -1.7175e-03,  1.1247e-02, -1.2164e-02, -1.6548e-02,\n",
       "                       9.6137e-03,  2.4489e-03,  2.0379e-03, -8.2028e-03, -2.9108e-02,\n",
       "                       1.1333e-02,  5.6311e-03, -1.5371e-03, -6.0470e-03, -6.4569e-04,\n",
       "                       1.0720e-02, -1.7998e-02,  1.5996e-02, -2.4217e-02,  2.2163e-02,\n",
       "                      -1.9638e-03,  3.5762e-03, -1.0056e-02,  1.2495e-03, -1.3101e-03,\n",
       "                       1.7482e-02, -8.7250e-03, -1.5965e-03,  5.8392e-03, -1.7763e-03,\n",
       "                       9.2296e-03,  2.3823e-02,  1.6730e-02, -2.2349e-02,  1.6891e-03,\n",
       "                      -8.8815e-03,  2.4448e-02,  8.0087e-04, -1.1371e-02, -1.1842e-02,\n",
       "                      -7.2264e-03, -1.4254e-02, -3.0371e-03, -1.1784e-02,  3.1082e-03,\n",
       "                      -2.8252e-02,  4.4120e-03, -3.3489e-02, -4.4195e-03,  1.2806e-03,\n",
       "                      -1.8078e-02,  3.1067e-03, -2.7274e-02,  5.7603e-03, -6.3983e-03,\n",
       "                       1.2338e-02, -7.6020e-03,  2.3747e-02, -2.9027e-02,  3.9595e-03,\n",
       "                      -1.3330e-02,  2.7231e-02, -1.3085e-02,  2.8002e-05, -5.5526e-03,\n",
       "                      -9.4716e-03,  1.0580e-02, -9.5627e-03, -6.2127e-03,  1.0622e-02,\n",
       "                       1.5639e-02, -6.8571e-03,  9.6371e-04,  2.5174e-02,  2.6774e-02,\n",
       "                      -5.6637e-03,  2.1415e-02,  3.5052e-03, -1.8234e-02, -8.2609e-03,\n",
       "                       5.7257e-02, -2.6636e-02, -5.2669e-03,  8.8863e-03, -2.9376e-02,\n",
       "                      -2.1367e-02, -5.9489e-03, -1.7416e-02, -2.9328e-04,  1.9812e-02,\n",
       "                       4.1024e-03, -5.4106e-03,  7.1352e-03,  8.9019e-03, -2.4620e-02,\n",
       "                       7.9326e-03, -1.7315e-02, -1.6604e-02,  1.7487e-03,  4.8834e-03,\n",
       "                      -1.8793e-02,  5.6774e-03, -1.1068e-02, -6.1434e-03,  3.4107e-03,\n",
       "                       1.1792e-02, -1.2312e-02, -8.1772e-03, -1.9542e-02, -2.5484e-02,\n",
       "                       1.2975e-02, -1.6842e-03,  2.9814e-02, -1.8673e-03, -5.3053e-03,\n",
       "                       6.8968e-03,  3.5808e-03, -1.7048e-02,  1.1986e-02,  1.3824e-03,\n",
       "                      -1.8287e-03,  5.1461e-03, -2.9127e-02])),\n",
       "             ('embedder.layers.0.3.normalizer.running_var',\n",
       "              tensor([1.0223, 1.0279, 0.9996, 0.9835, 1.0039, 0.9997, 1.0278, 1.0386, 0.9885,\n",
       "                      1.0328, 1.0261, 1.0009, 0.9946, 0.9890, 0.9914, 1.0249, 1.0093, 1.0269,\n",
       "                      0.9990, 1.0020, 0.9998, 1.0008, 1.0015, 0.9998, 1.0190, 1.0294, 0.9690,\n",
       "                      1.0173, 1.0324, 1.0440, 0.9976, 1.0139, 1.0244, 1.0230, 0.9891, 0.9865,\n",
       "                      0.9515, 1.0142, 1.0406, 1.0086, 1.0089, 0.9731, 1.0355, 1.0075, 1.0390,\n",
       "                      0.9877, 1.0511, 0.9856, 1.0044, 0.9981, 0.9738, 0.9897, 1.0136, 0.9975,\n",
       "                      0.9956, 1.0602, 0.9548, 0.9627, 1.0102, 1.0024, 0.9798, 1.0619, 0.9960,\n",
       "                      1.0018, 1.0676, 1.0010, 1.0575, 0.9876, 0.9964, 1.0277, 0.9871, 0.9980,\n",
       "                      0.9663, 1.0130, 0.9906, 1.0181, 1.0063, 1.0111, 1.0044, 0.9984, 1.0007,\n",
       "                      1.0167, 0.9662, 1.0142, 0.9821, 1.0114, 1.0231, 0.9989, 1.0134, 1.0092,\n",
       "                      1.0099, 1.0035, 1.0035, 1.0232, 1.0049, 1.0348, 0.9988, 1.0366, 0.9710,\n",
       "                      1.0016, 1.0395, 1.0431, 0.9922, 0.9622, 0.9983, 1.0269, 0.9788, 1.0273,\n",
       "                      0.9715, 1.0438, 1.0376, 0.9846, 1.0110, 1.0178, 1.0343, 1.0081, 1.0185,\n",
       "                      1.0106, 1.0329, 1.0026, 0.9983, 0.9980, 1.0310, 1.0069, 0.9880, 0.9945,\n",
       "                      0.9951, 0.9899])),\n",
       "             ('embedder.layers.0.3.normalizer.num_batches_tracked', tensor(1)),\n",
       "             ('embedder.layers.1.0.module.W_query',\n",
       "              tensor([[[ 0.1197,  0.1010,  0.2402,  ...,  0.0786,  0.0653, -0.1984],\n",
       "                       [ 0.0798,  0.1098, -0.0638,  ..., -0.0568,  0.0113, -0.1024],\n",
       "                       [ 0.0343,  0.1329,  0.2009,  ...,  0.1580,  0.2205, -0.0152],\n",
       "                       ...,\n",
       "                       [-0.1340, -0.1439, -0.1410,  ...,  0.2094, -0.2416,  0.1532],\n",
       "                       [ 0.2131, -0.1045,  0.0645,  ..., -0.1428,  0.1333, -0.2355],\n",
       "                       [-0.1122,  0.1800,  0.0620,  ...,  0.2361, -0.1980, -0.0275]],\n",
       "              \n",
       "                      [[-0.0984, -0.2466,  0.1178,  ...,  0.1384, -0.0070,  0.2461],\n",
       "                       [ 0.0331, -0.1037, -0.1072,  ...,  0.1626,  0.2171, -0.0422],\n",
       "                       [-0.0292, -0.2313, -0.0590,  ..., -0.0919,  0.0370, -0.1511],\n",
       "                       ...,\n",
       "                       [-0.0754,  0.1068, -0.0929,  ...,  0.2258,  0.1306, -0.0711],\n",
       "                       [-0.0873, -0.1891,  0.2283,  ..., -0.1672,  0.0698,  0.1646],\n",
       "                       [-0.1163,  0.2156, -0.2057,  ..., -0.0825,  0.0564, -0.1773]],\n",
       "              \n",
       "                      [[ 0.2485,  0.2158, -0.1630,  ...,  0.2270,  0.2234,  0.0218],\n",
       "                       [-0.2082, -0.2170,  0.0451,  ..., -0.0727, -0.1430,  0.0629],\n",
       "                       [-0.1074, -0.1614, -0.0339,  ...,  0.0085,  0.2258, -0.0304],\n",
       "                       ...,\n",
       "                       [ 0.0563, -0.0048, -0.1249,  ..., -0.2278, -0.0035,  0.0008],\n",
       "                       [ 0.0199, -0.1221, -0.0863,  ...,  0.2219, -0.2098,  0.0797],\n",
       "                       [-0.0453, -0.0978, -0.0511,  ..., -0.0061,  0.2393,  0.0352]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1122,  0.0936,  0.0333,  ..., -0.1399, -0.2352, -0.1211],\n",
       "                       [ 0.0748,  0.1277,  0.0055,  ...,  0.0514, -0.1449,  0.2160],\n",
       "                       [ 0.1262, -0.1465, -0.0525,  ..., -0.1548, -0.1996,  0.0347],\n",
       "                       ...,\n",
       "                       [-0.2058, -0.1515, -0.0273,  ...,  0.0039,  0.0398,  0.0683],\n",
       "                       [ 0.0556,  0.0061,  0.1029,  ..., -0.1502,  0.1363, -0.1975],\n",
       "                       [ 0.0479, -0.2229,  0.0317,  ..., -0.0039,  0.2085,  0.1970]],\n",
       "              \n",
       "                      [[-0.2417,  0.1568, -0.1567,  ...,  0.1723,  0.1166, -0.2299],\n",
       "                       [-0.0026, -0.0828, -0.1089,  ..., -0.2485,  0.1288, -0.0740],\n",
       "                       [-0.0519, -0.2218, -0.0872,  ...,  0.1271,  0.2070,  0.0171],\n",
       "                       ...,\n",
       "                       [ 0.1986,  0.0657,  0.0350,  ...,  0.0658, -0.1650,  0.1313],\n",
       "                       [-0.0726, -0.2008, -0.0746,  ...,  0.0529, -0.2290, -0.0869],\n",
       "                       [ 0.1278,  0.0707,  0.1120,  ..., -0.0743, -0.2071, -0.0028]],\n",
       "              \n",
       "                      [[ 0.0599, -0.1420,  0.0738,  ...,  0.1407, -0.0374, -0.2439],\n",
       "                       [-0.2242,  0.0640, -0.1299,  ...,  0.0204, -0.0915, -0.1288],\n",
       "                       [ 0.0498,  0.1073, -0.0206,  ..., -0.0388, -0.0757,  0.0295],\n",
       "                       ...,\n",
       "                       [ 0.0122, -0.0327, -0.1614,  ...,  0.0985,  0.1011,  0.0520],\n",
       "                       [-0.1294,  0.0224, -0.1435,  ...,  0.1525, -0.1842,  0.2284],\n",
       "                       [-0.0803,  0.1235,  0.1710,  ...,  0.1774,  0.2227, -0.1001]]])),\n",
       "             ('embedder.layers.1.0.module.W_key',\n",
       "              tensor([[[-0.1396, -0.0991,  0.0904,  ...,  0.2497, -0.1949, -0.0750],\n",
       "                       [-0.1376, -0.1568, -0.0072,  ...,  0.0368, -0.0651,  0.0326],\n",
       "                       [-0.0093, -0.2294,  0.0825,  ...,  0.1192, -0.0454, -0.1720],\n",
       "                       ...,\n",
       "                       [ 0.0804, -0.1921, -0.1402,  ..., -0.2322, -0.2153, -0.0852],\n",
       "                       [ 0.0701, -0.0154, -0.0262,  ...,  0.1564, -0.2352, -0.0113],\n",
       "                       [ 0.2350, -0.1954,  0.1355,  ..., -0.0437,  0.2311, -0.0360]],\n",
       "              \n",
       "                      [[-0.0668,  0.2291, -0.0036,  ..., -0.0689,  0.0377, -0.0255],\n",
       "                       [ 0.1726, -0.1396, -0.1704,  ...,  0.1022, -0.0178, -0.1776],\n",
       "                       [-0.1170, -0.0024, -0.1680,  ..., -0.1395,  0.2348, -0.1584],\n",
       "                       ...,\n",
       "                       [ 0.1279, -0.1107, -0.1072,  ..., -0.0191, -0.2242, -0.2434],\n",
       "                       [-0.1303, -0.0201,  0.1024,  ...,  0.0112, -0.1715, -0.2087],\n",
       "                       [ 0.2027,  0.1183, -0.2204,  ..., -0.1654, -0.1769, -0.1407]],\n",
       "              \n",
       "                      [[-0.0226,  0.1381, -0.1088,  ...,  0.2080, -0.1824,  0.0528],\n",
       "                       [ 0.1935,  0.0019, -0.0935,  ..., -0.2196,  0.2064,  0.2171],\n",
       "                       [-0.2387, -0.0971,  0.0424,  ...,  0.1276, -0.2038,  0.1097],\n",
       "                       ...,\n",
       "                       [ 0.2488, -0.0316,  0.0075,  ...,  0.1980, -0.0788, -0.0261],\n",
       "                       [-0.1102,  0.0131, -0.2093,  ..., -0.0800,  0.0139,  0.1089],\n",
       "                       [-0.1460, -0.2325,  0.2161,  ..., -0.1748,  0.0522,  0.0684]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1270, -0.0309, -0.1242,  ...,  0.1827,  0.0168,  0.0088],\n",
       "                       [-0.1128, -0.2167, -0.0375,  ...,  0.0057, -0.2185, -0.2073],\n",
       "                       [-0.0848,  0.0714, -0.2142,  ..., -0.1432,  0.2427, -0.0574],\n",
       "                       ...,\n",
       "                       [-0.2446, -0.0393,  0.1951,  ...,  0.0847, -0.0024, -0.2432],\n",
       "                       [-0.1320,  0.0543, -0.1078,  ...,  0.1061, -0.2424, -0.1345],\n",
       "                       [-0.1237, -0.1716, -0.1136,  ..., -0.0089,  0.2428,  0.1587]],\n",
       "              \n",
       "                      [[-0.1401,  0.2185,  0.1482,  ...,  0.0392, -0.0061,  0.1066],\n",
       "                       [ 0.0148, -0.1607, -0.2482,  ...,  0.2092,  0.1689, -0.1156],\n",
       "                       [ 0.2391, -0.1814,  0.0645,  ..., -0.1465, -0.2305, -0.0973],\n",
       "                       ...,\n",
       "                       [ 0.0565, -0.2198,  0.2028,  ..., -0.1023, -0.2179,  0.0833],\n",
       "                       [ 0.2175, -0.2470,  0.1775,  ..., -0.0419, -0.2193,  0.2102],\n",
       "                       [-0.1333,  0.0825,  0.2481,  ..., -0.0176, -0.2422, -0.1944]],\n",
       "              \n",
       "                      [[ 0.1497, -0.0245, -0.2405,  ..., -0.0028, -0.0624, -0.0085],\n",
       "                       [-0.1815, -0.1308, -0.2248,  ...,  0.1323, -0.0387, -0.0076],\n",
       "                       [-0.0568,  0.0663, -0.1941,  ...,  0.0599, -0.1120,  0.2140],\n",
       "                       ...,\n",
       "                       [-0.2341,  0.0679,  0.1058,  ...,  0.0716,  0.2023,  0.1996],\n",
       "                       [ 0.1086, -0.0745,  0.0177,  ...,  0.1051, -0.0108, -0.1606],\n",
       "                       [ 0.2179, -0.1850,  0.1242,  ...,  0.1672, -0.0610,  0.0075]]])),\n",
       "             ('embedder.layers.1.0.module.W_val',\n",
       "              tensor([[[-5.5634e-02, -1.8161e-01,  1.7010e-01,  ..., -9.0622e-02,\n",
       "                         6.7210e-02,  2.2098e-04],\n",
       "                       [ 1.2003e-02,  1.6607e-02,  5.5173e-02,  ..., -1.8048e-01,\n",
       "                        -3.2162e-02, -1.3394e-01],\n",
       "                       [ 5.3776e-02,  4.8688e-02,  2.1778e-02,  ..., -1.9638e-01,\n",
       "                        -7.5569e-02,  1.4674e-01],\n",
       "                       ...,\n",
       "                       [-2.1600e-02,  1.8220e-01,  1.0455e-01,  ...,  6.8524e-03,\n",
       "                         1.0211e-01, -2.0412e-01],\n",
       "                       [ 1.6596e-02, -7.9915e-02, -1.4447e-01,  ..., -1.4619e-01,\n",
       "                        -1.3805e-02, -1.1600e-01],\n",
       "                       [ 1.9841e-01,  1.6931e-01, -1.1174e-01,  ..., -9.2018e-04,\n",
       "                        -1.8734e-01, -1.7232e-01]],\n",
       "              \n",
       "                      [[ 3.3384e-02, -9.6092e-02, -5.1219e-02,  ...,  1.0037e-01,\n",
       "                         1.9034e-01,  1.1978e-01],\n",
       "                       [-1.0975e-03, -5.2057e-02,  7.3624e-02,  ..., -1.5748e-01,\n",
       "                        -1.4917e-01, -3.0897e-02],\n",
       "                       [ 4.2107e-02, -1.9813e-01, -8.0812e-02,  ...,  8.1008e-02,\n",
       "                        -1.4982e-01, -1.4454e-01],\n",
       "                       ...,\n",
       "                       [ 2.1662e-01, -1.9727e-01,  1.9714e-01,  ..., -1.1730e-01,\n",
       "                         8.7831e-02,  9.6086e-02],\n",
       "                       [ 1.6702e-01, -1.5425e-01,  2.0406e-01,  ...,  2.3807e-01,\n",
       "                         1.8461e-01, -7.9116e-02],\n",
       "                       [-2.0999e-01,  1.8620e-01, -1.9791e-02,  ..., -1.0786e-02,\n",
       "                        -5.0372e-02, -1.6989e-02]],\n",
       "              \n",
       "                      [[ 1.3157e-02,  2.0712e-01, -9.7865e-02,  ..., -1.1813e-01,\n",
       "                         1.4227e-01,  7.5256e-02],\n",
       "                       [ 4.4949e-02, -6.3440e-02,  1.3134e-01,  ...,  6.0571e-02,\n",
       "                        -7.6274e-02,  9.9241e-02],\n",
       "                       [ 2.1810e-01, -1.4397e-01,  5.8256e-02,  ..., -5.8417e-03,\n",
       "                        -2.1904e-01, -4.9526e-03],\n",
       "                       ...,\n",
       "                       [-2.1527e-01, -1.1967e-01, -9.2843e-02,  ...,  1.2253e-01,\n",
       "                         2.4204e-01, -2.2231e-02],\n",
       "                       [-9.6670e-02, -6.0332e-02,  5.0573e-02,  ..., -4.0163e-02,\n",
       "                        -1.9326e-01, -1.7306e-01],\n",
       "                       [ 2.4603e-01, -1.9247e-01,  1.9728e-01,  ...,  2.5420e-03,\n",
       "                         1.4127e-01,  1.6265e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-1.5686e-01, -2.2334e-01,  6.8174e-02,  ..., -1.4690e-01,\n",
       "                         1.9141e-01, -2.8412e-02],\n",
       "                       [ 2.4189e-01,  1.3201e-01, -1.6389e-01,  ...,  2.0033e-01,\n",
       "                         1.9957e-01, -1.5913e-02],\n",
       "                       [-1.8663e-01,  2.1140e-01, -2.4504e-01,  ...,  2.2714e-01,\n",
       "                        -2.0340e-02,  1.4867e-01],\n",
       "                       ...,\n",
       "                       [ 1.5241e-01, -1.7544e-01, -1.1532e-01,  ..., -1.4095e-01,\n",
       "                         1.5802e-01, -1.5486e-01],\n",
       "                       [-9.7555e-02, -1.6847e-01, -2.4067e-01,  ...,  6.1419e-02,\n",
       "                        -2.4041e-01,  1.6690e-01],\n",
       "                       [ 2.4290e-01,  8.1075e-02,  2.3977e-01,  ...,  1.3579e-01,\n",
       "                         6.3195e-02,  2.0601e-01]],\n",
       "              \n",
       "                      [[-8.3010e-02, -1.9336e-01,  1.3978e-01,  ...,  6.4470e-02,\n",
       "                        -5.9009e-03, -1.3715e-01],\n",
       "                       [-2.2617e-01, -2.4681e-01, -3.5042e-02,  ...,  4.7838e-02,\n",
       "                        -9.1356e-02,  1.7318e-01],\n",
       "                       [-7.2651e-02,  1.9928e-01,  2.4324e-01,  ...,  1.3764e-01,\n",
       "                         6.8364e-02, -2.4547e-01],\n",
       "                       ...,\n",
       "                       [-1.3134e-01,  2.2047e-02,  2.2889e-01,  ...,  4.1152e-02,\n",
       "                        -9.1454e-02,  1.2481e-02],\n",
       "                       [ 3.7454e-02,  1.4552e-01, -2.4176e-02,  ...,  1.1026e-01,\n",
       "                        -4.7201e-02, -1.9995e-01],\n",
       "                       [-1.5593e-01, -1.8550e-01,  2.2284e-01,  ...,  1.1622e-01,\n",
       "                         2.2765e-01,  1.8065e-01]],\n",
       "              \n",
       "                      [[ 7.7186e-02,  1.3070e-01,  1.7893e-01,  ...,  7.1637e-02,\n",
       "                         2.2578e-01, -2.2823e-01],\n",
       "                       [ 6.5916e-03, -5.4389e-03, -1.8543e-01,  ..., -9.0040e-03,\n",
       "                        -9.1291e-02,  1.5577e-01],\n",
       "                       [-9.4298e-02, -1.3958e-01,  6.3083e-02,  ...,  2.2537e-01,\n",
       "                        -1.1400e-01, -1.9405e-01],\n",
       "                       ...,\n",
       "                       [-3.4311e-02, -1.8771e-01, -6.6422e-03,  ..., -1.9650e-01,\n",
       "                         1.7307e-01,  2.2786e-01],\n",
       "                       [ 1.6235e-01, -1.4337e-01,  1.0048e-01,  ..., -8.4536e-02,\n",
       "                         2.4280e-01,  1.4836e-01],\n",
       "                       [ 2.1608e-01, -2.2519e-01,  1.7043e-01,  ..., -1.4490e-01,\n",
       "                         2.4179e-01, -2.0883e-01]]])),\n",
       "             ('embedder.layers.1.0.module.W_out',\n",
       "              tensor([[[-0.0227,  0.0509,  0.0653,  ..., -0.0385, -0.0370, -0.0728],\n",
       "                       [-0.0560,  0.0098, -0.0194,  ...,  0.0450,  0.0023,  0.0300],\n",
       "                       [ 0.0126,  0.0146, -0.0176,  ...,  0.0671, -0.0781, -0.0872],\n",
       "                       ...,\n",
       "                       [-0.0589,  0.0741, -0.0612,  ..., -0.0420,  0.0496, -0.0345],\n",
       "                       [ 0.0647,  0.0206,  0.0199,  ...,  0.0025,  0.0662,  0.0752],\n",
       "                       [ 0.0523, -0.0037,  0.0316,  ...,  0.0726, -0.0857,  0.0089]],\n",
       "              \n",
       "                      [[-0.0064, -0.0617,  0.0807,  ..., -0.0016, -0.0456, -0.0175],\n",
       "                       [ 0.0486, -0.0860, -0.0813,  ...,  0.0106,  0.0174,  0.0174],\n",
       "                       [-0.0603, -0.0463, -0.0324,  ..., -0.0263,  0.0646, -0.0195],\n",
       "                       ...,\n",
       "                       [-0.0415, -0.0117, -0.0843,  ..., -0.0293, -0.0258, -0.0298],\n",
       "                       [ 0.0705, -0.0653, -0.0648,  ...,  0.0070,  0.0139,  0.0617],\n",
       "                       [ 0.0857, -0.0745,  0.0777,  ..., -0.0393, -0.0415,  0.0390]],\n",
       "              \n",
       "                      [[-0.0025,  0.0157, -0.0317,  ..., -0.0229, -0.0599, -0.0654],\n",
       "                       [ 0.0776,  0.0452, -0.0695,  ...,  0.0837, -0.0050, -0.0448],\n",
       "                       [-0.0764,  0.0608,  0.0371,  ..., -0.0407, -0.0237,  0.0675],\n",
       "                       ...,\n",
       "                       [-0.0119,  0.0654,  0.0515,  ..., -0.0456, -0.0713, -0.0295],\n",
       "                       [-0.0763,  0.0208,  0.0521,  ..., -0.0401, -0.0397,  0.0738],\n",
       "                       [ 0.0801, -0.0706,  0.0678,  ..., -0.0406,  0.0424, -0.0819]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0688, -0.0812, -0.0286,  ...,  0.0763,  0.0322,  0.0257],\n",
       "                       [ 0.0381,  0.0025, -0.0487,  ...,  0.0192,  0.0576,  0.0386],\n",
       "                       [ 0.0756,  0.0362, -0.0285,  ...,  0.0396, -0.0297, -0.0021],\n",
       "                       ...,\n",
       "                       [-0.0481,  0.0561, -0.0146,  ...,  0.0381, -0.0482, -0.0748],\n",
       "                       [-0.0199, -0.0381, -0.0125,  ..., -0.0474,  0.0047, -0.0175],\n",
       "                       [-0.0601,  0.0253, -0.0168,  ...,  0.0387,  0.0719, -0.0174]],\n",
       "              \n",
       "                      [[-0.0526, -0.0006, -0.0135,  ..., -0.0049, -0.0507,  0.0120],\n",
       "                       [ 0.0684, -0.0124,  0.0801,  ..., -0.0677,  0.0004,  0.0461],\n",
       "                       [ 0.0867, -0.0131,  0.0633,  ..., -0.0715,  0.0802, -0.0073],\n",
       "                       ...,\n",
       "                       [-0.0652, -0.0639,  0.0337,  ..., -0.0050, -0.0601,  0.0342],\n",
       "                       [-0.0475,  0.0837,  0.0002,  ...,  0.0668,  0.0696, -0.0717],\n",
       "                       [ 0.0620,  0.0108,  0.0511,  ...,  0.0524,  0.0157, -0.0803]],\n",
       "              \n",
       "                      [[-0.0514, -0.0675,  0.0259,  ..., -0.0829,  0.0375, -0.0312],\n",
       "                       [ 0.0639,  0.0326, -0.0749,  ..., -0.0129, -0.0516, -0.0526],\n",
       "                       [-0.0066,  0.0588,  0.0240,  ...,  0.0319, -0.0515, -0.0710],\n",
       "                       ...,\n",
       "                       [-0.0603, -0.0624,  0.0498,  ..., -0.0058,  0.0308,  0.0739],\n",
       "                       [ 0.0084, -0.0517,  0.0525,  ..., -0.0802, -0.0438, -0.0287],\n",
       "                       [ 0.0555,  0.0056,  0.0707,  ..., -0.0464,  0.0836,  0.0649]]])),\n",
       "             ('embedder.layers.1.1.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder.layers.1.1.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder.layers.1.1.normalizer.running_mean',\n",
       "              tensor([ 1.1596e-02,  3.9873e-03,  1.1360e-02, -2.9103e-03, -3.7525e-03,\n",
       "                      -4.7526e-03, -8.9535e-03, -6.6945e-03,  2.8791e-04,  8.9377e-03,\n",
       "                       2.3508e-03, -8.7796e-03,  9.6296e-03,  1.7411e-03, -2.3237e-03,\n",
       "                      -9.9721e-05,  6.6275e-03, -3.1628e-03, -7.5139e-04,  1.2319e-02,\n",
       "                       2.4139e-02, -1.4879e-03, -1.0055e-02,  4.8928e-03,  9.2456e-03,\n",
       "                       1.3521e-03,  1.5014e-02, -1.1116e-02, -4.3966e-03, -9.6140e-03,\n",
       "                       2.5117e-03, -1.8690e-02,  2.0580e-03, -6.5748e-03,  1.4306e-03,\n",
       "                       6.7581e-04,  6.6436e-03, -2.1453e-03, -7.5094e-03,  1.5401e-03,\n",
       "                       3.7098e-03,  8.5480e-03, -4.1407e-03,  1.7383e-04,  5.5346e-03,\n",
       "                      -1.3850e-03, -5.7402e-03,  2.1693e-02,  5.2485e-03, -1.0908e-02,\n",
       "                      -1.4267e-02, -1.5819e-03,  5.3080e-03, -4.6140e-03, -8.2125e-05,\n",
       "                      -9.4653e-03, -3.1408e-03,  7.1640e-03, -3.7609e-03, -2.3252e-03,\n",
       "                       6.4201e-04,  5.8388e-03,  5.1643e-03,  1.6880e-02, -9.7864e-03,\n",
       "                      -1.2105e-02, -4.5141e-03,  4.5660e-03, -1.3301e-02, -5.0012e-03,\n",
       "                      -5.9384e-03, -9.0542e-03,  1.5106e-03, -1.0595e-03, -2.6425e-03,\n",
       "                       8.3428e-03,  7.5772e-04, -5.9027e-03,  8.4716e-03, -1.7105e-03,\n",
       "                       4.9354e-04, -1.0944e-02, -6.5223e-03, -2.0411e-02, -1.1801e-03,\n",
       "                      -1.7539e-02,  5.6952e-03,  1.0824e-02, -7.5586e-03,  1.1686e-02,\n",
       "                       2.0374e-02, -1.2638e-02, -6.4704e-03,  4.4289e-03, -1.6780e-03,\n",
       "                       8.6623e-04, -8.1963e-03,  9.2972e-03, -8.6873e-03,  8.0429e-03,\n",
       "                       1.6301e-03, -1.6406e-03, -7.5208e-03, -2.9604e-03, -6.4509e-03,\n",
       "                      -3.9271e-04,  7.8087e-03, -3.8235e-04, -1.5451e-02, -3.5331e-03,\n",
       "                      -6.1159e-03,  8.1702e-05, -5.9490e-03, -1.3589e-03, -8.5893e-03,\n",
       "                      -1.7383e-02,  1.8520e-02, -5.7646e-04, -1.2162e-02, -1.5969e-02,\n",
       "                       2.6144e-03, -6.2127e-03, -3.9380e-03, -3.4589e-03,  1.0905e-03,\n",
       "                      -1.4060e-03, -8.7331e-04,  7.4584e-03])),\n",
       "             ('embedder.layers.1.1.normalizer.running_var',\n",
       "              tensor([1.3196, 1.1400, 0.9826, 1.3346, 0.9857, 0.9795, 1.0804, 1.2027, 1.0238,\n",
       "                      1.0095, 1.2329, 1.0140, 1.2791, 1.2549, 1.1282, 1.0285, 1.0301, 1.2714,\n",
       "                      0.9895, 1.0228, 1.5539, 1.2791, 0.9563, 0.9940, 1.2819, 1.1136, 1.2628,\n",
       "                      1.1218, 0.9280, 1.2429, 0.9678, 1.0860, 1.4082, 1.1103, 1.4355, 0.9454,\n",
       "                      1.2048, 0.9796, 0.9718, 1.5337, 0.9685, 1.0525, 1.0305, 1.2271, 1.1369,\n",
       "                      1.0176, 0.9598, 1.0736, 1.2697, 1.1184, 1.0078, 1.1541, 1.0623, 1.2494,\n",
       "                      1.0011, 1.0713, 1.0367, 1.0992, 0.9181, 1.2501, 1.0420, 1.3372, 0.9405,\n",
       "                      1.1594, 1.1728, 0.9481, 0.9469, 1.1147, 1.1470, 1.1424, 1.4812, 0.9930,\n",
       "                      1.3101, 1.1698, 1.0263, 0.9932, 1.0593, 0.9710, 0.9435, 1.3378, 1.0939,\n",
       "                      1.2585, 1.0638, 0.9738, 1.3407, 1.1260, 0.9900, 1.3140, 0.9495, 1.0290,\n",
       "                      0.9765, 1.0961, 1.3173, 0.9413, 1.2207, 0.9515, 1.0360, 1.2403, 1.0435,\n",
       "                      1.1777, 1.2045, 1.3528, 1.1732, 1.3455, 1.0521, 0.9588, 1.3704, 0.9358,\n",
       "                      1.4021, 1.0040, 1.1102, 1.4019, 1.0193, 1.3934, 1.1223, 1.0496, 1.4023,\n",
       "                      1.2109, 1.1131, 1.1209, 0.9857, 1.1298, 1.1493, 0.9521, 1.0151, 1.6909,\n",
       "                      1.0315, 0.9111])),\n",
       "             ('embedder.layers.1.1.normalizer.num_batches_tracked', tensor(1)),\n",
       "             ('embedder.layers.1.2.module.0.weight',\n",
       "              tensor([[-0.0180,  0.0620, -0.0003,  ..., -0.0736,  0.0044, -0.0716],\n",
       "                      [-0.0880, -0.0709, -0.0567,  ...,  0.0852,  0.0416,  0.0241],\n",
       "                      [-0.0297, -0.0690,  0.0788,  ..., -0.0123, -0.0496, -0.0007],\n",
       "                      ...,\n",
       "                      [ 0.0277, -0.0341,  0.0708,  ...,  0.0436, -0.0241, -0.0156],\n",
       "                      [-0.0525, -0.0435,  0.0124,  ..., -0.0581, -0.0461, -0.0673],\n",
       "                      [ 0.0598,  0.0030, -0.0668,  ...,  0.0380,  0.0192,  0.0524]])),\n",
       "             ('embedder.layers.1.2.module.0.bias',\n",
       "              tensor([-0.0529, -0.0433,  0.0622,  0.0730,  0.0605, -0.0481,  0.0483,  0.0539,\n",
       "                      -0.0485, -0.0697,  0.0764,  0.0789, -0.0492, -0.0137,  0.0822, -0.0649,\n",
       "                      -0.0797,  0.0803,  0.0341,  0.0156,  0.0509,  0.0214,  0.0398,  0.0119,\n",
       "                      -0.0561, -0.0441, -0.0531,  0.0639, -0.0770, -0.0335, -0.0069, -0.0028,\n",
       "                       0.0098,  0.0154, -0.0078,  0.0803, -0.0696,  0.0538,  0.0140, -0.0194,\n",
       "                      -0.0648,  0.0499, -0.0697,  0.0849, -0.0622,  0.0849, -0.0325, -0.0109,\n",
       "                       0.0407,  0.0132,  0.0781,  0.0330,  0.0216,  0.0710,  0.0587, -0.0248,\n",
       "                       0.0550,  0.0295,  0.0071, -0.0658,  0.0371, -0.0633, -0.0016,  0.0553,\n",
       "                       0.0860,  0.0270, -0.0189, -0.0383, -0.0629, -0.0329, -0.0444, -0.0077,\n",
       "                       0.0695,  0.0543, -0.0619,  0.0245,  0.0392,  0.0410, -0.0577, -0.0112,\n",
       "                      -0.0551,  0.0878, -0.0436, -0.0468, -0.0742, -0.0571, -0.0663,  0.0753,\n",
       "                       0.0043,  0.0322, -0.0690,  0.0834,  0.0483,  0.0845, -0.0675,  0.0736,\n",
       "                       0.0813, -0.0422, -0.0536, -0.0859,  0.0605,  0.0728, -0.0814, -0.0399,\n",
       "                       0.0191, -0.0558,  0.0694,  0.0589,  0.0483, -0.0084,  0.0168,  0.0855,\n",
       "                       0.0389,  0.0563, -0.0438,  0.0813,  0.0612,  0.0735,  0.0085,  0.0110,\n",
       "                      -0.0291,  0.0626,  0.0875, -0.0655, -0.0527,  0.0636,  0.0818,  0.0571,\n",
       "                      -0.0202, -0.0777,  0.0570, -0.0558, -0.0262, -0.0084, -0.0534, -0.0426,\n",
       "                       0.0188,  0.0275, -0.0131,  0.0178, -0.0866,  0.0322, -0.0580,  0.0102,\n",
       "                       0.0273, -0.0271,  0.0330,  0.0614, -0.0222,  0.0559, -0.0725,  0.0330,\n",
       "                       0.0416,  0.0672,  0.0804,  0.0219, -0.0375,  0.0674,  0.0053, -0.0794,\n",
       "                      -0.0791, -0.0751,  0.0398,  0.0788, -0.0727,  0.0460, -0.0244,  0.0649,\n",
       "                      -0.0349, -0.0224,  0.0101,  0.0160,  0.0571,  0.0758, -0.0872, -0.0594,\n",
       "                      -0.0502, -0.0065,  0.0451, -0.0541,  0.0858,  0.0003,  0.0374,  0.0797,\n",
       "                       0.0596,  0.0256,  0.0817, -0.0549, -0.0530, -0.0651, -0.0710,  0.0044,\n",
       "                       0.0453, -0.0851, -0.0407,  0.0315, -0.0107, -0.0182,  0.0849, -0.0200,\n",
       "                      -0.0236, -0.0672, -0.0253, -0.0085, -0.0211,  0.0757, -0.0669,  0.0303,\n",
       "                      -0.0511, -0.0235, -0.0739, -0.0877,  0.0249, -0.0113, -0.0730, -0.0327,\n",
       "                      -0.0250,  0.0074,  0.0760, -0.0477,  0.0533,  0.0753,  0.0476, -0.0196,\n",
       "                      -0.0462,  0.0355, -0.0135, -0.0039,  0.0721,  0.0140,  0.0010,  0.0032,\n",
       "                       0.0093, -0.0572,  0.0150,  0.0499, -0.0611,  0.0463, -0.0145,  0.0094,\n",
       "                      -0.0360,  0.0325, -0.0725, -0.0651, -0.0850,  0.0396,  0.0728, -0.0530,\n",
       "                       0.0135,  0.0636,  0.0515, -0.0273,  0.0585, -0.0810,  0.0464,  0.0731,\n",
       "                      -0.0382, -0.0765, -0.0022,  0.0304,  0.0631, -0.0666, -0.0102,  0.0655,\n",
       "                      -0.0176,  0.0222, -0.0365,  0.0482,  0.0805,  0.0292,  0.0623,  0.0092,\n",
       "                      -0.0011, -0.0726,  0.0147,  0.0196,  0.0476, -0.0406,  0.0450, -0.0265,\n",
       "                      -0.0132, -0.0870,  0.0801, -0.0264, -0.0758, -0.0444,  0.0030, -0.0174,\n",
       "                      -0.0270,  0.0790,  0.0591,  0.0193,  0.0144, -0.0706, -0.0161, -0.0248,\n",
       "                       0.0533,  0.0236,  0.0564, -0.0258, -0.0468,  0.0022,  0.0013,  0.0544,\n",
       "                       0.0239,  0.0809, -0.0397, -0.0474,  0.0558, -0.0673,  0.0747, -0.0820,\n",
       "                       0.0468, -0.0569, -0.0250, -0.0861,  0.0142, -0.0101, -0.0246, -0.0324,\n",
       "                      -0.0600, -0.0056, -0.0161,  0.0396, -0.0542,  0.0415, -0.0413, -0.0546,\n",
       "                       0.0834,  0.0190, -0.0850,  0.0247,  0.0612, -0.0125, -0.0311,  0.0439,\n",
       "                       0.0339,  0.0104,  0.0073, -0.0614, -0.0858, -0.0696,  0.0117, -0.0845,\n",
       "                      -0.0159, -0.0223,  0.0868,  0.0107, -0.0255, -0.0246, -0.0223, -0.0690,\n",
       "                      -0.0664, -0.0652, -0.0747,  0.0830,  0.0640,  0.0071,  0.0550,  0.0327,\n",
       "                      -0.0282,  0.0095,  0.0578,  0.0382,  0.0546,  0.0829, -0.0669,  0.0174,\n",
       "                       0.0835, -0.0827, -0.0687, -0.0543, -0.0579,  0.0010,  0.0561, -0.0841,\n",
       "                      -0.0439,  0.0373, -0.0770, -0.0531,  0.0080,  0.0864,  0.0789, -0.0124,\n",
       "                       0.0627, -0.0604,  0.0673,  0.0615, -0.0795, -0.0157, -0.0236,  0.0800,\n",
       "                       0.0176, -0.0679,  0.0719,  0.0098,  0.0473, -0.0147, -0.0241,  0.0270,\n",
       "                      -0.0772, -0.0591, -0.0536, -0.0023, -0.0157, -0.0066,  0.0862, -0.0350,\n",
       "                       0.0651, -0.0488,  0.0098,  0.0689,  0.0163, -0.0765,  0.0826,  0.0878,\n",
       "                       0.0782, -0.0397,  0.0280, -0.0002,  0.0246, -0.0063, -0.0763,  0.0850,\n",
       "                      -0.0254, -0.0493, -0.0104,  0.0285, -0.0777,  0.0233, -0.0821,  0.0304,\n",
       "                       0.0140,  0.0499, -0.0861, -0.0866,  0.0596, -0.0237, -0.0244, -0.0346,\n",
       "                       0.0881,  0.0254, -0.0676,  0.0418,  0.0804, -0.0514,  0.0638, -0.0780,\n",
       "                      -0.0640, -0.0387,  0.0075, -0.0409, -0.0364,  0.0117,  0.0098, -0.0337,\n",
       "                       0.0819, -0.0067,  0.0227, -0.0697, -0.0647, -0.0187, -0.0734, -0.0116,\n",
       "                       0.0865, -0.0543,  0.0040, -0.0406,  0.0518,  0.0560, -0.0835, -0.0111,\n",
       "                      -0.0384,  0.0386,  0.0037, -0.0374,  0.0200, -0.0485, -0.0519, -0.0327,\n",
       "                      -0.0473,  0.0836, -0.0684, -0.0547, -0.0589,  0.0051, -0.0806,  0.0682,\n",
       "                       0.0428, -0.0758, -0.0621,  0.0643, -0.0080, -0.0818, -0.0043,  0.0688,\n",
       "                       0.0513,  0.0337,  0.0654,  0.0242,  0.0037, -0.0830,  0.0711,  0.0760,\n",
       "                       0.0500,  0.0448,  0.0472, -0.0484,  0.0649, -0.0011,  0.0810,  0.0702])),\n",
       "             ('embedder.layers.1.2.module.2.weight',\n",
       "              tensor([[ 0.0151,  0.0147, -0.0359,  ...,  0.0226,  0.0024,  0.0163],\n",
       "                      [ 0.0165,  0.0355,  0.0392,  ..., -0.0317, -0.0204, -0.0258],\n",
       "                      [-0.0114, -0.0315, -0.0405,  ..., -0.0110, -0.0088,  0.0199],\n",
       "                      ...,\n",
       "                      [-0.0173, -0.0015,  0.0373,  ..., -0.0431,  0.0296,  0.0157],\n",
       "                      [-0.0258, -0.0163,  0.0378,  ...,  0.0120, -0.0431,  0.0330],\n",
       "                      [ 0.0151,  0.0202, -0.0085,  ...,  0.0190,  0.0201,  0.0389]])),\n",
       "             ('embedder.layers.1.2.module.2.bias',\n",
       "              tensor([ 0.0400,  0.0341,  0.0171, -0.0182,  0.0301,  0.0015,  0.0409,  0.0416,\n",
       "                       0.0311,  0.0439, -0.0108,  0.0238, -0.0014,  0.0346, -0.0158,  0.0189,\n",
       "                       0.0033, -0.0235, -0.0336, -0.0222,  0.0221, -0.0070, -0.0289, -0.0358,\n",
       "                       0.0378,  0.0143, -0.0305, -0.0018, -0.0204,  0.0213,  0.0339,  0.0397,\n",
       "                      -0.0278, -0.0400, -0.0339, -0.0011, -0.0005,  0.0141, -0.0002,  0.0115,\n",
       "                      -0.0303, -0.0406,  0.0106,  0.0004, -0.0414,  0.0078,  0.0381, -0.0322,\n",
       "                       0.0388, -0.0214,  0.0140,  0.0093, -0.0251,  0.0084,  0.0121,  0.0170,\n",
       "                      -0.0165, -0.0010, -0.0004, -0.0177, -0.0213, -0.0172, -0.0287,  0.0420,\n",
       "                       0.0044,  0.0039, -0.0083, -0.0361,  0.0203, -0.0194, -0.0390,  0.0415,\n",
       "                       0.0271, -0.0261,  0.0300, -0.0248,  0.0331, -0.0212, -0.0440,  0.0082,\n",
       "                      -0.0021,  0.0095, -0.0404, -0.0208, -0.0214, -0.0018, -0.0158, -0.0245,\n",
       "                       0.0288, -0.0294,  0.0285, -0.0062,  0.0287,  0.0071,  0.0211,  0.0053,\n",
       "                       0.0382, -0.0347,  0.0402,  0.0341, -0.0188,  0.0406, -0.0058,  0.0004,\n",
       "                      -0.0021,  0.0014, -0.0207,  0.0400, -0.0409, -0.0141, -0.0085,  0.0275,\n",
       "                       0.0123,  0.0333,  0.0331,  0.0107,  0.0281, -0.0379, -0.0238, -0.0171,\n",
       "                      -0.0437,  0.0093,  0.0263,  0.0040,  0.0409, -0.0431, -0.0281, -0.0192])),\n",
       "             ('embedder.layers.1.3.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder.layers.1.3.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder.layers.1.3.normalizer.running_mean',\n",
       "              tensor([ 0.0193,  0.0088, -0.0031, -0.0019, -0.0001,  0.0099,  0.0094, -0.0154,\n",
       "                      -0.0254, -0.0012,  0.0072,  0.0168,  0.0261,  0.0091, -0.0258,  0.0156,\n",
       "                       0.0159, -0.0164,  0.0014,  0.0100,  0.0139, -0.0056,  0.0276,  0.0069,\n",
       "                       0.0130,  0.0081,  0.0016, -0.0082, -0.0029, -0.0113, -0.0063, -0.0055,\n",
       "                       0.0132,  0.0188, -0.0039, -0.0105, -0.0134,  0.0147, -0.0026, -0.0077,\n",
       "                      -0.0290,  0.0045,  0.0126, -0.0002,  0.0082,  0.0267,  0.0194,  0.0371,\n",
       "                       0.0152, -0.0158, -0.0006,  0.0166, -0.0058, -0.0382, -0.0082, -0.0014,\n",
       "                       0.0250, -0.0130,  0.0099,  0.0076,  0.0066, -0.0059, -0.0110,  0.0047,\n",
       "                       0.0062, -0.0067,  0.0123,  0.0141, -0.0065, -0.0047, -0.0036,  0.0080,\n",
       "                       0.0038, -0.0144,  0.0169,  0.0001, -0.0065,  0.0073,  0.0101,  0.0165,\n",
       "                       0.0140, -0.0122,  0.0115, -0.0156, -0.0162, -0.0285, -0.0069,  0.0140,\n",
       "                       0.0235, -0.0220,  0.0014, -0.0252,  0.0245, -0.0158, -0.0161,  0.0010,\n",
       "                       0.0020, -0.0133, -0.0114,  0.0134, -0.0127,  0.0107, -0.0017, -0.0005,\n",
       "                      -0.0012, -0.0015,  0.0184,  0.0252, -0.0322, -0.0278,  0.0236,  0.0117,\n",
       "                      -0.0264, -0.0248, -0.0073,  0.0038, -0.0321, -0.0069, -0.0022,  0.0227,\n",
       "                       0.0002,  0.0276, -0.0106, -0.0115,  0.0179, -0.0119, -0.0019,  0.0269])),\n",
       "             ('embedder.layers.1.3.normalizer.running_var',\n",
       "              tensor([1.0224, 1.0120, 0.9913, 0.9714, 1.0145, 1.0210, 1.0071, 0.9671, 1.0124,\n",
       "                      0.9947, 1.0003, 1.0030, 1.0058, 1.0204, 1.0219, 0.9900, 0.9974, 1.0395,\n",
       "                      1.0204, 1.0053, 0.9805, 0.9957, 1.0120, 1.0372, 1.0202, 0.9825, 1.0327,\n",
       "                      1.0324, 1.0116, 0.9809, 0.9936, 1.0251, 1.0483, 1.0082, 1.0100, 1.0198,\n",
       "                      1.0240, 1.0126, 0.9646, 1.0091, 1.0416, 0.9914, 1.0287, 0.9965, 1.0150,\n",
       "                      1.0280, 1.0160, 1.0508, 1.0152, 0.9823, 0.9884, 0.9872, 0.9922, 0.9875,\n",
       "                      1.0014, 1.0001, 1.0334, 1.0198, 1.0065, 1.0381, 1.0027, 1.0000, 0.9916,\n",
       "                      1.0137, 0.9831, 1.0010, 1.0075, 0.9912, 1.0292, 0.9844, 1.0001, 1.0484,\n",
       "                      0.9922, 1.0109, 1.0263, 0.9868, 1.0149, 1.0006, 0.9897, 0.9703, 0.9922,\n",
       "                      1.0066, 0.9986, 1.0007, 0.9917, 1.0239, 0.9875, 1.0330, 1.0219, 1.0250,\n",
       "                      0.9952, 1.0271, 0.9843, 1.0105, 1.0044, 1.0044, 1.0080, 0.9919, 0.9682,\n",
       "                      1.0159, 0.9845, 0.9827, 1.0255, 1.0225, 0.9985, 0.9964, 1.0039, 0.9997,\n",
       "                      1.0353, 0.9996, 0.9833, 0.9794, 0.9959, 0.9930, 1.0258, 1.0160, 1.0148,\n",
       "                      1.0513, 1.0445, 1.0300, 1.0177, 1.0227, 0.9841, 1.0288, 1.0088, 0.9742,\n",
       "                      1.0035, 1.0069])),\n",
       "             ('embedder.layers.1.3.normalizer.num_batches_tracked', tensor(1)),\n",
       "             ('embedder.layers.2.0.module.W_query',\n",
       "              tensor([[[ 0.2324,  0.1158, -0.1640,  ..., -0.1472,  0.1043, -0.1790],\n",
       "                       [-0.0436,  0.1313,  0.0232,  ...,  0.0820, -0.1261, -0.0842],\n",
       "                       [ 0.1962,  0.2010, -0.1411,  ..., -0.2120, -0.1636, -0.1843],\n",
       "                       ...,\n",
       "                       [-0.1276, -0.2066,  0.0973,  ...,  0.2230,  0.1269, -0.0993],\n",
       "                       [-0.1344, -0.0698,  0.1674,  ..., -0.0017, -0.1560, -0.1195],\n",
       "                       [ 0.0256,  0.2219, -0.2367,  ...,  0.1524, -0.0784, -0.1215]],\n",
       "              \n",
       "                      [[ 0.0836,  0.1605,  0.0623,  ..., -0.0043,  0.1233,  0.1004],\n",
       "                       [-0.2497,  0.0725,  0.1871,  ...,  0.0900, -0.1117,  0.2232],\n",
       "                       [ 0.2010,  0.1057, -0.0270,  ..., -0.1660, -0.1150,  0.2442],\n",
       "                       ...,\n",
       "                       [ 0.2403, -0.0106,  0.1504,  ...,  0.1895,  0.1121, -0.1723],\n",
       "                       [ 0.2413,  0.0728, -0.1536,  ..., -0.1581,  0.1476,  0.1915],\n",
       "                       [ 0.1504,  0.2495, -0.0317,  ..., -0.2256, -0.1680,  0.2046]],\n",
       "              \n",
       "                      [[ 0.1182,  0.0747,  0.1249,  ...,  0.2093, -0.0356, -0.2409],\n",
       "                       [ 0.1791, -0.0122, -0.1283,  ..., -0.1612,  0.2416, -0.1319],\n",
       "                       [ 0.0287,  0.2128, -0.2253,  ...,  0.0097,  0.1831,  0.0198],\n",
       "                       ...,\n",
       "                       [ 0.0386,  0.0845, -0.2199,  ...,  0.2123, -0.1971,  0.0444],\n",
       "                       [ 0.0985, -0.1667, -0.0043,  ..., -0.2265, -0.1885, -0.1117],\n",
       "                       [-0.0167,  0.0846, -0.0760,  ...,  0.2180,  0.1299, -0.2409]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1763, -0.0392, -0.1049,  ...,  0.0831,  0.0689,  0.1129],\n",
       "                       [ 0.0424,  0.2248,  0.0621,  ..., -0.2181, -0.1468,  0.2342],\n",
       "                       [ 0.1456, -0.0154,  0.2471,  ..., -0.0425,  0.0018,  0.0114],\n",
       "                       ...,\n",
       "                       [-0.0069,  0.1555, -0.1808,  ...,  0.0333, -0.2361, -0.1813],\n",
       "                       [ 0.1177, -0.0122,  0.0143,  ...,  0.1626,  0.1400,  0.2136],\n",
       "                       [-0.2201, -0.0207,  0.0360,  ..., -0.1706, -0.0767,  0.1862]],\n",
       "              \n",
       "                      [[-0.0997,  0.1726, -0.0141,  ..., -0.1072,  0.0484,  0.0662],\n",
       "                       [ 0.0906, -0.1561, -0.1720,  ...,  0.0857, -0.0667, -0.0072],\n",
       "                       [-0.1389, -0.0939, -0.2442,  ..., -0.1547,  0.1314,  0.0498],\n",
       "                       ...,\n",
       "                       [-0.1384,  0.0896, -0.0229,  ...,  0.1675,  0.0029, -0.1796],\n",
       "                       [ 0.0604,  0.0316,  0.2124,  ...,  0.0087,  0.0227, -0.0546],\n",
       "                       [-0.1114, -0.1358,  0.0411,  ..., -0.1141, -0.0225,  0.0707]],\n",
       "              \n",
       "                      [[-0.1763, -0.0396, -0.0562,  ...,  0.1166, -0.2467,  0.1737],\n",
       "                       [-0.2468,  0.1571,  0.0573,  ..., -0.0823,  0.1822,  0.2191],\n",
       "                       [ 0.0271, -0.2179, -0.0302,  ...,  0.2351, -0.0176,  0.1248],\n",
       "                       ...,\n",
       "                       [-0.2467,  0.0687,  0.1045,  ..., -0.0343, -0.1113, -0.0679],\n",
       "                       [ 0.0050, -0.1100, -0.2219,  ...,  0.1150,  0.0849,  0.2500],\n",
       "                       [ 0.1733,  0.1810, -0.1644,  ..., -0.0430, -0.2123,  0.1817]]])),\n",
       "             ('embedder.layers.2.0.module.W_key',\n",
       "              tensor([[[ 0.1138,  0.2121,  0.1584,  ...,  0.0461, -0.0672, -0.1862],\n",
       "                       [-0.2157,  0.0199,  0.1357,  ...,  0.0349,  0.0351,  0.1795],\n",
       "                       [-0.0715,  0.0515, -0.0243,  ..., -0.2135,  0.2198, -0.0749],\n",
       "                       ...,\n",
       "                       [ 0.1882,  0.0703, -0.2445,  ..., -0.0356,  0.1042,  0.2385],\n",
       "                       [-0.2249, -0.0918,  0.1797,  ...,  0.0557,  0.1769, -0.1863],\n",
       "                       [-0.1071, -0.2431, -0.2466,  ..., -0.2062, -0.0720,  0.0547]],\n",
       "              \n",
       "                      [[-0.1281,  0.0009, -0.1072,  ...,  0.0971,  0.1942, -0.0278],\n",
       "                       [ 0.1766, -0.2223, -0.0973,  ..., -0.0537, -0.1886, -0.1011],\n",
       "                       [-0.1434, -0.1164,  0.2330,  ..., -0.1396, -0.0538,  0.1236],\n",
       "                       ...,\n",
       "                       [ 0.0252,  0.1990, -0.1376,  ...,  0.0735, -0.0704,  0.1646],\n",
       "                       [ 0.0052, -0.1961,  0.1567,  ...,  0.0019,  0.1939,  0.1387],\n",
       "                       [-0.0213, -0.1279,  0.0708,  ..., -0.1321, -0.2482, -0.1336]],\n",
       "              \n",
       "                      [[-0.1158, -0.0607, -0.0054,  ..., -0.0052, -0.1295, -0.1155],\n",
       "                       [-0.0330,  0.0405, -0.1469,  ...,  0.0488, -0.1089, -0.0220],\n",
       "                       [ 0.2404,  0.0868, -0.0620,  ..., -0.0626, -0.1865,  0.0012],\n",
       "                       ...,\n",
       "                       [ 0.2385,  0.1545,  0.0434,  ...,  0.0361,  0.1081,  0.2073],\n",
       "                       [-0.1850,  0.1064,  0.1775,  ..., -0.0077,  0.2204,  0.0324],\n",
       "                       [ 0.0853,  0.1883,  0.2333,  ...,  0.2349, -0.2384, -0.2105]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2357,  0.1369, -0.0251,  ...,  0.0020,  0.1509,  0.1671],\n",
       "                       [ 0.1534, -0.0958, -0.2445,  ...,  0.1512,  0.0876, -0.1488],\n",
       "                       [ 0.1987, -0.0837, -0.2161,  ...,  0.1524,  0.1674,  0.1935],\n",
       "                       ...,\n",
       "                       [-0.1307, -0.1181,  0.0025,  ...,  0.1560,  0.2208,  0.0945],\n",
       "                       [-0.2146,  0.1216,  0.0361,  ...,  0.0236, -0.2286,  0.2280],\n",
       "                       [ 0.2062,  0.1263, -0.0500,  ...,  0.2275, -0.0015, -0.1483]],\n",
       "              \n",
       "                      [[ 0.1718,  0.0805,  0.1708,  ...,  0.0529, -0.1286, -0.1206],\n",
       "                       [ 0.0099, -0.0899,  0.0713,  ...,  0.0544, -0.1450, -0.1602],\n",
       "                       [-0.0663,  0.1270,  0.2086,  ...,  0.0405, -0.0153, -0.0831],\n",
       "                       ...,\n",
       "                       [-0.0645,  0.2021, -0.1847,  ..., -0.2394, -0.1715, -0.2398],\n",
       "                       [-0.1636,  0.0107,  0.2036,  ...,  0.1278, -0.2112, -0.1249],\n",
       "                       [ 0.0911,  0.0019,  0.2411,  ..., -0.0554, -0.1698,  0.2154]],\n",
       "              \n",
       "                      [[ 0.0614,  0.1987,  0.1269,  ..., -0.1494,  0.0703,  0.1216],\n",
       "                       [ 0.0360, -0.0165,  0.0097,  ..., -0.1201, -0.0689,  0.0825],\n",
       "                       [-0.0377, -0.2267, -0.2438,  ..., -0.1912,  0.1910,  0.2441],\n",
       "                       ...,\n",
       "                       [ 0.1212, -0.0900,  0.0756,  ..., -0.0318, -0.2005,  0.2276],\n",
       "                       [-0.0572,  0.2422,  0.0380,  ..., -0.1765, -0.2039,  0.0983],\n",
       "                       [ 0.1271, -0.0106, -0.0746,  ..., -0.0894,  0.1341, -0.0150]]])),\n",
       "             ('embedder.layers.2.0.module.W_val',\n",
       "              tensor([[[ 0.0554, -0.2214, -0.0929,  ..., -0.0442,  0.1416,  0.0414],\n",
       "                       [ 0.1148, -0.1993,  0.1667,  ...,  0.2317,  0.0270, -0.1114],\n",
       "                       [-0.1550,  0.1436, -0.1614,  ...,  0.0797, -0.1176, -0.2297],\n",
       "                       ...,\n",
       "                       [ 0.0206, -0.0688, -0.0093,  ..., -0.2044,  0.1039, -0.1179],\n",
       "                       [-0.1958, -0.2195,  0.0231,  ...,  0.2490,  0.2423, -0.1607],\n",
       "                       [-0.1101,  0.2345,  0.2423,  ..., -0.0549,  0.1996,  0.2408]],\n",
       "              \n",
       "                      [[-0.1912,  0.0172,  0.2373,  ..., -0.0920,  0.1223,  0.0342],\n",
       "                       [ 0.2242,  0.0797,  0.1548,  ..., -0.0259,  0.1935,  0.0870],\n",
       "                       [-0.0825, -0.2349,  0.1842,  ...,  0.0149, -0.1784,  0.0049],\n",
       "                       ...,\n",
       "                       [ 0.1853, -0.0939, -0.1164,  ..., -0.1898,  0.2366, -0.1137],\n",
       "                       [ 0.1240,  0.0568,  0.2102,  ...,  0.1286,  0.0786, -0.0489],\n",
       "                       [ 0.1983, -0.2346,  0.0130,  ...,  0.1224, -0.1994,  0.0269]],\n",
       "              \n",
       "                      [[-0.1243, -0.2476, -0.0408,  ...,  0.0116,  0.1527, -0.1009],\n",
       "                       [ 0.1187, -0.0456, -0.0135,  ..., -0.2378,  0.1022, -0.0515],\n",
       "                       [-0.2243, -0.0902,  0.1605,  ..., -0.1515,  0.0844,  0.0344],\n",
       "                       ...,\n",
       "                       [-0.1962, -0.1976,  0.0019,  ...,  0.0411,  0.2289,  0.1686],\n",
       "                       [ 0.0525,  0.1728,  0.0708,  ...,  0.0887, -0.2464, -0.1903],\n",
       "                       [ 0.0261,  0.0028, -0.1569,  ...,  0.0473, -0.1827, -0.1327]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0885, -0.2300, -0.2347,  ..., -0.0689, -0.2365,  0.0689],\n",
       "                       [-0.1073, -0.2365,  0.1808,  ..., -0.0784, -0.0398, -0.1282],\n",
       "                       [ 0.2490, -0.1251, -0.1901,  ..., -0.1912, -0.2381, -0.0869],\n",
       "                       ...,\n",
       "                       [-0.1063, -0.0051,  0.1336,  ..., -0.1659,  0.1729,  0.0115],\n",
       "                       [-0.2185,  0.2035, -0.0341,  ...,  0.2262,  0.0665,  0.1509],\n",
       "                       [ 0.0458,  0.1611, -0.0978,  ..., -0.1486, -0.1250, -0.1345]],\n",
       "              \n",
       "                      [[ 0.1154,  0.0243, -0.1321,  ...,  0.0445, -0.1051,  0.0112],\n",
       "                       [ 0.1116, -0.1211,  0.0727,  ..., -0.1300, -0.0574,  0.0126],\n",
       "                       [ 0.1527, -0.0986, -0.0056,  ..., -0.0873,  0.1959,  0.1247],\n",
       "                       ...,\n",
       "                       [ 0.2416,  0.0578,  0.1221,  ..., -0.1981, -0.2244,  0.0515],\n",
       "                       [-0.1625,  0.0316,  0.1313,  ...,  0.1347, -0.0837, -0.2057],\n",
       "                       [ 0.1742,  0.1887,  0.0773,  ...,  0.2422, -0.0729, -0.0041]],\n",
       "              \n",
       "                      [[ 0.0930, -0.1861, -0.1135,  ...,  0.2187, -0.1056, -0.2075],\n",
       "                       [ 0.1443,  0.1410, -0.0623,  ..., -0.0548, -0.1305, -0.0387],\n",
       "                       [ 0.0670, -0.1521, -0.1614,  ..., -0.2134, -0.2411,  0.0824],\n",
       "                       ...,\n",
       "                       [-0.1077, -0.0114,  0.0317,  ...,  0.0366,  0.1123,  0.1982],\n",
       "                       [-0.1557, -0.2272, -0.1926,  ...,  0.0408,  0.0062, -0.1433],\n",
       "                       [ 0.0226, -0.1189, -0.0950,  ..., -0.2381, -0.0859, -0.1330]]])),\n",
       "             ('embedder.layers.2.0.module.W_out',\n",
       "              tensor([[[-0.0803,  0.0705,  0.0049,  ...,  0.0333,  0.0033, -0.0565],\n",
       "                       [ 0.0703, -0.0291,  0.0375,  ..., -0.0010, -0.0084,  0.0624],\n",
       "                       [ 0.0716,  0.0095, -0.0458,  ...,  0.0875,  0.0423, -0.0371],\n",
       "                       ...,\n",
       "                       [ 0.0332, -0.0427, -0.0484,  ..., -0.0866,  0.0752,  0.0152],\n",
       "                       [-0.0470, -0.0878, -0.0386,  ...,  0.0035,  0.0401,  0.0225],\n",
       "                       [-0.0648,  0.0059, -0.0652,  ..., -0.0593,  0.0510, -0.0095]],\n",
       "              \n",
       "                      [[-0.0362,  0.0336, -0.0502,  ...,  0.0593,  0.0810, -0.0296],\n",
       "                       [ 0.0183, -0.0774, -0.0691,  ...,  0.0525, -0.0181,  0.0008],\n",
       "                       [ 0.0829, -0.0367,  0.0158,  ...,  0.0527,  0.0207,  0.0514],\n",
       "                       ...,\n",
       "                       [ 0.0015,  0.0476,  0.0379,  ..., -0.0788, -0.0466, -0.0470],\n",
       "                       [ 0.0237,  0.0668, -0.0243,  ..., -0.0883,  0.0734, -0.0647],\n",
       "                       [ 0.0486,  0.0563, -0.0468,  ..., -0.0321, -0.0605, -0.0724]],\n",
       "              \n",
       "                      [[-0.0367,  0.0750, -0.0677,  ...,  0.0649,  0.0537, -0.0071],\n",
       "                       [ 0.0488,  0.0158, -0.0037,  ..., -0.0821,  0.0629,  0.0873],\n",
       "                       [ 0.0170,  0.0822,  0.0594,  ..., -0.0875, -0.0300, -0.0801],\n",
       "                       ...,\n",
       "                       [ 0.0868,  0.0347, -0.0726,  ..., -0.0878,  0.0235,  0.0394],\n",
       "                       [-0.0644,  0.0861,  0.0425,  ...,  0.0561,  0.0561,  0.0457],\n",
       "                       [-0.0864,  0.0397, -0.0310,  ...,  0.0716, -0.0089,  0.0603]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0368, -0.0106, -0.0557,  ...,  0.0458,  0.0555, -0.0706],\n",
       "                       [ 0.0589,  0.0505, -0.0450,  ...,  0.0025, -0.0469, -0.0449],\n",
       "                       [-0.0353,  0.0004, -0.0331,  ..., -0.0204,  0.0541,  0.0729],\n",
       "                       ...,\n",
       "                       [ 0.0852, -0.0528, -0.0143,  ..., -0.0796, -0.0733, -0.0876],\n",
       "                       [ 0.0214, -0.0043, -0.0139,  ...,  0.0472,  0.0351,  0.0594],\n",
       "                       [-0.0603, -0.0219, -0.0699,  ...,  0.0211,  0.0330, -0.0306]],\n",
       "              \n",
       "                      [[-0.0127,  0.0556,  0.0103,  ...,  0.0595, -0.0419,  0.0288],\n",
       "                       [-0.0228, -0.0176,  0.0757,  ..., -0.0385, -0.0380,  0.0404],\n",
       "                       [-0.0818,  0.0731,  0.0601,  ...,  0.0458, -0.0471, -0.0697],\n",
       "                       ...,\n",
       "                       [-0.0472, -0.0476,  0.0684,  ...,  0.0330, -0.0838,  0.0420],\n",
       "                       [-0.0358, -0.0401,  0.0004,  ..., -0.0583,  0.0210,  0.0858],\n",
       "                       [-0.0113, -0.0659, -0.0163,  ..., -0.0878,  0.0839, -0.0320]],\n",
       "              \n",
       "                      [[ 0.0251,  0.0289, -0.0119,  ...,  0.0420, -0.0372,  0.0200],\n",
       "                       [-0.0825, -0.0091, -0.0204,  ..., -0.0288, -0.0391, -0.0004],\n",
       "                       [-0.0306, -0.0122,  0.0034,  ...,  0.0608,  0.0153, -0.0055],\n",
       "                       ...,\n",
       "                       [ 0.0721, -0.0614, -0.0735,  ..., -0.0277,  0.0086,  0.0276],\n",
       "                       [ 0.0009, -0.0414, -0.0296,  ...,  0.0640,  0.0040, -0.0205],\n",
       "                       [ 0.0755, -0.0034,  0.0202,  ..., -0.0516,  0.0863,  0.0799]]])),\n",
       "             ('embedder.layers.2.1.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder.layers.2.1.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder.layers.2.1.normalizer.running_mean',\n",
       "              tensor([-2.5379e-03, -3.6352e-03,  4.3900e-03,  1.1413e-02,  3.5843e-03,\n",
       "                       1.0997e-02, -6.6140e-03, -1.0739e-02,  2.7049e-03,  1.0956e-02,\n",
       "                       5.6524e-03,  3.0436e-02, -1.6414e-02, -3.1873e-03,  2.6278e-03,\n",
       "                      -5.8672e-05,  4.6184e-03,  1.6617e-03, -1.0598e-02, -2.1890e-02,\n",
       "                      -4.5447e-03,  2.0809e-02, -8.5695e-03,  7.1939e-03, -3.6075e-03,\n",
       "                      -1.0197e-02, -6.4155e-03,  1.9896e-02, -3.7548e-03, -3.5037e-04,\n",
       "                      -2.8308e-03,  7.0570e-03, -3.8557e-03, -4.2782e-03,  3.7180e-03,\n",
       "                       7.0926e-03,  4.0333e-03,  7.4079e-03, -2.3298e-02, -8.5784e-03,\n",
       "                      -3.8312e-03, -2.0892e-03,  4.5000e-03, -1.9940e-03, -2.7655e-03,\n",
       "                      -4.5423e-03,  6.1921e-03, -2.3892e-02,  1.5012e-02, -1.2752e-02,\n",
       "                      -5.7034e-03,  1.4287e-04, -3.6846e-04,  1.4529e-02, -8.9936e-03,\n",
       "                       2.0943e-03,  5.4545e-03,  5.8818e-03, -8.1558e-03,  1.6223e-03,\n",
       "                       6.6394e-04,  1.9027e-03,  1.6051e-03,  3.0307e-03, -1.4776e-02,\n",
       "                       1.6131e-02,  7.6993e-03, -5.9653e-03,  1.1495e-02, -7.8436e-03,\n",
       "                      -1.8397e-02,  1.1225e-02,  5.7343e-03,  1.6615e-03, -2.4714e-02,\n",
       "                      -8.4033e-03, -2.4095e-03, -1.6654e-02,  1.6938e-03, -5.6924e-03,\n",
       "                       6.9226e-03, -1.4775e-02,  6.2069e-03, -7.7655e-03,  7.4706e-03,\n",
       "                       1.5575e-02, -1.0196e-02,  2.9405e-04, -1.1219e-02,  1.1780e-02,\n",
       "                      -8.8941e-03,  3.1010e-03,  1.6357e-02,  5.0517e-03,  6.8076e-03,\n",
       "                       2.2677e-02,  3.0057e-04, -4.6140e-03,  1.4424e-02,  1.2329e-02,\n",
       "                      -1.8488e-03, -3.3223e-03,  1.1866e-02,  8.6880e-03, -1.0843e-02,\n",
       "                       1.6706e-02, -7.5252e-03, -5.3985e-03,  8.4832e-03,  1.0040e-02,\n",
       "                       4.7058e-03,  2.3881e-02,  1.1000e-02,  2.4460e-02, -1.5480e-03,\n",
       "                      -2.5207e-02, -1.9855e-03, -7.1274e-03,  1.0205e-02, -5.0109e-03,\n",
       "                      -9.7371e-03,  1.6588e-02, -5.7275e-03, -2.3102e-02,  1.5502e-03,\n",
       "                      -1.1657e-03, -1.7458e-02,  6.7383e-03])),\n",
       "             ('embedder.layers.2.1.normalizer.running_var',\n",
       "              tensor([1.0795, 0.9904, 1.0844, 1.0392, 1.3060, 1.0706, 1.0904, 1.0227, 0.9915,\n",
       "                      0.9403, 0.9652, 1.0263, 1.3375, 1.1551, 0.9960, 1.0130, 1.3084, 1.0349,\n",
       "                      1.0920, 1.0492, 1.0891, 1.1330, 1.0735, 1.0323, 0.9811, 1.1148, 1.0200,\n",
       "                      0.9856, 1.0386, 1.2832, 1.1080, 0.9773, 1.0042, 0.9586, 1.0773, 1.0491,\n",
       "                      1.1101, 1.0133, 1.0906, 0.9707, 1.0731, 1.2368, 0.9240, 1.1208, 1.0177,\n",
       "                      1.0030, 1.1952, 0.9483, 1.0198, 1.0418, 0.9912, 1.0080, 1.1502, 0.9589,\n",
       "                      1.1099, 1.0275, 1.0239, 1.1559, 1.1231, 0.9294, 0.9491, 0.9137, 1.0532,\n",
       "                      0.9926, 1.0868, 1.0517, 0.9654, 1.0540, 1.1022, 1.0129, 1.0417, 0.9926,\n",
       "                      1.0160, 0.9738, 1.0267, 1.0409, 1.0616, 1.2545, 1.0211, 1.0316, 1.0331,\n",
       "                      1.0200, 1.0273, 1.2198, 1.0729, 0.9817, 1.1383, 1.0457, 1.0379, 1.2810,\n",
       "                      0.9735, 1.0043, 0.9323, 0.9711, 1.0191, 0.9864, 1.0217, 0.9295, 1.0292,\n",
       "                      0.9611, 1.1254, 1.0718, 0.9546, 1.0661, 1.1187, 0.9776, 1.0583, 1.0342,\n",
       "                      0.9637, 1.0334, 1.0426, 1.0472, 1.2662, 0.9350, 1.0729, 1.1311, 1.1824,\n",
       "                      1.0817, 0.9906, 1.0836, 1.1776, 0.9730, 0.9338, 0.9879, 1.1819, 1.0118,\n",
       "                      0.9989, 1.0202])),\n",
       "             ('embedder.layers.2.1.normalizer.num_batches_tracked', tensor(1)),\n",
       "             ('embedder.layers.2.2.module.0.weight',\n",
       "              tensor([[ 0.0505, -0.0874, -0.0359,  ..., -0.0035, -0.0393,  0.0716],\n",
       "                      [ 0.0205, -0.0075,  0.0047,  ..., -0.0324,  0.0716, -0.0706],\n",
       "                      [ 0.0010, -0.0768, -0.0227,  ..., -0.0254, -0.0768,  0.0295],\n",
       "                      ...,\n",
       "                      [ 0.0449, -0.0014,  0.0807,  ..., -0.0331,  0.0228,  0.0521],\n",
       "                      [ 0.0192,  0.0348, -0.0551,  ...,  0.0518,  0.0788, -0.0442],\n",
       "                      [ 0.0359,  0.0719, -0.0847,  ...,  0.0179, -0.0124,  0.0286]])),\n",
       "             ('embedder.layers.2.2.module.0.bias',\n",
       "              tensor([-1.7605e-02,  1.3020e-02,  2.7355e-02, -4.2784e-02, -3.8112e-02,\n",
       "                      -7.3530e-02, -5.9398e-03, -6.8379e-02, -4.4868e-02, -3.9267e-02,\n",
       "                       8.1212e-02, -8.5203e-03,  8.1215e-02,  5.6159e-02,  4.4389e-02,\n",
       "                      -4.6835e-02, -7.9719e-02,  1.5814e-02, -3.0034e-03,  2.2998e-02,\n",
       "                       4.6500e-02,  8.2917e-02,  6.2071e-02,  3.5627e-02,  7.5782e-02,\n",
       "                       8.5474e-02,  3.0234e-02,  6.6663e-02, -7.6917e-02, -6.7292e-02,\n",
       "                       9.9439e-03, -7.2946e-02,  6.3462e-02, -8.2666e-02,  7.6840e-04,\n",
       "                       4.0954e-02,  5.0083e-02,  1.2293e-02, -2.4713e-02,  5.9609e-02,\n",
       "                       3.5737e-02, -5.8153e-02, -7.7030e-02, -3.3149e-02, -8.0507e-02,\n",
       "                      -2.1496e-02, -7.5904e-02, -9.1164e-03,  6.7548e-02, -5.4479e-02,\n",
       "                       9.3027e-03,  8.2819e-02, -3.5396e-02,  5.0147e-02,  6.3502e-02,\n",
       "                      -3.2798e-02, -8.6953e-02, -2.9309e-02,  7.1193e-02,  4.1576e-02,\n",
       "                       3.9784e-02, -4.0461e-02, -3.9724e-02, -3.5783e-02, -7.9185e-02,\n",
       "                       2.7876e-02, -6.6410e-02, -7.5319e-02, -7.7105e-02,  7.6258e-02,\n",
       "                      -1.6764e-05, -2.6024e-02,  1.5529e-02,  6.6316e-02, -7.9055e-02,\n",
       "                       5.0606e-02,  6.5060e-02,  5.2172e-02, -6.9436e-02, -5.5527e-02,\n",
       "                      -5.1188e-02, -4.6403e-02, -4.7028e-02,  7.6697e-02,  5.5997e-02,\n",
       "                       2.3591e-02,  3.5871e-02, -4.4245e-02, -6.3252e-02,  8.5637e-02,\n",
       "                      -1.9268e-02,  5.3393e-02, -5.5840e-02,  6.6560e-03,  2.8392e-02,\n",
       "                       7.2834e-02, -4.3565e-02, -7.9775e-02, -4.0136e-02, -7.6308e-02,\n",
       "                       1.5382e-02,  4.4189e-02,  1.3908e-02, -4.5580e-02,  1.7827e-02,\n",
       "                      -4.9894e-02,  1.2876e-03,  6.3466e-02, -2.3197e-02,  3.4746e-02,\n",
       "                      -3.9371e-03,  5.2894e-02,  6.0699e-03,  8.1863e-02,  6.4383e-02,\n",
       "                       6.3514e-02, -1.7541e-02, -3.4383e-02, -2.1318e-02, -2.1865e-02,\n",
       "                      -7.1109e-02, -1.7998e-02,  1.4371e-02, -1.3598e-02, -3.8115e-02,\n",
       "                       3.1881e-02, -6.0781e-02,  3.2759e-02,  8.8425e-03, -4.4263e-02,\n",
       "                       9.0089e-04, -2.6845e-02, -7.2214e-02,  7.2629e-02,  2.2373e-02,\n",
       "                       4.9119e-02,  3.5615e-02, -2.4060e-02, -2.7830e-02,  2.6427e-02,\n",
       "                       3.3453e-02,  1.5787e-03, -6.8565e-02, -6.7288e-02, -4.0486e-02,\n",
       "                      -2.7305e-02, -8.1364e-02,  4.9687e-02,  1.3446e-02,  2.7550e-02,\n",
       "                       4.9675e-02,  1.3447e-02,  4.9844e-03,  6.8725e-02, -6.8073e-02,\n",
       "                      -6.2646e-02, -7.1414e-02,  2.4875e-03,  7.0587e-02,  8.4762e-03,\n",
       "                       5.2690e-02, -7.4961e-02,  9.3025e-03, -4.4418e-02, -9.1627e-03,\n",
       "                       2.5572e-02, -1.9383e-02, -2.6501e-02,  8.3533e-02, -1.7995e-02,\n",
       "                       2.9909e-02,  7.5303e-02,  1.0590e-02, -2.1295e-03, -7.1306e-02,\n",
       "                      -7.1304e-02, -7.2564e-02,  2.3189e-02, -3.3747e-02, -3.1172e-03,\n",
       "                      -2.6346e-03, -6.8880e-03, -7.8084e-03, -4.6641e-02,  1.9364e-03,\n",
       "                      -9.2723e-03,  9.0152e-03, -7.4797e-02, -7.4641e-02,  4.9011e-02,\n",
       "                      -8.2180e-02, -5.6428e-02, -4.0292e-02, -7.4838e-02, -5.9435e-02,\n",
       "                      -7.0333e-02,  5.4593e-02, -3.9368e-02, -1.8335e-02,  4.0550e-02,\n",
       "                       4.4548e-02, -8.0905e-02,  3.2183e-02,  7.1016e-02, -3.9388e-02,\n",
       "                      -3.8043e-02, -2.1560e-02,  3.8431e-02,  1.2083e-02,  2.7525e-02,\n",
       "                       1.3980e-02, -4.0421e-02, -1.0489e-02, -7.3987e-02,  7.0880e-02,\n",
       "                      -3.7082e-02, -1.8823e-02, -2.1979e-02,  3.5741e-02, -7.1489e-02,\n",
       "                       4.7696e-02,  8.1108e-02,  7.0821e-02, -6.4455e-02, -8.1584e-02,\n",
       "                      -1.5870e-02, -6.0051e-02, -3.6775e-03, -2.8116e-02,  1.1954e-02,\n",
       "                       1.5912e-02,  6.5344e-02, -7.7916e-02, -3.8428e-02, -3.4294e-02,\n",
       "                      -4.9371e-02,  5.5328e-02, -2.3243e-02,  3.4288e-02,  7.9051e-02,\n",
       "                       6.7211e-02,  4.2620e-02,  6.7260e-02,  3.7729e-02,  3.5392e-02,\n",
       "                       8.0960e-02, -2.4295e-02,  2.5882e-02,  5.4121e-02,  4.2959e-02,\n",
       "                      -8.2374e-02,  7.0446e-02,  2.6429e-02,  5.2559e-02,  8.2360e-02,\n",
       "                      -4.6595e-02, -6.6458e-02,  8.4138e-02, -8.4984e-02, -3.6615e-02,\n",
       "                      -7.2152e-03, -4.1646e-02, -1.2040e-02, -6.8375e-02,  4.9103e-02,\n",
       "                       2.7448e-02, -5.2832e-02, -8.0763e-03, -1.0017e-02,  6.7367e-02,\n",
       "                      -4.2291e-02, -1.3775e-02, -3.5678e-02,  5.8706e-02,  3.3718e-03,\n",
       "                       2.0694e-02,  6.9857e-02, -6.5551e-02,  2.8448e-02,  6.9927e-02,\n",
       "                       5.6210e-02,  6.6190e-02, -1.9539e-02, -6.3918e-02,  4.6864e-02,\n",
       "                      -4.9290e-02, -7.8450e-02, -7.7521e-03, -1.5636e-02,  5.2391e-02,\n",
       "                      -6.2034e-02,  5.5609e-02,  8.0898e-02,  7.2644e-02,  3.3218e-02,\n",
       "                      -7.0255e-03, -5.1298e-02,  6.1452e-02,  6.1827e-02,  1.8591e-02,\n",
       "                      -8.0001e-02,  9.8132e-03, -1.2987e-02,  3.0397e-02,  3.2626e-02,\n",
       "                      -3.3894e-02, -6.3953e-02, -1.3871e-02, -3.5747e-02,  7.8838e-02,\n",
       "                      -3.0340e-02,  6.0503e-02,  3.6437e-02, -8.8225e-02,  8.5772e-02,\n",
       "                      -1.8491e-02,  7.8646e-02, -3.7562e-02,  4.3671e-02,  4.1710e-02,\n",
       "                      -3.9033e-02,  6.6656e-02, -2.6324e-02, -8.4507e-02,  3.9870e-02,\n",
       "                      -6.9630e-02,  7.6661e-03,  1.3967e-02,  3.5613e-02,  3.7833e-02,\n",
       "                       4.3015e-02,  5.7896e-02,  8.5345e-02, -7.7728e-02,  7.0504e-02,\n",
       "                      -3.1729e-02,  3.6192e-02,  4.2078e-02,  6.7008e-02, -1.2827e-02,\n",
       "                       3.2137e-02, -3.4446e-02,  8.5483e-02,  3.7876e-02, -1.1594e-02,\n",
       "                       3.4811e-02, -1.1706e-03, -1.6815e-02, -6.3398e-02,  1.3975e-02,\n",
       "                      -4.3356e-02, -1.8475e-02, -4.5770e-03,  4.3838e-02, -4.2763e-02,\n",
       "                      -6.1791e-02,  7.5253e-02,  8.8053e-02, -7.8083e-02,  4.0290e-02,\n",
       "                      -8.2560e-02, -8.2953e-02, -7.2142e-02, -8.2102e-02, -4.0499e-02,\n",
       "                       2.5258e-02, -5.0118e-03,  6.8016e-02, -3.2872e-02,  3.2456e-02,\n",
       "                      -7.1321e-02,  3.4242e-02,  2.9563e-02,  7.9751e-02, -8.6741e-02,\n",
       "                       1.9023e-02,  3.5153e-02,  3.9272e-02,  1.3951e-02, -6.2792e-02,\n",
       "                       2.3039e-03, -7.1026e-02,  8.1934e-02,  4.4916e-02, -4.4987e-02,\n",
       "                       7.7410e-03, -7.7803e-02, -2.5260e-02, -2.1807e-02,  6.9230e-02,\n",
       "                      -3.9180e-02,  3.5022e-02, -5.7222e-02, -3.9577e-03,  2.3911e-02,\n",
       "                       6.5051e-02,  6.6417e-02,  8.2108e-02, -1.6194e-02, -5.6453e-02,\n",
       "                      -1.8652e-02, -5.4385e-02,  6.9420e-02,  6.9400e-02, -8.5118e-02,\n",
       "                       2.3084e-02,  2.1870e-02,  6.2335e-02,  2.4364e-02,  2.6600e-02,\n",
       "                       7.7968e-02,  3.9793e-02, -5.0389e-02,  3.8658e-02, -5.0571e-02,\n",
       "                      -5.0666e-03,  8.3519e-02, -2.4157e-02,  1.6455e-02, -1.8041e-02,\n",
       "                       6.3769e-03, -9.1840e-03, -7.2521e-02,  2.4851e-02,  2.1992e-02,\n",
       "                       8.2917e-02, -3.5699e-02, -5.3158e-02,  3.5066e-02,  1.7173e-02,\n",
       "                       3.0495e-02, -7.7406e-02, -2.2393e-02,  1.1798e-02, -8.8065e-02,\n",
       "                      -6.2426e-02, -1.6270e-02, -7.1242e-02,  8.2502e-02,  2.7013e-02,\n",
       "                       5.0604e-02, -7.3930e-02, -8.6947e-02,  6.6381e-03, -3.1013e-02,\n",
       "                      -1.3813e-02, -4.4028e-02,  3.5652e-02,  2.5456e-02,  6.3987e-02,\n",
       "                      -8.0490e-02, -3.1839e-02,  4.4165e-02, -1.0063e-02, -8.6524e-02,\n",
       "                       5.8780e-02, -4.3946e-02,  2.9861e-02, -3.0453e-02, -3.9396e-03,\n",
       "                       1.4479e-02, -4.5674e-02,  2.7161e-02, -5.0937e-02,  3.9239e-02,\n",
       "                       3.8905e-02,  6.0005e-02, -1.8003e-02,  3.3986e-02,  4.3151e-02,\n",
       "                      -3.5595e-02,  2.2205e-02,  8.5126e-02,  4.2166e-02, -6.7969e-02,\n",
       "                      -5.6484e-02, -3.7545e-02,  2.4204e-02,  1.9891e-02, -6.6654e-02,\n",
       "                       5.1927e-02,  5.2141e-02, -4.3620e-02, -3.4493e-02, -6.9598e-02,\n",
       "                      -7.0320e-02, -8.3461e-03,  5.9990e-02,  3.7554e-02,  7.6733e-02,\n",
       "                       6.1887e-02,  7.7811e-02,  5.2677e-02, -7.7347e-02,  3.5981e-02,\n",
       "                      -2.4431e-02, -4.7759e-02, -8.4973e-02,  8.5107e-02, -6.1830e-03,\n",
       "                       5.3354e-02,  2.1304e-02,  3.2613e-02, -7.9231e-02, -2.9300e-02,\n",
       "                       5.3792e-02,  3.6278e-02, -7.1961e-02,  8.1696e-02,  3.5382e-02,\n",
       "                       7.8482e-02, -5.3146e-02])),\n",
       "             ('embedder.layers.2.2.module.2.weight',\n",
       "              tensor([[-0.0179,  0.0233, -0.0011,  ..., -0.0102, -0.0435,  0.0202],\n",
       "                      [ 0.0183, -0.0061, -0.0336,  ...,  0.0123, -0.0278,  0.0432],\n",
       "                      [-0.0015,  0.0041, -0.0378,  ..., -0.0059, -0.0140, -0.0172],\n",
       "                      ...,\n",
       "                      [ 0.0370, -0.0312, -0.0387,  ...,  0.0284,  0.0009,  0.0093],\n",
       "                      [-0.0021, -0.0439,  0.0212,  ..., -0.0434, -0.0280, -0.0275],\n",
       "                      [-0.0315,  0.0062,  0.0020,  ..., -0.0406,  0.0229, -0.0124]])),\n",
       "             ('embedder.layers.2.2.module.2.bias',\n",
       "              tensor([ 6.1247e-03, -4.3954e-02,  7.7626e-03, -1.6529e-03,  2.9206e-02,\n",
       "                      -1.6537e-02,  2.2260e-02,  3.3128e-02, -8.5058e-03, -2.6372e-02,\n",
       "                       9.0307e-04, -4.3409e-02,  1.4763e-02,  9.0779e-03, -1.4907e-02,\n",
       "                       2.0592e-02, -3.9890e-02,  4.1828e-02,  1.8612e-02,  2.5331e-02,\n",
       "                      -2.2270e-02,  1.5168e-02,  2.1353e-02,  1.6500e-02,  3.5584e-02,\n",
       "                       2.1324e-02, -2.5328e-02,  4.0309e-02, -1.8136e-02,  2.0376e-02,\n",
       "                       4.3838e-02, -7.0285e-03, -4.6032e-03, -5.0746e-03,  2.6604e-02,\n",
       "                      -2.0702e-02, -3.7936e-02, -8.5444e-03, -3.7269e-02, -1.8527e-02,\n",
       "                       2.4958e-02, -3.4268e-02,  3.2501e-02, -1.9156e-02,  1.6238e-02,\n",
       "                       3.3365e-02,  2.2800e-02, -2.3613e-02, -7.3915e-03,  3.9579e-02,\n",
       "                      -3.5574e-02,  4.2137e-02, -2.0704e-02, -4.7782e-04, -1.9681e-02,\n",
       "                      -1.5328e-02,  2.9343e-02, -1.5652e-02,  4.2181e-02, -2.0058e-02,\n",
       "                       4.6350e-05,  3.2646e-02,  1.7236e-03,  2.8723e-02, -3.0070e-02,\n",
       "                      -4.0754e-02, -2.3398e-02, -3.2147e-02,  2.7646e-03, -4.0145e-02,\n",
       "                      -1.0857e-02,  8.9542e-03, -1.4884e-02,  1.0809e-02,  1.2682e-02,\n",
       "                       3.6890e-02,  2.8237e-02, -1.2488e-02,  1.1902e-02,  1.6129e-02,\n",
       "                      -1.9639e-02, -2.9746e-02,  3.5784e-02,  5.4287e-03, -3.4359e-02,\n",
       "                       3.1318e-02, -3.1679e-02,  1.9586e-02, -1.8616e-02, -3.6852e-02,\n",
       "                       3.4479e-02, -3.2330e-02,  3.5314e-02,  2.6009e-02, -1.1746e-04,\n",
       "                       1.1993e-02,  2.0589e-02, -2.0699e-02, -2.2369e-02, -2.7398e-02,\n",
       "                      -2.8396e-02,  1.8453e-02, -3.2016e-02,  2.1306e-02,  1.7882e-02,\n",
       "                      -4.2455e-02,  1.1314e-02, -3.2113e-03,  3.0942e-02,  4.4135e-02,\n",
       "                      -2.0154e-02, -3.3261e-02,  2.0263e-02,  5.3427e-03,  9.1027e-03,\n",
       "                       2.9058e-02,  2.5046e-02, -2.3554e-02,  1.9989e-02, -3.4180e-02,\n",
       "                       1.3906e-02, -1.1112e-02,  4.1704e-03, -1.7324e-02, -1.9316e-02,\n",
       "                       2.4198e-02, -2.4422e-02,  4.6975e-03])),\n",
       "             ('embedder.layers.2.3.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder.layers.2.3.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder.layers.2.3.normalizer.running_mean',\n",
       "              tensor([ 8.1460e-03,  1.4420e-02, -3.3980e-02, -3.4318e-02,  2.3744e-02,\n",
       "                      -3.2993e-03, -1.8140e-03, -2.8435e-02,  3.3853e-03, -5.5447e-03,\n",
       "                      -9.0695e-03, -1.9876e-02, -6.0379e-03, -1.6390e-02,  4.7150e-04,\n",
       "                       1.1692e-02,  1.2214e-03,  1.5101e-02,  1.6057e-02,  1.3539e-02,\n",
       "                      -4.0422e-03,  1.4175e-03,  6.7025e-03,  1.3945e-03, -3.2776e-03,\n",
       "                       3.0846e-02, -1.5378e-02, -2.9327e-03,  3.9507e-03,  8.8695e-04,\n",
       "                      -8.6256e-03,  1.8863e-02, -7.4238e-03, -7.8412e-03,  1.3711e-02,\n",
       "                       1.6941e-02, -3.6982e-03,  5.6612e-03,  2.5370e-03, -1.4017e-03,\n",
       "                      -4.7648e-04, -5.7641e-04,  7.7259e-03,  8.9351e-04,  2.2777e-02,\n",
       "                      -6.4603e-03,  1.0789e-02, -1.5302e-02, -1.0756e-02,  1.8652e-02,\n",
       "                       1.3644e-02,  1.4739e-02, -3.1408e-02,  3.0002e-03,  7.7193e-03,\n",
       "                       2.7342e-03, -7.0403e-03,  9.9072e-03, -1.8763e-02,  1.0179e-02,\n",
       "                      -4.3731e-03,  1.6594e-03, -1.1235e-02, -2.3121e-02, -2.6083e-02,\n",
       "                      -4.2511e-03,  7.0776e-03, -2.8412e-02,  2.2250e-02, -2.4762e-03,\n",
       "                       1.1642e-02, -2.0341e-03,  5.2986e-03, -5.0259e-03, -9.1381e-04,\n",
       "                      -1.5304e-02, -9.9471e-03,  1.0801e-02,  9.4708e-03, -1.5890e-02,\n",
       "                      -2.1474e-03, -7.5431e-03,  2.8785e-03, -1.5962e-02, -7.1235e-03,\n",
       "                       7.4938e-03,  4.1069e-04,  5.8968e-03,  6.0093e-03, -1.8821e-02,\n",
       "                       2.3097e-02,  4.9789e-05,  6.0129e-03,  2.9049e-02,  2.0276e-02,\n",
       "                       9.0939e-03, -7.2273e-03, -1.2383e-02,  1.3117e-03, -1.9868e-03,\n",
       "                      -2.4509e-03, -2.8711e-03,  1.7000e-02, -2.9252e-03, -3.3015e-02,\n",
       "                      -3.1714e-03,  4.5978e-03, -1.1493e-02,  3.2021e-02,  2.4715e-02,\n",
       "                      -2.9383e-02,  4.9847e-03,  7.7920e-04, -3.6717e-04,  1.8213e-02,\n",
       "                       1.1431e-02, -5.2809e-05, -2.6804e-03, -9.2394e-03, -4.4707e-03,\n",
       "                       1.7042e-02,  2.0159e-02, -3.1252e-04, -9.8133e-03, -1.7950e-03,\n",
       "                      -3.3989e-02, -1.6884e-02, -1.5372e-02])),\n",
       "             ('embedder.layers.2.3.normalizer.running_var',\n",
       "              tensor([0.9946, 1.0000, 1.0100, 1.0169, 0.9872, 1.0050, 0.9976, 0.9921, 1.0350,\n",
       "                      1.0262, 0.9965, 0.9872, 1.0295, 1.0122, 1.0376, 0.9929, 0.9967, 0.9989,\n",
       "                      0.9811, 1.0097, 1.0251, 1.0016, 0.9876, 0.9951, 1.0220, 1.0494, 1.0002,\n",
       "                      1.0031, 1.0003, 0.9645, 1.0374, 1.0018, 1.0239, 1.0164, 1.0026, 1.0064,\n",
       "                      1.0574, 1.0140, 1.0389, 0.9848, 0.9953, 1.0067, 1.0132, 1.0304, 1.0012,\n",
       "                      1.0090, 1.0068, 0.9953, 1.0093, 1.0083, 1.0166, 1.0528, 1.0376, 0.9846,\n",
       "                      1.0050, 1.0272, 1.0000, 0.9789, 0.9907, 1.0006, 0.9991, 0.9906, 1.0171,\n",
       "                      1.0090, 0.9989, 1.0367, 0.9947, 0.9989, 0.9721, 0.9970, 0.9803, 1.0311,\n",
       "                      1.0500, 0.9745, 1.0027, 1.0222, 1.0343, 0.9576, 0.9939, 0.9936, 0.9844,\n",
       "                      0.9999, 0.9999, 0.9927, 1.0063, 0.9785, 0.9968, 0.9976, 0.9877, 1.0046,\n",
       "                      1.0130, 0.9893, 1.0115, 1.0067, 0.9844, 1.0094, 1.0219, 1.0135, 1.0136,\n",
       "                      1.0150, 0.9992, 0.9947, 1.0027, 1.0312, 0.9995, 0.9939, 1.0048, 0.9830,\n",
       "                      1.0189, 1.0076, 1.0186, 1.0042, 0.9996, 1.0297, 1.0029, 1.0117, 0.9922,\n",
       "                      0.9752, 1.0131, 1.0030, 1.0080, 1.0267, 1.0001, 0.9999, 1.0507, 1.0198,\n",
       "                      1.0017, 1.0062])),\n",
       "             ('embedder.layers.2.3.normalizer.num_batches_tracked', tensor(1)),\n",
       "             ('embedder_act.layers.0.0.module.W_query',\n",
       "              tensor([[[-0.0028, -0.1791,  0.0051,  ..., -0.0648,  0.2206, -0.1637],\n",
       "                       [-0.0148,  0.0819,  0.1814,  ...,  0.2418, -0.0279,  0.0783],\n",
       "                       [-0.0600, -0.1101, -0.2485,  ..., -0.1972,  0.2405,  0.0593],\n",
       "                       ...,\n",
       "                       [-0.0966, -0.1791, -0.0334,  ..., -0.2057,  0.2090, -0.0384],\n",
       "                       [-0.0740, -0.1558,  0.1382,  ...,  0.0477,  0.1109,  0.0956],\n",
       "                       [ 0.1001, -0.0382,  0.1232,  ...,  0.1476, -0.0583,  0.0986]],\n",
       "              \n",
       "                      [[ 0.0778, -0.1546, -0.1352,  ..., -0.1612,  0.1387, -0.1052],\n",
       "                       [-0.0251,  0.1940, -0.1210,  ...,  0.1837,  0.1573,  0.1839],\n",
       "                       [-0.1241,  0.0096, -0.2243,  ..., -0.1615,  0.1473, -0.1552],\n",
       "                       ...,\n",
       "                       [ 0.0334,  0.1008,  0.1955,  ...,  0.1279,  0.1275,  0.2017],\n",
       "                       [-0.2144,  0.1463, -0.0235,  ..., -0.1069, -0.1786, -0.0689],\n",
       "                       [-0.1289, -0.0765, -0.2289,  ..., -0.2419, -0.0223,  0.2111]],\n",
       "              \n",
       "                      [[-0.1393, -0.0610,  0.0724,  ..., -0.0408,  0.2275, -0.0128],\n",
       "                       [-0.2196,  0.1065,  0.0599,  ...,  0.0950, -0.0689, -0.1123],\n",
       "                       [-0.0638, -0.0995, -0.0773,  ...,  0.0838, -0.0812,  0.0352],\n",
       "                       ...,\n",
       "                       [-0.2051, -0.0664, -0.0627,  ..., -0.0753, -0.2196,  0.0266],\n",
       "                       [-0.2191, -0.1024, -0.0608,  ..., -0.0891,  0.0438,  0.0920],\n",
       "                       [-0.1010,  0.0621,  0.1182,  ...,  0.0153,  0.1449, -0.2241]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.1684, -0.0828, -0.1247,  ...,  0.0926, -0.1387,  0.2159],\n",
       "                       [ 0.0290, -0.1158, -0.0499,  ...,  0.1963,  0.0684,  0.0928],\n",
       "                       [-0.0366,  0.2255, -0.1933,  ...,  0.1985, -0.0454, -0.1706],\n",
       "                       ...,\n",
       "                       [ 0.0440, -0.0131,  0.0753,  ...,  0.2367, -0.1044,  0.1778],\n",
       "                       [-0.2370, -0.1005, -0.0683,  ..., -0.1594, -0.0584, -0.1005],\n",
       "                       [-0.2384, -0.1910,  0.0172,  ..., -0.2297, -0.0479, -0.2490]],\n",
       "              \n",
       "                      [[-0.0486, -0.1961, -0.2379,  ..., -0.1899,  0.1284, -0.1163],\n",
       "                       [ 0.1816,  0.0912, -0.0419,  ...,  0.2091,  0.2500, -0.0461],\n",
       "                       [-0.1279, -0.0457,  0.0909,  ...,  0.1124,  0.2257,  0.1835],\n",
       "                       ...,\n",
       "                       [-0.0571,  0.0963, -0.1554,  ...,  0.1894,  0.2237,  0.2419],\n",
       "                       [-0.0514,  0.2003,  0.0782,  ...,  0.0179,  0.1340,  0.2405],\n",
       "                       [-0.2460,  0.2186,  0.1138,  ..., -0.1707,  0.1198, -0.0560]],\n",
       "              \n",
       "                      [[ 0.0065,  0.1943,  0.1199,  ...,  0.1174, -0.0128,  0.1873],\n",
       "                       [-0.0186, -0.1039, -0.0198,  ...,  0.2296,  0.2341, -0.0453],\n",
       "                       [-0.1189, -0.2120,  0.0014,  ...,  0.2273, -0.0026,  0.0203],\n",
       "                       ...,\n",
       "                       [ 0.2054, -0.1267,  0.2142,  ..., -0.0839, -0.2123, -0.1194],\n",
       "                       [ 0.1898, -0.1995, -0.0225,  ..., -0.0092,  0.0811, -0.2064],\n",
       "                       [ 0.0978,  0.1639, -0.1929,  ..., -0.0275, -0.2216,  0.0263]]])),\n",
       "             ('embedder_act.layers.0.0.module.W_key',\n",
       "              tensor([[[ 0.0022,  0.0381, -0.2075,  ...,  0.1030,  0.1696,  0.2373],\n",
       "                       [-0.1448, -0.2401,  0.0413,  ...,  0.0022, -0.2098, -0.1124],\n",
       "                       [-0.1842, -0.2011, -0.1713,  ...,  0.0609, -0.2417,  0.2198],\n",
       "                       ...,\n",
       "                       [-0.2217, -0.2373,  0.1474,  ..., -0.1166,  0.2140, -0.2107],\n",
       "                       [ 0.1724,  0.1805, -0.1523,  ...,  0.0569, -0.2476, -0.0392],\n",
       "                       [-0.1059, -0.0476,  0.2237,  ..., -0.0068, -0.0777, -0.0087]],\n",
       "              \n",
       "                      [[-0.0281, -0.0643, -0.1313,  ..., -0.2336, -0.1749,  0.1382],\n",
       "                       [ 0.1891, -0.0628, -0.0316,  ...,  0.0645,  0.1110,  0.2265],\n",
       "                       [ 0.1791, -0.1442,  0.1943,  ..., -0.0638,  0.1991, -0.1632],\n",
       "                       ...,\n",
       "                       [-0.0082,  0.1572, -0.0272,  ..., -0.1608,  0.1103, -0.2079],\n",
       "                       [-0.0789, -0.1889,  0.2004,  ..., -0.0991, -0.0556, -0.2044],\n",
       "                       [-0.1947, -0.1487, -0.1581,  ..., -0.2386,  0.1982,  0.0889]],\n",
       "              \n",
       "                      [[-0.0588,  0.1781, -0.0025,  ..., -0.1657, -0.0414, -0.1115],\n",
       "                       [-0.0700,  0.1815,  0.0820,  ...,  0.1516,  0.1514,  0.2165],\n",
       "                       [ 0.2388,  0.0443, -0.2234,  ..., -0.1476,  0.2408,  0.1121],\n",
       "                       ...,\n",
       "                       [-0.1981, -0.0287, -0.0897,  ..., -0.2419,  0.1848,  0.2092],\n",
       "                       [-0.1189,  0.0574,  0.0824,  ..., -0.2319, -0.1019,  0.0775],\n",
       "                       [ 0.2362,  0.2027, -0.0545,  ..., -0.1907, -0.2422,  0.0542]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2234,  0.1096, -0.0243,  ...,  0.0369,  0.0663, -0.1945],\n",
       "                       [-0.1460, -0.2344, -0.1841,  ...,  0.0070, -0.0491, -0.0737],\n",
       "                       [ 0.0171,  0.1668,  0.2383,  ...,  0.1327,  0.1472, -0.1204],\n",
       "                       ...,\n",
       "                       [-0.0341, -0.2371, -0.1376,  ...,  0.0735,  0.1049,  0.0536],\n",
       "                       [-0.0876, -0.1379, -0.0312,  ..., -0.0143, -0.0973,  0.2496],\n",
       "                       [ 0.0414, -0.0972,  0.0614,  ..., -0.1290, -0.0127,  0.0856]],\n",
       "              \n",
       "                      [[-0.0214, -0.0471, -0.2170,  ...,  0.1197, -0.1555, -0.0548],\n",
       "                       [ 0.1661, -0.2213,  0.2317,  ...,  0.1863, -0.1405, -0.1238],\n",
       "                       [-0.0741, -0.2278, -0.1710,  ...,  0.1225,  0.1279, -0.1263],\n",
       "                       ...,\n",
       "                       [-0.0391, -0.0413, -0.1062,  ..., -0.2397, -0.0350, -0.0126],\n",
       "                       [ 0.1288,  0.0583,  0.0939,  ..., -0.2404,  0.2364, -0.0495],\n",
       "                       [ 0.0097,  0.2222,  0.0084,  ...,  0.0243, -0.0726, -0.0122]],\n",
       "              \n",
       "                      [[-0.0673,  0.2137,  0.0961,  ..., -0.1487,  0.2188,  0.0438],\n",
       "                       [ 0.2477, -0.2166, -0.0839,  ...,  0.1397,  0.2066, -0.1586],\n",
       "                       [-0.1597, -0.1009, -0.0203,  ...,  0.1259,  0.2117,  0.0520],\n",
       "                       ...,\n",
       "                       [ 0.1254, -0.1912,  0.0599,  ...,  0.1853,  0.2343, -0.1622],\n",
       "                       [-0.0568, -0.1446, -0.0553,  ...,  0.2209,  0.0806,  0.0324],\n",
       "                       [-0.0740, -0.0171, -0.1719,  ..., -0.2234,  0.0138, -0.1655]]])),\n",
       "             ('embedder_act.layers.0.0.module.W_val',\n",
       "              tensor([[[ 5.4473e-04, -1.9136e-01, -1.0417e-01,  ..., -2.3564e-01,\n",
       "                         1.9443e-01, -8.0801e-02],\n",
       "                       [ 1.8715e-01,  2.4220e-02, -1.7529e-01,  ...,  5.4781e-02,\n",
       "                        -2.2354e-01, -1.8561e-01],\n",
       "                       [ 1.3136e-01,  1.0798e-01,  2.3650e-02,  ...,  1.5158e-01,\n",
       "                         1.9254e-01,  2.2877e-01],\n",
       "                       ...,\n",
       "                       [-1.0726e-01, -3.8359e-02,  2.0935e-01,  ..., -1.4687e-01,\n",
       "                        -1.1297e-01,  2.4585e-01],\n",
       "                       [ 1.4101e-01,  1.9317e-01, -8.2838e-02,  ..., -1.5194e-01,\n",
       "                         2.9162e-03, -1.6977e-02],\n",
       "                       [-1.3182e-01,  1.7139e-01, -1.5134e-01,  ...,  2.4010e-01,\n",
       "                         8.7837e-02,  2.1611e-02]],\n",
       "              \n",
       "                      [[-1.8937e-02, -1.9831e-01, -4.6134e-02,  ..., -1.3933e-01,\n",
       "                        -1.8960e-01,  1.1492e-01],\n",
       "                       [-1.8934e-01, -1.0326e-01,  1.7383e-01,  ...,  1.7064e-01,\n",
       "                         9.4951e-02, -1.2535e-01],\n",
       "                       [ 5.0960e-02, -2.2040e-01,  1.5230e-01,  ...,  1.3985e-01,\n",
       "                         6.3626e-02, -1.0500e-01],\n",
       "                       ...,\n",
       "                       [ 9.7213e-02, -2.3302e-01,  5.5331e-02,  ...,  1.9446e-01,\n",
       "                        -7.2529e-02, -1.2391e-01],\n",
       "                       [ 2.7466e-02, -5.6797e-02,  1.6124e-01,  ...,  1.9790e-01,\n",
       "                        -8.7948e-02,  1.0524e-01],\n",
       "                       [-1.8061e-01, -5.3992e-02, -1.2467e-01,  ...,  1.4022e-01,\n",
       "                        -1.7137e-01,  1.1886e-02]],\n",
       "              \n",
       "                      [[-2.2536e-01, -1.6657e-01, -2.3261e-01,  ..., -1.9715e-01,\n",
       "                         9.8671e-02,  2.1295e-02],\n",
       "                       [-1.2935e-01,  1.7094e-02,  2.1423e-01,  ...,  1.0339e-01,\n",
       "                         8.2849e-02, -1.1090e-01],\n",
       "                       [ 1.4252e-01, -1.6302e-01,  1.1262e-01,  ...,  6.5873e-02,\n",
       "                         9.6654e-02, -2.0803e-01],\n",
       "                       ...,\n",
       "                       [ 2.3354e-01, -5.4584e-02,  5.6328e-02,  ..., -1.7744e-01,\n",
       "                         2.0183e-02,  4.1706e-02],\n",
       "                       [-2.2348e-02,  7.1964e-02, -6.7205e-02,  ...,  1.9167e-01,\n",
       "                         6.5845e-02, -1.1106e-01],\n",
       "                       [-1.9370e-01,  5.1188e-02,  6.8792e-02,  ..., -1.4905e-01,\n",
       "                        -7.1752e-02, -1.3452e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-2.5758e-02,  1.0068e-01,  1.4732e-01,  ...,  1.6200e-01,\n",
       "                         1.5907e-01, -2.1464e-01],\n",
       "                       [-1.2184e-01,  1.7698e-02, -1.1638e-01,  ..., -1.9390e-01,\n",
       "                        -7.7688e-03, -1.3130e-01],\n",
       "                       [-5.9714e-02,  2.1679e-02,  1.3847e-01,  ..., -1.1934e-01,\n",
       "                        -4.5114e-02,  7.0508e-02],\n",
       "                       ...,\n",
       "                       [ 4.0889e-05,  2.2862e-02,  2.1949e-01,  ..., -1.1280e-01,\n",
       "                        -9.6249e-02, -1.2811e-01],\n",
       "                       [ 8.9059e-02,  3.8209e-02, -2.1953e-01,  ...,  2.3149e-01,\n",
       "                         2.2435e-01, -2.1775e-01],\n",
       "                       [ 2.1884e-02,  2.0802e-01,  1.9150e-01,  ..., -5.2872e-02,\n",
       "                        -2.4877e-01, -1.5231e-02]],\n",
       "              \n",
       "                      [[-4.5495e-02, -1.6331e-01,  2.3428e-01,  ...,  2.2838e-01,\n",
       "                        -8.4901e-02,  2.2678e-01],\n",
       "                       [ 3.7901e-02, -2.3086e-01,  1.8814e-01,  ...,  2.2806e-01,\n",
       "                         2.9745e-02,  2.1331e-02],\n",
       "                       [-1.0782e-01,  1.6322e-01,  1.3683e-01,  ...,  2.0026e-01,\n",
       "                         1.4117e-01, -8.5150e-02],\n",
       "                       ...,\n",
       "                       [ 8.5871e-02, -2.4736e-01,  9.6394e-03,  ..., -2.0798e-02,\n",
       "                        -6.6182e-02,  2.4392e-01],\n",
       "                       [ 7.1445e-02,  1.2760e-01,  1.6892e-01,  ...,  1.1725e-01,\n",
       "                         1.1944e-01, -7.3145e-02],\n",
       "                       [ 1.2349e-01,  2.0844e-01, -2.0349e-01,  ...,  1.7149e-01,\n",
       "                        -1.1491e-01, -5.2802e-02]],\n",
       "              \n",
       "                      [[-1.1794e-02, -2.0046e-01,  3.0085e-02,  ..., -5.5586e-02,\n",
       "                        -1.1977e-01,  1.7253e-01],\n",
       "                       [ 2.2100e-01, -1.8180e-01, -6.4530e-02,  ...,  5.0697e-02,\n",
       "                        -2.0105e-01, -4.1546e-03],\n",
       "                       [-1.8360e-01, -1.3403e-01, -2.1013e-01,  ...,  1.7367e-01,\n",
       "                        -8.4591e-02,  1.0664e-01],\n",
       "                       ...,\n",
       "                       [ 2.1116e-01,  2.4411e-01, -3.4151e-02,  ...,  2.3685e-01,\n",
       "                        -2.4063e-01,  1.3637e-01],\n",
       "                       [ 2.4180e-01,  1.3725e-01, -1.5765e-01,  ..., -9.0689e-02,\n",
       "                        -4.9354e-02,  1.2255e-01],\n",
       "                       [ 8.6772e-02, -5.4464e-02,  8.3977e-02,  ...,  5.6792e-02,\n",
       "                        -2.0244e-02,  9.0546e-03]]])),\n",
       "             ('embedder_act.layers.0.0.module.W_out',\n",
       "              tensor([[[-0.0514,  0.0086,  0.0001,  ...,  0.0599, -0.0149, -0.0015],\n",
       "                       [ 0.0452,  0.0062,  0.0735,  ..., -0.0262, -0.0161,  0.0665],\n",
       "                       [ 0.0571,  0.0733,  0.0721,  ...,  0.0680,  0.0332, -0.0561],\n",
       "                       ...,\n",
       "                       [ 0.0089, -0.0262,  0.0433,  ...,  0.0029, -0.0459,  0.0359],\n",
       "                       [ 0.0005, -0.0690,  0.0059,  ...,  0.0032,  0.0177, -0.0072],\n",
       "                       [-0.0701, -0.0400,  0.0666,  ..., -0.0065, -0.0080, -0.0754]],\n",
       "              \n",
       "                      [[-0.0035, -0.0114,  0.0467,  ..., -0.0860, -0.0508,  0.0134],\n",
       "                       [ 0.0178, -0.0127, -0.0427,  ..., -0.0836,  0.0216,  0.0663],\n",
       "                       [ 0.0373,  0.0782, -0.0085,  ..., -0.0772,  0.0458, -0.0426],\n",
       "                       ...,\n",
       "                       [-0.0882,  0.0412, -0.0807,  ..., -0.0795, -0.0506, -0.0851],\n",
       "                       [ 0.0152, -0.0170, -0.0477,  ...,  0.0287,  0.0188, -0.0303],\n",
       "                       [-0.0491, -0.0545, -0.0380,  ..., -0.0110, -0.0690,  0.0779]],\n",
       "              \n",
       "                      [[-0.0226,  0.0402, -0.0582,  ..., -0.0734, -0.0546, -0.0043],\n",
       "                       [ 0.0757,  0.0062, -0.0690,  ...,  0.0434,  0.0326, -0.0131],\n",
       "                       [ 0.0196, -0.0220,  0.0878,  ...,  0.0763, -0.0182, -0.0147],\n",
       "                       ...,\n",
       "                       [ 0.0124, -0.0862, -0.0313,  ...,  0.0226, -0.0679, -0.0155],\n",
       "                       [ 0.0183, -0.0582,  0.0476,  ..., -0.0574,  0.0624,  0.0534],\n",
       "                       [-0.0495, -0.0839,  0.0756,  ..., -0.0206,  0.0058,  0.0150]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0231, -0.0004,  0.0575,  ...,  0.0049,  0.0733, -0.0690],\n",
       "                       [-0.0113, -0.0172, -0.0860,  ..., -0.0066,  0.0276,  0.0481],\n",
       "                       [ 0.0870, -0.0787,  0.0500,  ..., -0.0374,  0.0774,  0.0566],\n",
       "                       ...,\n",
       "                       [ 0.0845, -0.0806,  0.0304,  ...,  0.0367,  0.0683,  0.0292],\n",
       "                       [-0.0199, -0.0469, -0.0518,  ..., -0.0379, -0.0844, -0.0732],\n",
       "                       [ 0.0806, -0.0509,  0.0179,  ...,  0.0701, -0.0554, -0.0825]],\n",
       "              \n",
       "                      [[ 0.0059, -0.0758, -0.0768,  ..., -0.0251,  0.0571,  0.0605],\n",
       "                       [-0.0056, -0.0127,  0.0138,  ...,  0.0541,  0.0406,  0.0740],\n",
       "                       [-0.0370, -0.0789, -0.0028,  ..., -0.0149,  0.0412, -0.0704],\n",
       "                       ...,\n",
       "                       [-0.0031,  0.0325, -0.0059,  ...,  0.0483,  0.0134, -0.0125],\n",
       "                       [ 0.0464,  0.0247, -0.0876,  ...,  0.0376, -0.0780, -0.0042],\n",
       "                       [-0.0709,  0.0194, -0.0673,  ..., -0.0730, -0.0462,  0.0672]],\n",
       "              \n",
       "                      [[ 0.0181, -0.0206,  0.0862,  ..., -0.0508, -0.0744,  0.0240],\n",
       "                       [ 0.0064, -0.0078, -0.0409,  ...,  0.0200,  0.0739, -0.0819],\n",
       "                       [ 0.0634,  0.0224,  0.0593,  ..., -0.0646, -0.0533,  0.0518],\n",
       "                       ...,\n",
       "                       [-0.0354, -0.0321,  0.0063,  ...,  0.0874,  0.0233, -0.0393],\n",
       "                       [-0.0735,  0.0533, -0.0242,  ..., -0.0237, -0.0161,  0.0568],\n",
       "                       [ 0.0494,  0.0688, -0.0825,  ..., -0.0146, -0.0884,  0.0665]]])),\n",
       "             ('embedder_act.layers.0.1.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder_act.layers.0.1.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder_act.layers.0.1.normalizer.running_mean',\n",
       "              tensor([-1.0524e-01, -3.4659e-02,  7.7574e-02,  1.3978e-01,  2.2233e-02,\n",
       "                       7.1085e-02, -5.0828e-02,  3.8293e-02, -1.0021e-01,  9.8077e-02,\n",
       "                      -1.1800e-02,  1.7356e-02,  4.0998e-02,  3.7918e-02, -1.1011e-01,\n",
       "                      -8.1829e-02,  2.0891e-02,  2.9448e-02, -8.4752e-02,  1.0137e-02,\n",
       "                      -3.5927e-02,  1.0113e-01,  1.0197e-01,  4.9015e-02,  1.3814e-02,\n",
       "                      -9.2893e-02,  6.4257e-03, -3.8803e-02,  7.0336e-02, -4.5074e-02,\n",
       "                       1.8654e-01, -6.0723e-02, -2.0518e-02, -2.1897e-02, -3.2289e-02,\n",
       "                       9.7508e-02,  1.1599e-01,  9.4370e-02, -9.4722e-02,  7.0287e-03,\n",
       "                      -1.0089e-01, -5.0323e-02, -9.9473e-02,  6.9993e-02, -8.4144e-02,\n",
       "                       1.1158e-01, -3.8838e-02, -4.6961e-02,  2.5384e-02,  5.3016e-02,\n",
       "                       6.8755e-02, -1.4842e-02, -5.8850e-02,  2.3015e-02, -2.9952e-02,\n",
       "                      -8.0948e-02,  4.8634e-02,  4.0396e-02,  2.2223e-02, -5.1762e-02,\n",
       "                      -3.3243e-02, -1.7601e-01, -6.6998e-02, -1.1009e-01,  8.8566e-02,\n",
       "                      -3.8471e-02,  1.0712e-01, -3.3935e-02,  9.8085e-02, -9.9565e-03,\n",
       "                       8.1215e-02, -9.1943e-02,  1.4669e-01,  5.2004e-02,  8.1171e-02,\n",
       "                       1.6515e-02,  1.5662e-01,  2.0047e-02,  1.4450e-01, -6.5560e-02,\n",
       "                      -1.2151e-01, -1.3207e-04,  1.6112e-01,  8.0065e-02,  8.4078e-02,\n",
       "                       1.4510e-01, -7.9415e-03,  9.2110e-02, -4.7713e-02, -5.8542e-02,\n",
       "                       7.8226e-02,  8.1812e-02,  8.3748e-02, -1.5951e-02, -3.7687e-02,\n",
       "                      -1.3557e-02,  6.2562e-02, -8.4517e-02, -6.0279e-02, -1.3126e-01,\n",
       "                      -1.4566e-01,  3.3554e-02, -7.5594e-02,  6.1330e-02,  3.3778e-02,\n",
       "                       1.0160e-01, -7.2688e-02, -1.5545e-01,  1.5110e-01,  3.2113e-02,\n",
       "                      -2.6895e-02,  2.5947e-02, -1.2311e-01, -1.6646e-02,  4.9949e-02,\n",
       "                       3.3237e-02,  4.8560e-02,  4.7027e-02,  8.0288e-02,  5.4598e-02,\n",
       "                      -9.1755e-02,  5.4981e-02,  1.9959e-03, -8.6816e-02,  1.0833e-01,\n",
       "                      -4.6214e-03,  1.3088e-01, -3.9884e-02])),\n",
       "             ('embedder_act.layers.0.1.normalizer.running_var',\n",
       "              tensor([0.9038, 0.9032, 0.9019, 0.9020, 0.9020, 0.9006, 0.9010, 0.9025, 0.9005,\n",
       "                      0.9017, 0.9039, 0.9020, 0.9018, 0.9040, 0.9052, 0.9000, 0.9015, 0.9012,\n",
       "                      0.9002, 0.9014, 0.9047, 0.9056, 0.9020, 0.9027, 0.9026, 0.9033, 0.9064,\n",
       "                      0.9002, 0.9030, 0.9021, 0.9013, 0.9024, 0.9005, 0.9039, 0.9027, 0.9061,\n",
       "                      0.9076, 0.9028, 0.9010, 0.9039, 0.9031, 0.9011, 0.9024, 0.9017, 0.9030,\n",
       "                      0.9029, 0.9018, 0.9021, 0.9040, 0.9005, 0.9027, 0.9037, 0.9007, 0.9004,\n",
       "                      0.9003, 0.9091, 0.9042, 0.9039, 0.9012, 0.9035, 0.9022, 0.9040, 0.9019,\n",
       "                      0.9026, 0.9051, 0.9024, 0.9016, 0.9024, 0.9008, 0.9004, 0.9039, 0.9040,\n",
       "                      0.9042, 0.9055, 0.9055, 0.9036, 0.9036, 0.9016, 0.9026, 0.9038, 0.9029,\n",
       "                      0.9028, 0.9004, 0.9052, 0.9047, 0.9019, 0.9004, 0.9034, 0.9020, 0.9000,\n",
       "                      0.9008, 0.9038, 0.9004, 0.9009, 0.9042, 0.9005, 0.9037, 0.9008, 0.9048,\n",
       "                      0.9050, 0.9030, 0.9027, 0.9028, 0.9001, 0.9004, 0.9044, 0.9014, 0.9080,\n",
       "                      0.9038, 0.9023, 0.9001, 0.9020, 0.9009, 0.9007, 0.9003, 0.9029, 0.9041,\n",
       "                      0.9017, 0.9011, 0.9012, 0.9040, 0.9041, 0.9034, 0.9021, 0.9063, 0.9010,\n",
       "                      0.9003, 0.9022])),\n",
       "             ('embedder_act.layers.0.1.normalizer.num_batches_tracked',\n",
       "              tensor(1)),\n",
       "             ('embedder_act.layers.0.2.module.0.weight',\n",
       "              tensor([[ 0.0714,  0.0220,  0.0631,  ..., -0.0807,  0.0761, -0.0828],\n",
       "                      [-0.0038, -0.0484, -0.0456,  ...,  0.0490,  0.0852, -0.0309],\n",
       "                      [-0.0874, -0.0396, -0.0127,  ..., -0.0523,  0.0689,  0.0154],\n",
       "                      ...,\n",
       "                      [-0.0190,  0.0507,  0.0791,  ...,  0.0778, -0.0518,  0.0287],\n",
       "                      [-0.0722,  0.0443, -0.0034,  ...,  0.0583, -0.0400,  0.0255],\n",
       "                      [ 0.0260,  0.0795, -0.0282,  ...,  0.0414,  0.0764,  0.0384]])),\n",
       "             ('embedder_act.layers.0.2.module.0.bias',\n",
       "              tensor([ 0.0594, -0.0767, -0.0679,  0.0019, -0.0735,  0.0250,  0.0107, -0.0377,\n",
       "                       0.0791,  0.0315,  0.0316, -0.0195, -0.0090, -0.0699,  0.0458,  0.0105,\n",
       "                       0.0587, -0.0878,  0.0138,  0.0462,  0.0793,  0.0592,  0.0595, -0.0467,\n",
       "                       0.0304,  0.0027,  0.0340,  0.0612, -0.0267, -0.0776, -0.0632,  0.0596,\n",
       "                      -0.0479,  0.0077, -0.0655,  0.0862,  0.0812,  0.0292,  0.0178, -0.0260,\n",
       "                      -0.0827, -0.0699, -0.0880,  0.0024, -0.0109, -0.0519,  0.0224, -0.0811,\n",
       "                      -0.0616, -0.0539,  0.0503,  0.0690, -0.0025,  0.0314,  0.0302, -0.0698,\n",
       "                      -0.0675, -0.0238, -0.0011,  0.0284,  0.0391,  0.0599,  0.0695,  0.0473,\n",
       "                      -0.0872,  0.0291, -0.0642,  0.0204,  0.0029, -0.0109, -0.0879, -0.0761,\n",
       "                       0.0685, -0.0732,  0.0625, -0.0195, -0.0006, -0.0047,  0.0769,  0.0071,\n",
       "                       0.0705, -0.0267,  0.0531,  0.0499,  0.0761, -0.0075, -0.0751,  0.0662,\n",
       "                       0.0296, -0.0597, -0.0393,  0.0272,  0.0668, -0.0465, -0.0309, -0.0492,\n",
       "                      -0.0452, -0.0771, -0.0151, -0.0766, -0.0643, -0.0653,  0.0355,  0.0758,\n",
       "                      -0.0136, -0.0744,  0.0711,  0.0228, -0.0478, -0.0695,  0.0372,  0.0342,\n",
       "                      -0.0272, -0.0238, -0.0155, -0.0165, -0.0522,  0.0115,  0.0221, -0.0587,\n",
       "                      -0.0314, -0.0509,  0.0376, -0.0224,  0.0856, -0.0657, -0.0132, -0.0105,\n",
       "                      -0.0086, -0.0237,  0.0616, -0.0828,  0.0205,  0.0062,  0.0172, -0.0075,\n",
       "                       0.0145, -0.0813, -0.0609, -0.0543,  0.0451,  0.0478, -0.0755, -0.0366,\n",
       "                       0.0078,  0.0795, -0.0362, -0.0798,  0.0707, -0.0636, -0.0830,  0.0007,\n",
       "                      -0.0553,  0.0197,  0.0506,  0.0721,  0.0131, -0.0564, -0.0078, -0.0550,\n",
       "                      -0.0354,  0.0709, -0.0244,  0.0829, -0.0528,  0.0461, -0.0183, -0.0533,\n",
       "                       0.0594,  0.0315, -0.0041,  0.0193, -0.0742, -0.0865, -0.0464, -0.0034,\n",
       "                      -0.0835,  0.0836,  0.0561,  0.0450, -0.0334,  0.0715,  0.0172,  0.0037,\n",
       "                       0.0314,  0.0700,  0.0832, -0.0613,  0.0649, -0.0250, -0.0483, -0.0823,\n",
       "                       0.0388,  0.0622,  0.0811, -0.0060,  0.0437,  0.0442, -0.0356,  0.0168,\n",
       "                      -0.0791,  0.0094, -0.0279,  0.0672, -0.0488, -0.0815, -0.0466, -0.0504,\n",
       "                      -0.0395, -0.0630,  0.0208,  0.0027, -0.0247,  0.0615, -0.0245,  0.0414,\n",
       "                      -0.0047, -0.0377,  0.0537, -0.0228,  0.0671,  0.0792, -0.0304,  0.0815,\n",
       "                       0.0869,  0.0642, -0.0535, -0.0461, -0.0240,  0.0880,  0.0436,  0.0452,\n",
       "                      -0.0319, -0.0697,  0.0032, -0.0056, -0.0391, -0.0178, -0.0509,  0.0388,\n",
       "                      -0.0761, -0.0594,  0.0044, -0.0263, -0.0315,  0.0083,  0.0200, -0.0611,\n",
       "                       0.0706,  0.0659, -0.0603,  0.0697,  0.0774,  0.0185, -0.0743, -0.0460,\n",
       "                      -0.0192, -0.0068,  0.0769,  0.0054, -0.0069, -0.0067, -0.0699, -0.0153,\n",
       "                       0.0748,  0.0804, -0.0350, -0.0438,  0.0162,  0.0183, -0.0367, -0.0307,\n",
       "                      -0.0180,  0.0310, -0.0549,  0.0799,  0.0690,  0.0784,  0.0701,  0.0670,\n",
       "                       0.0364,  0.0620,  0.0456, -0.0680,  0.0057, -0.0210, -0.0603, -0.0827,\n",
       "                      -0.0016, -0.0668,  0.0790, -0.0113,  0.0192, -0.0385,  0.0308,  0.0742,\n",
       "                      -0.0082, -0.0435, -0.0793,  0.0765,  0.0862, -0.0513, -0.0756,  0.0087,\n",
       "                      -0.0756,  0.0872, -0.0793,  0.0514,  0.0723, -0.0250, -0.0494, -0.0691,\n",
       "                       0.0410,  0.0714,  0.0507, -0.0739, -0.0585, -0.0803, -0.0336,  0.0434,\n",
       "                      -0.0712, -0.0198,  0.0306, -0.0660,  0.0545,  0.0554, -0.0304, -0.0846,\n",
       "                       0.0839,  0.0398, -0.0821, -0.0690,  0.0837, -0.0660,  0.0796, -0.0450,\n",
       "                      -0.0439,  0.0376, -0.0573, -0.0082,  0.0805,  0.0371, -0.0854,  0.0128,\n",
       "                       0.0573,  0.0173,  0.0627, -0.0005, -0.0395, -0.0406,  0.0263,  0.0661,\n",
       "                       0.0680,  0.0477,  0.0423,  0.0424,  0.0314, -0.0159,  0.0694, -0.0561,\n",
       "                      -0.0653,  0.0707, -0.0744,  0.0637,  0.0227,  0.0546, -0.0664, -0.0180,\n",
       "                       0.0625,  0.0574,  0.0313, -0.0620,  0.0264,  0.0844, -0.0489, -0.0585,\n",
       "                      -0.0593, -0.0731, -0.0474,  0.0654,  0.0502, -0.0439,  0.0832,  0.0505,\n",
       "                      -0.0794,  0.0883, -0.0670,  0.0462,  0.0276, -0.0801, -0.0158,  0.0437,\n",
       "                       0.0118,  0.0121, -0.0688,  0.0239,  0.0465, -0.0094, -0.0263,  0.0273,\n",
       "                       0.0749, -0.0247, -0.0840, -0.0116, -0.0594, -0.0045, -0.0809, -0.0419,\n",
       "                       0.0362,  0.0820, -0.0687,  0.0059, -0.0012, -0.0302,  0.0671,  0.0514,\n",
       "                      -0.0003,  0.0547, -0.0184,  0.0152, -0.0437,  0.0426,  0.0003,  0.0856,\n",
       "                      -0.0825,  0.0705,  0.0678, -0.0714, -0.0210, -0.0311, -0.0108, -0.0451,\n",
       "                       0.0646,  0.0556,  0.0128, -0.0678, -0.0111,  0.0312,  0.0023,  0.0615,\n",
       "                       0.0485,  0.0803, -0.0257,  0.0180, -0.0765,  0.0879,  0.0527,  0.0726,\n",
       "                      -0.0262, -0.0763,  0.0553,  0.0245,  0.0814,  0.0255,  0.0134, -0.0151,\n",
       "                      -0.0633, -0.0521,  0.0444,  0.0218,  0.0012, -0.0151,  0.0563, -0.0737,\n",
       "                       0.0307,  0.0015, -0.0744,  0.0520, -0.0680, -0.0880, -0.0176, -0.0817,\n",
       "                       0.0026, -0.0827,  0.0207,  0.0174, -0.0850, -0.0472, -0.0882, -0.0267,\n",
       "                       0.0551, -0.0637,  0.0173, -0.0582, -0.0364, -0.0319, -0.0465, -0.0319,\n",
       "                      -0.0264, -0.0332,  0.0014,  0.0729, -0.0441,  0.0451, -0.0367, -0.0090,\n",
       "                      -0.0579,  0.0299,  0.0192, -0.0056,  0.0542, -0.0678,  0.0496, -0.0063,\n",
       "                       0.0519,  0.0284,  0.0341, -0.0524,  0.0219,  0.0440, -0.0557,  0.0326])),\n",
       "             ('embedder_act.layers.0.2.module.2.weight',\n",
       "              tensor([[ 0.0411, -0.0174, -0.0360,  ..., -0.0382,  0.0365, -0.0345],\n",
       "                      [-0.0395,  0.0389, -0.0003,  ..., -0.0304, -0.0030,  0.0388],\n",
       "                      [-0.0306,  0.0189,  0.0022,  ...,  0.0022,  0.0165,  0.0103],\n",
       "                      ...,\n",
       "                      [ 0.0230, -0.0142, -0.0342,  ..., -0.0375, -0.0004, -0.0381],\n",
       "                      [-0.0259,  0.0360, -0.0350,  ...,  0.0271,  0.0093, -0.0215],\n",
       "                      [ 0.0090,  0.0129, -0.0075,  ...,  0.0398,  0.0156,  0.0378]])),\n",
       "             ('embedder_act.layers.0.2.module.2.bias',\n",
       "              tensor([-0.0048,  0.0405,  0.0239,  0.0342,  0.0098, -0.0261,  0.0236,  0.0254,\n",
       "                       0.0317,  0.0063,  0.0401, -0.0300, -0.0101, -0.0380,  0.0299, -0.0344,\n",
       "                       0.0203,  0.0173, -0.0195, -0.0428,  0.0313, -0.0364, -0.0295, -0.0059,\n",
       "                       0.0353,  0.0144, -0.0349, -0.0138, -0.0393,  0.0002, -0.0183,  0.0347,\n",
       "                      -0.0311, -0.0274, -0.0434,  0.0182, -0.0278,  0.0079, -0.0301, -0.0263,\n",
       "                       0.0264,  0.0096,  0.0264, -0.0092, -0.0035,  0.0347, -0.0073, -0.0435,\n",
       "                      -0.0258,  0.0200,  0.0306, -0.0300,  0.0237, -0.0361, -0.0189, -0.0377,\n",
       "                       0.0126, -0.0262, -0.0142, -0.0170, -0.0392,  0.0101, -0.0202,  0.0231,\n",
       "                      -0.0147,  0.0282,  0.0049, -0.0224,  0.0206, -0.0380,  0.0113,  0.0040,\n",
       "                      -0.0183, -0.0414,  0.0217, -0.0116,  0.0406,  0.0287,  0.0217,  0.0184,\n",
       "                      -0.0296,  0.0337, -0.0236,  0.0311, -0.0206,  0.0286,  0.0167, -0.0108,\n",
       "                       0.0363, -0.0118, -0.0291, -0.0187,  0.0263,  0.0428, -0.0127, -0.0251,\n",
       "                      -0.0283,  0.0266,  0.0441, -0.0333, -0.0383,  0.0256,  0.0372, -0.0301,\n",
       "                      -0.0107,  0.0364, -0.0340,  0.0405, -0.0410,  0.0384,  0.0238,  0.0288,\n",
       "                       0.0068, -0.0306, -0.0204,  0.0084,  0.0078, -0.0203, -0.0222, -0.0339,\n",
       "                       0.0102,  0.0356,  0.0011, -0.0087,  0.0258,  0.0342, -0.0284,  0.0418])),\n",
       "             ('embedder_act.layers.0.3.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder_act.layers.0.3.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder_act.layers.0.3.normalizer.running_mean',\n",
       "              tensor([ 5.7730e-03,  1.4685e-02,  1.4991e-02,  1.3369e-02, -2.4455e-03,\n",
       "                      -1.0110e-02, -9.9612e-03,  9.9858e-03,  1.1294e-02,  1.2397e-02,\n",
       "                      -3.6684e-03, -1.5210e-02, -1.9760e-02,  1.1940e-02, -1.6851e-02,\n",
       "                       9.5235e-04,  1.4031e-02, -1.2330e-02, -4.7885e-03, -8.4994e-04,\n",
       "                       7.6795e-03,  4.0549e-03, -1.5352e-03, -2.1523e-02,  8.3554e-03,\n",
       "                       1.9271e-02, -7.9046e-03, -7.2732e-03, -3.7902e-03, -1.3170e-02,\n",
       "                       3.2153e-02,  2.3514e-02, -6.9533e-04, -2.9768e-02, -2.5628e-03,\n",
       "                       2.5616e-02, -6.3069e-03, -1.0098e-03,  2.2545e-02, -1.5994e-03,\n",
       "                       4.5337e-03,  7.1509e-03,  1.3855e-02,  1.1292e-02,  9.5276e-03,\n",
       "                       1.0601e-03, -6.6955e-03,  1.3762e-02, -1.6300e-02,  8.1519e-03,\n",
       "                      -1.6233e-02,  9.1722e-03,  5.4739e-03,  4.0081e-03, -3.9134e-03,\n",
       "                      -2.0762e-02, -2.0756e-02, -6.5333e-03, -2.1507e-02, -1.0534e-03,\n",
       "                      -1.7854e-03,  1.6227e-02,  5.9741e-03,  1.7128e-02, -2.3558e-02,\n",
       "                      -2.3944e-02,  8.3549e-03, -1.6751e-02,  1.5924e-02,  3.0629e-04,\n",
       "                       9.0586e-03, -1.3608e-02, -2.5994e-03,  1.0749e-02, -1.7663e-03,\n",
       "                      -7.7967e-04,  1.0624e-02, -1.1559e-02, -5.8725e-03,  9.6932e-03,\n",
       "                       1.5447e-02,  1.5951e-02, -2.4524e-03,  1.8719e-02,  3.6437e-03,\n",
       "                      -1.0234e-02,  8.1276e-03, -3.1602e-03,  1.2866e-02,  1.1582e-02,\n",
       "                      -6.4540e-03,  1.1539e-02,  9.1781e-05,  1.2638e-02, -1.6605e-02,\n",
       "                       2.9963e-03, -1.6500e-02,  1.2978e-02,  1.2663e-02, -1.9897e-02,\n",
       "                      -1.2997e-02,  4.1469e-03,  8.0960e-03, -8.7893e-03, -2.5986e-03,\n",
       "                       3.0297e-02, -6.7403e-03,  6.9467e-03, -1.3291e-02, -8.1662e-03,\n",
       "                      -2.8317e-02, -5.6781e-03, -1.3475e-02,  1.1460e-02, -5.5620e-03,\n",
       "                      -9.2871e-03,  1.0059e-03,  1.8695e-03, -2.4398e-02, -1.1868e-02,\n",
       "                       1.1704e-03,  2.0300e-02,  1.3392e-02,  5.6632e-03,  8.5386e-03,\n",
       "                       2.2212e-02, -2.5575e-02,  2.6001e-02])),\n",
       "             ('embedder_act.layers.0.3.normalizer.running_var',\n",
       "              tensor([1.0184, 0.9909, 0.9761, 0.9844, 1.0045, 1.0584, 0.9961, 0.9938, 1.0444,\n",
       "                      0.9768, 1.0134, 1.0287, 1.0015, 0.9906, 1.0754, 1.0001, 1.0224, 1.0082,\n",
       "                      0.9778, 1.0431, 0.9863, 1.0117, 0.9933, 1.0096, 1.0011, 1.0080, 1.0014,\n",
       "                      1.0122, 1.0406, 1.0013, 0.9958, 1.0635, 1.0504, 0.9989, 1.0459, 1.0054,\n",
       "                      0.9835, 0.9922, 1.0167, 0.9889, 1.0280, 1.0270, 0.9965, 0.9855, 1.0175,\n",
       "                      1.0413, 1.0040, 0.9879, 1.0461, 0.9883, 0.9716, 0.9854, 1.0080, 0.9755,\n",
       "                      1.0398, 0.9935, 1.0443, 1.0240, 1.0380, 1.0096, 1.0132, 1.0422, 0.9893,\n",
       "                      0.9942, 1.0144, 0.9998, 1.0150, 1.0344, 0.9897, 0.9923, 0.9810, 0.9752,\n",
       "                      1.0270, 0.9832, 1.0305, 0.9810, 0.9938, 0.9876, 1.0366, 1.0047, 0.9826,\n",
       "                      0.9861, 1.0039, 1.0162, 0.9981, 1.0017, 1.0166, 0.9725, 0.9715, 0.9941,\n",
       "                      1.0220, 1.0616, 1.0374, 0.9708, 0.9846, 1.0157, 1.0044, 0.9735, 1.0391,\n",
       "                      0.9715, 0.9907, 0.9982, 0.9862, 1.0177, 0.9957, 1.0066, 0.9874, 1.0147,\n",
       "                      1.0033, 1.0128, 0.9750, 1.0089, 1.0278, 0.9754, 0.9865, 1.0272, 1.0097,\n",
       "                      1.0312, 0.9907, 0.9884, 0.9880, 1.0231, 1.0135, 0.9886, 1.0243, 0.9954,\n",
       "                      0.9907, 1.0162])),\n",
       "             ('embedder_act.layers.0.3.normalizer.num_batches_tracked',\n",
       "              tensor(1)),\n",
       "             ('embedder_act.layers.1.0.module.W_query',\n",
       "              tensor([[[-1.2533e-01,  1.2670e-01,  6.6099e-03,  ..., -2.1710e-01,\n",
       "                         1.8156e-01,  2.0678e-02],\n",
       "                       [-1.4579e-01, -1.2876e-01, -2.3031e-01,  ..., -1.1350e-01,\n",
       "                         1.2019e-01, -1.9802e-01],\n",
       "                       [-1.6113e-02,  1.4799e-01,  1.5977e-01,  ..., -3.1480e-02,\n",
       "                         1.3531e-01, -5.3880e-02],\n",
       "                       ...,\n",
       "                       [ 1.1859e-01, -1.3383e-03, -2.4443e-01,  ..., -1.9427e-02,\n",
       "                         4.2415e-02,  4.9041e-02],\n",
       "                       [-2.0574e-01,  1.8280e-01, -1.4558e-02,  ...,  6.4258e-02,\n",
       "                         2.3930e-01,  6.5943e-02],\n",
       "                       [-9.4558e-02, -8.4403e-02,  2.0714e-01,  ...,  7.5404e-02,\n",
       "                        -1.2035e-01, -1.3622e-01]],\n",
       "              \n",
       "                      [[ 4.9267e-02, -1.6711e-01, -2.3947e-02,  ...,  2.2196e-03,\n",
       "                        -3.1508e-03, -1.7195e-01],\n",
       "                       [ 1.8953e-01,  5.2294e-02,  2.2761e-01,  ...,  6.4482e-02,\n",
       "                         1.3797e-01, -9.2610e-02],\n",
       "                       [-1.4838e-01, -1.0904e-01, -1.6211e-02,  ...,  7.2782e-02,\n",
       "                         1.9698e-01,  2.0428e-01],\n",
       "                       ...,\n",
       "                       [ 2.2753e-01,  2.2418e-03, -1.3660e-01,  ..., -1.4169e-01,\n",
       "                        -1.9735e-01, -4.0789e-02],\n",
       "                       [-2.4779e-01,  1.2123e-01, -7.3498e-02,  ..., -6.9448e-02,\n",
       "                        -8.0778e-02, -2.0288e-01],\n",
       "                       [-2.2371e-02,  1.6820e-01,  2.3516e-01,  ...,  1.6225e-01,\n",
       "                        -1.8740e-01, -8.7370e-02]],\n",
       "              \n",
       "                      [[-1.6053e-01,  3.8948e-02, -3.2161e-02,  ..., -1.0024e-01,\n",
       "                         6.0857e-02, -1.5405e-03],\n",
       "                       [ 1.6323e-01, -1.2738e-01,  2.6392e-02,  ...,  3.0294e-02,\n",
       "                         2.4408e-01, -6.6949e-02],\n",
       "                       [-1.9607e-01,  1.9093e-01,  2.3129e-01,  ..., -2.1628e-01,\n",
       "                        -1.0836e-01, -4.3779e-02],\n",
       "                       ...,\n",
       "                       [-2.0010e-01,  1.0740e-01, -1.1748e-01,  ..., -2.2279e-01,\n",
       "                         1.0304e-01,  3.1003e-02],\n",
       "                       [-1.4173e-01, -2.0939e-01,  1.4940e-01,  ..., -9.8601e-02,\n",
       "                        -7.3702e-02,  5.4268e-02],\n",
       "                       [ 1.4318e-01,  1.4332e-01, -1.3077e-01,  ...,  1.1926e-01,\n",
       "                         2.3388e-01, -9.7177e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 2.3044e-01, -1.6723e-01,  7.3660e-02,  ..., -8.6801e-02,\n",
       "                         1.9197e-01, -1.2039e-02],\n",
       "                       [-1.4625e-01,  1.1690e-01,  6.7002e-02,  ..., -1.9067e-01,\n",
       "                         1.6861e-01,  1.2483e-01],\n",
       "                       [ 1.8994e-01,  1.4377e-01,  1.0396e-01,  ...,  1.7595e-01,\n",
       "                        -1.4694e-01, -2.4494e-01],\n",
       "                       ...,\n",
       "                       [ 1.5261e-01, -8.5687e-02, -1.4152e-01,  ...,  1.0393e-01,\n",
       "                        -2.3815e-01,  6.5770e-02],\n",
       "                       [ 2.2986e-01, -1.1932e-01,  1.7938e-01,  ..., -1.3753e-02,\n",
       "                         1.9265e-01, -8.3212e-03],\n",
       "                       [ 8.7890e-02,  8.5026e-02, -1.3457e-01,  ...,  2.8934e-02,\n",
       "                         1.3038e-01, -1.4725e-01]],\n",
       "              \n",
       "                      [[-4.3531e-02,  7.9497e-02, -1.7760e-01,  ..., -1.6695e-01,\n",
       "                         9.6662e-02, -6.5613e-02],\n",
       "                       [-1.4178e-02,  1.4363e-01,  6.6925e-02,  ..., -1.5235e-01,\n",
       "                        -5.3335e-02, -7.8702e-02],\n",
       "                       [-1.7347e-01, -1.3215e-01, -2.4931e-01,  ...,  2.0949e-01,\n",
       "                        -8.5758e-02, -4.3180e-02],\n",
       "                       ...,\n",
       "                       [-8.7420e-02,  1.2705e-01,  2.3223e-01,  ..., -1.4286e-02,\n",
       "                        -1.6309e-01, -8.5886e-02],\n",
       "                       [ 3.8874e-02,  1.2059e-01,  2.2732e-01,  ...,  1.0371e-01,\n",
       "                        -9.7819e-02, -1.3683e-01],\n",
       "                       [-2.3264e-02,  8.4264e-02,  1.8759e-01,  ..., -1.0091e-01,\n",
       "                         1.6325e-01, -1.9205e-01]],\n",
       "              \n",
       "                      [[ 1.5164e-01,  2.3470e-01, -4.8335e-02,  ...,  2.0655e-01,\n",
       "                         1.3178e-01, -9.0694e-02],\n",
       "                       [-1.7944e-01,  1.1973e-01, -1.6095e-01,  ..., -1.7929e-01,\n",
       "                        -7.2523e-02,  1.3765e-01],\n",
       "                       [-1.3436e-01, -1.1979e-02,  7.6681e-02,  ..., -4.7195e-02,\n",
       "                        -1.5946e-02,  2.1277e-01],\n",
       "                       ...,\n",
       "                       [-1.0305e-01, -1.5390e-04,  4.9355e-02,  ...,  4.8181e-03,\n",
       "                         1.1845e-02,  1.8267e-01],\n",
       "                       [-2.0533e-01,  1.0019e-01,  6.1733e-02,  ...,  7.6489e-02,\n",
       "                         1.1228e-01,  2.3666e-02],\n",
       "                       [-5.1512e-02,  2.0132e-01,  7.6634e-02,  ..., -3.3881e-02,\n",
       "                         1.1157e-01,  5.5126e-02]]])),\n",
       "             ('embedder_act.layers.1.0.module.W_key',\n",
       "              tensor([[[-7.4121e-02,  2.4419e-01,  2.1129e-01,  ..., -1.3187e-01,\n",
       "                        -1.3974e-02,  1.5405e-01],\n",
       "                       [-1.6890e-01,  2.3777e-01, -2.1621e-01,  ...,  1.7673e-01,\n",
       "                        -1.6880e-01, -2.1578e-01],\n",
       "                       [ 1.7321e-03,  1.7355e-01, -1.3246e-01,  ...,  9.2509e-02,\n",
       "                         3.7717e-02,  2.4307e-01],\n",
       "                       ...,\n",
       "                       [-1.6770e-01,  9.5147e-03, -2.0649e-01,  ..., -5.2764e-02,\n",
       "                        -2.4580e-01, -1.5504e-01],\n",
       "                       [ 2.2826e-01,  8.4796e-02, -9.0070e-02,  ..., -2.3076e-01,\n",
       "                        -2.9191e-02, -1.6351e-02],\n",
       "                       [-1.8996e-01,  1.7130e-01, -7.4318e-03,  ...,  6.9951e-03,\n",
       "                         7.4350e-02, -3.4213e-02]],\n",
       "              \n",
       "                      [[ 1.3566e-01,  2.4506e-04,  2.8600e-02,  ..., -2.0141e-01,\n",
       "                         6.9076e-02,  1.9477e-02],\n",
       "                       [ 6.6217e-02,  8.7503e-02, -4.6558e-02,  ..., -2.0383e-02,\n",
       "                        -1.1569e-01, -1.4297e-01],\n",
       "                       [-2.4243e-01,  1.3046e-02, -3.4932e-02,  ..., -1.5910e-02,\n",
       "                         3.4079e-02, -1.0158e-01],\n",
       "                       ...,\n",
       "                       [-6.1532e-02, -2.0340e-01, -1.8066e-01,  ..., -2.4087e-01,\n",
       "                         6.6932e-02,  2.9670e-02],\n",
       "                       [-2.0512e-01, -1.6790e-01, -1.2059e-01,  ..., -1.2552e-01,\n",
       "                         6.1169e-02, -1.1831e-01],\n",
       "                       [ 9.2454e-03,  1.0600e-01, -8.9157e-02,  ...,  2.4435e-01,\n",
       "                        -1.1203e-01,  1.5472e-01]],\n",
       "              \n",
       "                      [[-7.0245e-03,  7.4630e-02,  2.4963e-01,  ..., -2.2181e-01,\n",
       "                         1.7635e-01, -2.1570e-01],\n",
       "                       [ 1.2471e-01,  2.2964e-01, -2.8122e-02,  ..., -1.6421e-01,\n",
       "                         1.5948e-01,  1.2596e-01],\n",
       "                       [ 2.2477e-01,  5.5138e-02, -8.0701e-02,  ..., -1.9791e-01,\n",
       "                         1.5286e-01, -8.6199e-02],\n",
       "                       ...,\n",
       "                       [ 1.0386e-01,  1.8405e-01,  9.1035e-02,  ..., -3.2718e-02,\n",
       "                        -1.0309e-01, -6.5925e-02],\n",
       "                       [ 1.2080e-01,  4.7563e-02, -2.3886e-01,  ..., -4.3480e-02,\n",
       "                         1.2380e-01, -2.1762e-01],\n",
       "                       [-5.7780e-02, -4.4405e-02, -2.2289e-01,  ..., -2.1500e-01,\n",
       "                        -4.0119e-02,  1.5095e-01]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-2.2889e-01, -1.1383e-01, -9.6095e-02,  ..., -9.1417e-02,\n",
       "                        -1.5786e-01, -5.4387e-02],\n",
       "                       [-2.2897e-01, -6.4001e-02,  1.2297e-01,  ...,  2.1122e-01,\n",
       "                        -2.0061e-01, -2.3492e-01],\n",
       "                       [-2.6546e-02, -8.2714e-02, -1.5112e-01,  ...,  8.9694e-02,\n",
       "                         1.6997e-01, -6.4233e-02],\n",
       "                       ...,\n",
       "                       [ 2.0246e-01,  1.7387e-01, -1.2891e-01,  ...,  7.7680e-03,\n",
       "                         1.9704e-01,  1.6241e-01],\n",
       "                       [-2.2844e-01, -7.3186e-03, -2.3092e-01,  ...,  1.3331e-01,\n",
       "                         3.5922e-02, -7.6546e-02],\n",
       "                       [-1.0983e-01,  2.4809e-01,  7.8195e-02,  ...,  1.8651e-01,\n",
       "                        -2.3831e-01, -4.5840e-02]],\n",
       "              \n",
       "                      [[-2.2162e-01, -5.7744e-02, -2.0094e-01,  ..., -1.1176e-01,\n",
       "                         1.4278e-01,  1.9146e-01],\n",
       "                       [ 1.1198e-02,  6.2708e-02, -2.1567e-01,  ..., -5.2049e-02,\n",
       "                        -4.3813e-02,  2.0537e-01],\n",
       "                       [-4.5653e-02, -1.0238e-01, -1.8931e-01,  ..., -4.0141e-02,\n",
       "                         6.5092e-02,  1.3478e-01],\n",
       "                       ...,\n",
       "                       [ 1.4610e-01, -2.4228e-01, -1.1071e-01,  ..., -4.1144e-02,\n",
       "                         2.1784e-01, -2.8009e-03],\n",
       "                       [ 1.7916e-02,  4.0724e-02, -2.6148e-02,  ..., -1.5745e-01,\n",
       "                        -2.0946e-01,  1.4369e-01],\n",
       "                       [ 3.5790e-02,  1.5178e-02, -1.5633e-01,  ...,  1.3380e-01,\n",
       "                         5.6842e-02,  2.3982e-01]],\n",
       "              \n",
       "                      [[ 8.4607e-02, -4.1155e-02, -6.2472e-02,  ..., -1.3873e-01,\n",
       "                        -2.3447e-01, -3.9126e-02],\n",
       "                       [-9.4973e-02, -9.5590e-02,  1.1058e-01,  ..., -2.3768e-01,\n",
       "                        -2.3410e-01, -4.6700e-02],\n",
       "                       [ 1.4575e-01, -2.4286e-01, -8.0815e-02,  ...,  2.0072e-01,\n",
       "                         3.6661e-02,  9.3830e-02],\n",
       "                       ...,\n",
       "                       [-1.1918e-02, -1.3525e-01, -4.1730e-02,  ..., -9.8343e-02,\n",
       "                         2.4543e-01,  2.0387e-01],\n",
       "                       [ 7.8990e-02,  1.9386e-01,  2.4885e-02,  ...,  1.1890e-02,\n",
       "                        -1.4679e-01,  1.4161e-01],\n",
       "                       [ 6.1865e-02,  1.1014e-01, -2.0556e-01,  ...,  1.3787e-01,\n",
       "                        -1.1198e-01, -4.2792e-02]]])),\n",
       "             ('embedder_act.layers.1.0.module.W_val',\n",
       "              tensor([[[ 0.0785,  0.0525, -0.1064,  ...,  0.1030,  0.1756, -0.2281],\n",
       "                       [ 0.0498, -0.0820, -0.2240,  ..., -0.1338,  0.0469,  0.0310],\n",
       "                       [-0.1573, -0.1030, -0.0326,  ..., -0.2259,  0.1127,  0.1692],\n",
       "                       ...,\n",
       "                       [ 0.0572, -0.0037,  0.2317,  ...,  0.0264,  0.1330, -0.0755],\n",
       "                       [ 0.1463,  0.2086, -0.0267,  ...,  0.1961,  0.0080, -0.0802],\n",
       "                       [-0.1053,  0.0981,  0.1712,  ...,  0.0585,  0.0944,  0.1271]],\n",
       "              \n",
       "                      [[ 0.0317, -0.0738,  0.2206,  ...,  0.2182,  0.0704, -0.1073],\n",
       "                       [ 0.2405, -0.0846, -0.0298,  ...,  0.1237,  0.0098, -0.1388],\n",
       "                       [-0.1699,  0.0850,  0.2215,  ..., -0.1837,  0.0750, -0.1566],\n",
       "                       ...,\n",
       "                       [-0.0315, -0.1536,  0.1253,  ..., -0.1279,  0.0927, -0.1472],\n",
       "                       [-0.1444, -0.0553,  0.0329,  ..., -0.1570,  0.0611, -0.0868],\n",
       "                       [ 0.0898, -0.0391, -0.1246,  ...,  0.1298,  0.1421, -0.0567]],\n",
       "              \n",
       "                      [[ 0.1661,  0.0945,  0.0396,  ...,  0.2379,  0.1594, -0.0340],\n",
       "                       [-0.0444,  0.2382, -0.0606,  ...,  0.0963,  0.0181,  0.1233],\n",
       "                       [ 0.1273,  0.1612,  0.0201,  ..., -0.1627, -0.0558, -0.1631],\n",
       "                       ...,\n",
       "                       [-0.0367,  0.0480,  0.1557,  ...,  0.1796, -0.0672,  0.1988],\n",
       "                       [ 0.2049, -0.1293,  0.2379,  ...,  0.1871,  0.0649,  0.0021],\n",
       "                       [-0.2476, -0.1054, -0.0006,  ..., -0.1906,  0.1959, -0.0944]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.2491,  0.1487,  0.1900,  ...,  0.1017, -0.1150,  0.1687],\n",
       "                       [ 0.0157,  0.0215,  0.0581,  ..., -0.1907,  0.0658,  0.1909],\n",
       "                       [ 0.0671, -0.1095, -0.0036,  ...,  0.1082, -0.0061, -0.2014],\n",
       "                       ...,\n",
       "                       [ 0.1970,  0.2440, -0.1767,  ...,  0.1117, -0.2298, -0.2399],\n",
       "                       [ 0.1377, -0.0845,  0.0187,  ..., -0.1454,  0.2186,  0.1761],\n",
       "                       [-0.0894, -0.2297, -0.0551,  ...,  0.0679,  0.0667, -0.1101]],\n",
       "              \n",
       "                      [[-0.1559,  0.0450, -0.0084,  ..., -0.2079,  0.0037, -0.2426],\n",
       "                       [-0.0234, -0.1378,  0.0029,  ...,  0.1388, -0.2475,  0.0158],\n",
       "                       [ 0.0775, -0.1551,  0.1782,  ...,  0.1508, -0.1043,  0.0005],\n",
       "                       ...,\n",
       "                       [-0.0176,  0.2056, -0.0277,  ...,  0.2154, -0.1020, -0.0099],\n",
       "                       [-0.0931,  0.1724,  0.0131,  ..., -0.0454,  0.1268, -0.1187],\n",
       "                       [ 0.1690,  0.1146, -0.2088,  ...,  0.0623,  0.1856,  0.0605]],\n",
       "              \n",
       "                      [[-0.1418,  0.2408, -0.1407,  ...,  0.1510, -0.0786,  0.1876],\n",
       "                       [ 0.0752, -0.0700, -0.1275,  ..., -0.0249, -0.1402,  0.0332],\n",
       "                       [ 0.1146, -0.2000,  0.1865,  ..., -0.0627,  0.0558,  0.1051],\n",
       "                       ...,\n",
       "                       [ 0.2491,  0.1955, -0.0668,  ..., -0.0772, -0.1574,  0.0715],\n",
       "                       [-0.1178,  0.1605, -0.2310,  ...,  0.0116,  0.1058, -0.1990],\n",
       "                       [-0.0492, -0.1057, -0.0507,  ...,  0.2360,  0.2376,  0.0406]]])),\n",
       "             ('embedder_act.layers.1.0.module.W_out',\n",
       "              tensor([[[-0.0601, -0.0290, -0.0782,  ..., -0.0241, -0.0101, -0.0689],\n",
       "                       [-0.0218, -0.0451, -0.0040,  ...,  0.0859, -0.0812,  0.0780],\n",
       "                       [-0.0125, -0.0705,  0.0843,  ..., -0.0305,  0.0483,  0.0803],\n",
       "                       ...,\n",
       "                       [ 0.0492,  0.0736, -0.0066,  ...,  0.0155, -0.0649, -0.0844],\n",
       "                       [ 0.0397, -0.0240,  0.0777,  ...,  0.0478, -0.0121, -0.0670],\n",
       "                       [-0.0872, -0.0283,  0.0372,  ..., -0.0217, -0.0343,  0.0061]],\n",
       "              \n",
       "                      [[ 0.0797,  0.0392, -0.0806,  ..., -0.0358, -0.0349, -0.0798],\n",
       "                       [ 0.0633, -0.0746, -0.0033,  ...,  0.0459,  0.0398,  0.0050],\n",
       "                       [ 0.0868, -0.0704, -0.0213,  ..., -0.0469, -0.0798, -0.0350],\n",
       "                       ...,\n",
       "                       [-0.0612, -0.0372,  0.0006,  ...,  0.0644, -0.0399,  0.0200],\n",
       "                       [-0.0538,  0.0134, -0.0090,  ..., -0.0285, -0.0498, -0.0205],\n",
       "                       [-0.0207,  0.0294,  0.0537,  ...,  0.0607,  0.0367,  0.0415]],\n",
       "              \n",
       "                      [[ 0.0743, -0.0146, -0.0599,  ..., -0.0657, -0.0606,  0.0460],\n",
       "                       [ 0.0706, -0.0397,  0.0394,  ..., -0.0754,  0.0289,  0.0837],\n",
       "                       [-0.0569, -0.0556, -0.0192,  ..., -0.0400, -0.0439,  0.0096],\n",
       "                       ...,\n",
       "                       [-0.0813,  0.0358,  0.0381,  ..., -0.0322, -0.0795, -0.0725],\n",
       "                       [-0.0328, -0.0716,  0.0691,  ..., -0.0277,  0.0207, -0.0678],\n",
       "                       [-0.0167,  0.0138, -0.0852,  ...,  0.0329, -0.0826, -0.0145]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0058,  0.0315, -0.0832,  ...,  0.0333, -0.0361,  0.0767],\n",
       "                       [-0.0611, -0.0359, -0.0692,  ...,  0.0107,  0.0433,  0.0377],\n",
       "                       [-0.0096,  0.0146, -0.0725,  ...,  0.0529,  0.0869,  0.0724],\n",
       "                       ...,\n",
       "                       [-0.0149,  0.0765, -0.0229,  ...,  0.0850,  0.0754,  0.0567],\n",
       "                       [ 0.0386,  0.0130, -0.0008,  ..., -0.0412, -0.0302, -0.0687],\n",
       "                       [-0.0496, -0.0264,  0.0839,  ...,  0.0588, -0.0029,  0.0383]],\n",
       "              \n",
       "                      [[-0.0375,  0.0799,  0.0706,  ...,  0.0742,  0.0267, -0.0155],\n",
       "                       [-0.0687, -0.0090,  0.0826,  ..., -0.0033, -0.0590, -0.0777],\n",
       "                       [ 0.0042, -0.0491, -0.0332,  ...,  0.0275, -0.0874,  0.0859],\n",
       "                       ...,\n",
       "                       [-0.0030,  0.0051,  0.0801,  ...,  0.0558, -0.0696,  0.0859],\n",
       "                       [-0.0324, -0.0709,  0.0518,  ..., -0.0626,  0.0405, -0.0245],\n",
       "                       [-0.0780,  0.0774,  0.0309,  ..., -0.0047,  0.0514,  0.0650]],\n",
       "              \n",
       "                      [[ 0.0716,  0.0597, -0.0844,  ...,  0.0594, -0.0257,  0.0056],\n",
       "                       [ 0.0645,  0.0475,  0.0840,  ..., -0.0548, -0.0479,  0.0870],\n",
       "                       [ 0.0831, -0.0125, -0.0077,  ..., -0.0394,  0.0194,  0.0403],\n",
       "                       ...,\n",
       "                       [-0.0467, -0.0685, -0.0129,  ...,  0.0505,  0.0500,  0.0274],\n",
       "                       [-0.0566, -0.0201,  0.0883,  ..., -0.0865,  0.0309, -0.0230],\n",
       "                       [-0.0116,  0.0172, -0.0464,  ...,  0.0055, -0.0092,  0.0690]]])),\n",
       "             ('embedder_act.layers.1.1.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder_act.layers.1.1.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder_act.layers.1.1.normalizer.running_mean',\n",
       "              tensor([-2.9292e-04,  1.8402e-02,  1.0524e-02, -2.8078e-03, -2.0223e-03,\n",
       "                      -1.2956e-02, -9.2303e-03, -1.4052e-02,  1.7225e-03, -7.5201e-03,\n",
       "                       5.4383e-04,  2.6159e-02, -6.1849e-03,  1.9697e-02, -8.6576e-03,\n",
       "                      -1.1247e-02,  7.3264e-03,  4.0770e-03,  6.2399e-03, -4.0591e-03,\n",
       "                       1.7665e-02,  1.1047e-02,  2.2886e-02, -3.5586e-03,  2.4933e-04,\n",
       "                      -5.3631e-03, -1.1704e-02, -2.8947e-03, -2.2865e-03, -7.0784e-03,\n",
       "                      -5.6885e-03,  2.0755e-03,  1.7203e-03,  4.1294e-04, -3.0295e-03,\n",
       "                      -3.7276e-03,  4.8519e-03, -6.4662e-03,  7.6052e-03,  3.7959e-03,\n",
       "                      -6.5880e-03, -1.6328e-03,  7.5447e-03, -8.5545e-03,  1.4567e-02,\n",
       "                       1.3084e-03, -4.9745e-03,  9.4066e-03, -1.6474e-02, -1.3408e-02,\n",
       "                      -5.7060e-03, -9.5000e-03, -1.7764e-02, -2.7849e-02,  7.6702e-03,\n",
       "                      -1.7851e-02, -4.2213e-03,  9.5752e-03, -4.8516e-03,  5.7831e-03,\n",
       "                       5.2897e-03,  5.5068e-03, -6.8488e-03, -2.4509e-05, -1.1836e-02,\n",
       "                       6.9106e-04, -5.8921e-03,  5.6442e-04,  5.2413e-04, -2.5658e-02,\n",
       "                       9.7098e-03, -1.6093e-02, -5.5291e-04,  5.4726e-03,  1.6116e-02,\n",
       "                       1.1415e-02,  1.1121e-02,  1.1665e-02, -9.1051e-03, -8.7283e-03,\n",
       "                       1.3328e-02, -1.7919e-02,  1.0455e-02, -1.0772e-03,  6.9451e-04,\n",
       "                       1.4235e-02,  1.3988e-02, -1.6866e-03, -3.6832e-03, -6.1205e-03,\n",
       "                       4.6214e-03,  1.0121e-02, -7.5930e-04, -5.6873e-03, -1.5995e-02,\n",
       "                       6.4490e-03, -8.5157e-03, -2.3085e-03, -3.7526e-03, -2.2957e-02,\n",
       "                      -4.7536e-03, -1.8131e-02,  3.0530e-03, -1.5175e-02, -1.0277e-02,\n",
       "                      -1.4724e-02,  4.7642e-03,  1.4682e-02, -1.7397e-02,  2.0506e-04,\n",
       "                      -4.4344e-03, -1.3402e-02, -1.7428e-02, -3.9387e-03, -1.5140e-03,\n",
       "                      -1.5000e-02, -7.5054e-03, -7.0512e-03,  6.3090e-03, -1.1778e-04,\n",
       "                      -1.4073e-02, -3.0434e-03, -8.5438e-03, -2.2203e-02, -1.6426e-02,\n",
       "                      -8.9153e-04, -1.1712e-02,  4.4703e-03])),\n",
       "             ('embedder_act.layers.1.1.normalizer.running_var',\n",
       "              tensor([0.9710, 1.0823, 1.0517, 1.0424, 0.9956, 1.0250, 0.9466, 0.9126, 0.9467,\n",
       "                      1.1533, 1.0091, 1.2343, 1.2586, 1.2614, 1.0769, 1.1688, 0.9825, 1.0581,\n",
       "                      1.1831, 1.0342, 1.1892, 1.1276, 1.2350, 1.0881, 1.0339, 1.1124, 1.2796,\n",
       "                      1.0554, 1.0204, 1.4030, 0.9518, 1.0396, 1.1684, 0.9826, 1.0046, 0.9985,\n",
       "                      1.1143, 0.9979, 0.9395, 0.9442, 1.3991, 0.9235, 1.3389, 0.9273, 1.1629,\n",
       "                      1.2223, 1.0605, 1.0408, 1.1103, 1.1476, 1.1770, 1.3391, 1.1470, 1.2322,\n",
       "                      1.2430, 1.0897, 1.0624, 1.0783, 1.0802, 1.4720, 1.0361, 1.0143, 1.6192,\n",
       "                      1.6362, 1.1552, 0.9618, 0.9649, 1.0980, 1.3792, 0.9265, 0.9737, 1.0762,\n",
       "                      0.9140, 1.1109, 0.9882, 0.9812, 1.0546, 0.9512, 1.0300, 1.2178, 1.0483,\n",
       "                      1.1535, 0.9943, 1.0039, 0.9390, 1.0016, 1.0800, 1.1248, 0.9318, 1.0848,\n",
       "                      1.2295, 0.9670, 1.3758, 0.9728, 1.3631, 0.9393, 0.9212, 1.0658, 1.1043,\n",
       "                      1.5195, 0.9331, 1.2831, 1.2035, 0.9663, 1.1661, 1.1812, 1.1373, 1.0787,\n",
       "                      1.0789, 1.4908, 0.9956, 1.3038, 1.0409, 1.3870, 1.2043, 1.1259, 0.9429,\n",
       "                      1.1538, 0.9874, 1.2177, 1.0675, 1.4284, 1.2381, 1.0197, 0.9163, 1.0796,\n",
       "                      0.9941, 1.0972])),\n",
       "             ('embedder_act.layers.1.1.normalizer.num_batches_tracked',\n",
       "              tensor(1)),\n",
       "             ('embedder_act.layers.1.2.module.0.weight',\n",
       "              tensor([[-0.0264, -0.0787,  0.0143,  ...,  0.0533, -0.0266,  0.0077],\n",
       "                      [ 0.0090,  0.0838, -0.0643,  ...,  0.0690,  0.0649,  0.0720],\n",
       "                      [-0.0825,  0.0468,  0.0739,  ...,  0.0607, -0.0725,  0.0598],\n",
       "                      ...,\n",
       "                      [-0.0762,  0.0549,  0.0208,  ..., -0.0745,  0.0839, -0.0198],\n",
       "                      [ 0.0129, -0.0411,  0.0550,  ...,  0.0800,  0.0261, -0.0205],\n",
       "                      [-0.0810,  0.0464, -0.0150,  ...,  0.0352,  0.0822, -0.0882]])),\n",
       "             ('embedder_act.layers.1.2.module.0.bias',\n",
       "              tensor([-0.0218,  0.0599, -0.0435,  0.0154, -0.0778,  0.0603,  0.0746,  0.0737,\n",
       "                      -0.0758,  0.0803, -0.0177, -0.0230,  0.0523, -0.0072, -0.0532, -0.0839,\n",
       "                      -0.0040,  0.0362, -0.0857, -0.0149, -0.0617, -0.0067,  0.0179, -0.0109,\n",
       "                      -0.0810,  0.0842,  0.0358, -0.0775,  0.0471, -0.0015,  0.0742, -0.0738,\n",
       "                       0.0350,  0.0465,  0.0507,  0.0791, -0.0238,  0.0091, -0.0124, -0.0198,\n",
       "                      -0.0264,  0.0618, -0.0846, -0.0598, -0.0388,  0.0500, -0.0580,  0.0748,\n",
       "                       0.0383,  0.0799,  0.0079,  0.0206, -0.0738,  0.0143, -0.0707, -0.0139,\n",
       "                      -0.0063,  0.0851,  0.0643,  0.0541, -0.0872, -0.0126,  0.0175,  0.0247,\n",
       "                       0.0570, -0.0559,  0.0822,  0.0443,  0.0730,  0.0646,  0.0284,  0.0575,\n",
       "                       0.0197, -0.0505, -0.0516,  0.0329,  0.0535,  0.0352, -0.0115,  0.0849,\n",
       "                      -0.0529, -0.0073, -0.0469,  0.0288, -0.0819,  0.0362, -0.0829, -0.0042,\n",
       "                      -0.0846,  0.0100,  0.0607,  0.0396,  0.0761, -0.0432,  0.0299, -0.0844,\n",
       "                       0.0333,  0.0823, -0.0173,  0.0605,  0.0865,  0.0291,  0.0502,  0.0455,\n",
       "                       0.0867, -0.0615,  0.0391,  0.0865, -0.0569, -0.0595, -0.0406,  0.0441,\n",
       "                      -0.0258, -0.0085,  0.0422,  0.0636,  0.0876, -0.0497, -0.0329,  0.0233,\n",
       "                      -0.0121, -0.0555, -0.0135, -0.0231,  0.0132, -0.0516,  0.0784,  0.0635,\n",
       "                       0.0728,  0.0231,  0.0207,  0.0143, -0.0604, -0.0801,  0.0463,  0.0373,\n",
       "                      -0.0657,  0.0529, -0.0379,  0.0477, -0.0012, -0.0347, -0.0210, -0.0316,\n",
       "                       0.0235, -0.0120, -0.0299,  0.0521, -0.0679,  0.0652,  0.0055,  0.0704,\n",
       "                      -0.0631, -0.0083, -0.0108,  0.0624, -0.0025, -0.0639,  0.0567, -0.0580,\n",
       "                       0.0620,  0.0696, -0.0882,  0.0171,  0.0655,  0.0201, -0.0868, -0.0807,\n",
       "                       0.0579,  0.0199, -0.0613,  0.0521, -0.0281,  0.0671,  0.0636,  0.0820,\n",
       "                      -0.0843, -0.0223,  0.0763,  0.0240,  0.0846,  0.0746,  0.0604, -0.0677,\n",
       "                      -0.0757,  0.0294,  0.0745,  0.0700, -0.0755,  0.0704, -0.0334,  0.0623,\n",
       "                      -0.0789, -0.0430, -0.0808, -0.0459, -0.0681, -0.0539, -0.0184,  0.0775,\n",
       "                      -0.0489, -0.0626,  0.0657,  0.0585, -0.0748, -0.0213,  0.0544,  0.0557,\n",
       "                      -0.0594, -0.0155, -0.0300,  0.0296, -0.0023, -0.0398,  0.0827, -0.0718,\n",
       "                       0.0085, -0.0020,  0.0244,  0.0404,  0.0114, -0.0588, -0.0606, -0.0299,\n",
       "                       0.0856, -0.0552, -0.0809,  0.0595, -0.0825, -0.0687,  0.0543,  0.0133,\n",
       "                      -0.0796, -0.0327, -0.0523, -0.0136,  0.0340,  0.0465, -0.0521, -0.0380,\n",
       "                       0.0752,  0.0052, -0.0298,  0.0124,  0.0494, -0.0257,  0.0273, -0.0378,\n",
       "                      -0.0337,  0.0524, -0.0069,  0.0129,  0.0053,  0.0509, -0.0243,  0.0190,\n",
       "                       0.0581,  0.0260,  0.0681, -0.0697, -0.0571,  0.0394,  0.0081,  0.0177,\n",
       "                      -0.0628, -0.0467, -0.0599, -0.0729,  0.0426, -0.0178,  0.0470,  0.0535,\n",
       "                       0.0455,  0.0668, -0.0483,  0.0059, -0.0554, -0.0224,  0.0481,  0.0677,\n",
       "                      -0.0159, -0.0688,  0.0199,  0.0187,  0.0008,  0.0083,  0.0631,  0.0792,\n",
       "                      -0.0346, -0.0647, -0.0596, -0.0008,  0.0722,  0.0663,  0.0591,  0.0287,\n",
       "                      -0.0261,  0.0580, -0.0624,  0.0659, -0.0796, -0.0873,  0.0670,  0.0668,\n",
       "                       0.0839, -0.0659, -0.0223,  0.0862, -0.0657,  0.0480, -0.0032,  0.0880,\n",
       "                       0.0181, -0.0005, -0.0280, -0.0046, -0.0345, -0.0505, -0.0784,  0.0838,\n",
       "                       0.0112, -0.0820, -0.0344, -0.0040, -0.0036, -0.0072, -0.0026,  0.0608,\n",
       "                       0.0059, -0.0415, -0.0308,  0.0391, -0.0139, -0.0555,  0.0121, -0.0115,\n",
       "                       0.0445,  0.0261, -0.0201,  0.0159, -0.0325, -0.0032, -0.0678, -0.0433,\n",
       "                       0.0322,  0.0310, -0.0502,  0.0292,  0.0261, -0.0506,  0.0258,  0.0774,\n",
       "                      -0.0472,  0.0223, -0.0175, -0.0484, -0.0030,  0.0338, -0.0148, -0.0139,\n",
       "                       0.0332, -0.0856,  0.0500,  0.0043, -0.0676, -0.0447,  0.0171,  0.0813,\n",
       "                       0.0419,  0.0354, -0.0799,  0.0279, -0.0882,  0.0428,  0.0187, -0.0211,\n",
       "                       0.0113, -0.0209,  0.0033, -0.0843,  0.0314, -0.0420, -0.0515, -0.0389,\n",
       "                      -0.0449,  0.0545,  0.0720, -0.0544,  0.0141,  0.0196,  0.0849, -0.0665,\n",
       "                       0.0010,  0.0806,  0.0880, -0.0444, -0.0852,  0.0009,  0.0037,  0.0874,\n",
       "                       0.0732, -0.0134,  0.0626,  0.0524, -0.0453,  0.0247,  0.0517,  0.0760,\n",
       "                      -0.0242, -0.0114, -0.0466,  0.0252, -0.0275,  0.0438, -0.0528, -0.0292,\n",
       "                      -0.0314, -0.0350, -0.0111,  0.0173, -0.0339, -0.0646, -0.0193, -0.0528,\n",
       "                      -0.0390, -0.0454,  0.0743, -0.0346, -0.0652,  0.0597,  0.0863, -0.0049,\n",
       "                      -0.0618, -0.0542, -0.0812, -0.0333, -0.0062, -0.0620,  0.0052,  0.0677,\n",
       "                      -0.0536,  0.0369,  0.0003, -0.0595,  0.0273, -0.0227, -0.0026,  0.0769,\n",
       "                       0.0794, -0.0742,  0.0076, -0.0760,  0.0132, -0.0869,  0.0162, -0.0279,\n",
       "                       0.0277, -0.0118, -0.0221,  0.0369, -0.0635, -0.0146, -0.0880, -0.0092,\n",
       "                       0.0775, -0.0193, -0.0731, -0.0614, -0.0187,  0.0238, -0.0855,  0.0777,\n",
       "                       0.0758,  0.0308, -0.0345, -0.0106,  0.0632, -0.0418, -0.0674,  0.0437,\n",
       "                      -0.0088, -0.0333,  0.0531, -0.0167,  0.0682, -0.0201,  0.0775,  0.0548,\n",
       "                       0.0749, -0.0029, -0.0645,  0.0542, -0.0817, -0.0518, -0.0068,  0.0188,\n",
       "                      -0.0153,  0.0368,  0.0458, -0.0087, -0.0377, -0.0879,  0.0814, -0.0555,\n",
       "                       0.0241,  0.0602, -0.0525,  0.0187, -0.0042,  0.0633,  0.0381,  0.0424])),\n",
       "             ('embedder_act.layers.1.2.module.2.weight',\n",
       "              tensor([[-0.0002, -0.0245, -0.0415,  ...,  0.0415,  0.0275, -0.0030],\n",
       "                      [ 0.0194, -0.0138, -0.0209,  ..., -0.0229,  0.0297, -0.0115],\n",
       "                      [ 0.0205, -0.0121,  0.0029,  ..., -0.0318, -0.0435,  0.0278],\n",
       "                      ...,\n",
       "                      [ 0.0204, -0.0216, -0.0211,  ...,  0.0167, -0.0265,  0.0210],\n",
       "                      [-0.0425,  0.0110, -0.0374,  ..., -0.0399,  0.0334,  0.0403],\n",
       "                      [-0.0323, -0.0074, -0.0234,  ..., -0.0253, -0.0280,  0.0164]])),\n",
       "             ('embedder_act.layers.1.2.module.2.bias',\n",
       "              tensor([-4.0174e-02,  2.6850e-02, -2.3984e-02, -1.6442e-02,  1.8566e-02,\n",
       "                       3.9489e-02, -2.9918e-02,  6.7059e-03,  1.0158e-02,  3.2934e-03,\n",
       "                       3.6193e-02,  3.2065e-02, -2.7813e-02,  4.0791e-02,  1.0987e-02,\n",
       "                       3.5862e-02,  3.9737e-02, -1.3194e-02, -7.9372e-03,  3.4888e-04,\n",
       "                       3.5414e-02, -3.3995e-02,  2.2175e-02, -2.3216e-02,  5.1306e-03,\n",
       "                       5.0080e-03,  3.8608e-02, -1.7838e-02, -1.3296e-02, -2.8910e-02,\n",
       "                       3.3393e-02,  1.9829e-03,  3.3033e-03, -2.9100e-02, -3.3802e-02,\n",
       "                       1.7102e-02, -3.1209e-03,  3.6264e-02,  1.5773e-02,  1.0646e-02,\n",
       "                       2.4770e-02, -1.7755e-02, -1.0376e-02, -3.8509e-02, -1.6640e-02,\n",
       "                       2.6204e-02, -4.4799e-03, -1.1072e-02,  2.2624e-05, -3.6706e-02,\n",
       "                       7.0021e-03, -3.8449e-02, -1.7839e-02, -2.1350e-02,  1.2281e-02,\n",
       "                       4.3416e-02,  1.4386e-03, -2.5438e-02,  1.0115e-02,  3.0611e-02,\n",
       "                      -9.0993e-03, -2.6080e-02, -7.0532e-03, -3.2844e-02,  4.3027e-02,\n",
       "                       3.7555e-02, -4.2990e-02, -1.9447e-02, -1.8419e-02, -4.2833e-02,\n",
       "                      -1.1470e-02,  2.1756e-02,  2.9899e-04,  2.0756e-02, -1.9045e-02,\n",
       "                       1.8157e-02,  3.6236e-02,  1.7464e-02, -2.6070e-02,  4.0501e-02,\n",
       "                      -2.7704e-02, -1.8570e-02,  9.6252e-03,  2.6669e-02,  5.0200e-03,\n",
       "                       4.0486e-02,  3.8397e-02,  3.5150e-02,  1.0226e-02,  3.3181e-02,\n",
       "                      -2.4629e-02,  1.5810e-02,  2.9477e-02, -2.7565e-02, -2.0219e-02,\n",
       "                       2.8152e-02, -3.8323e-02,  6.7010e-04, -3.1530e-03, -3.8776e-02,\n",
       "                      -1.5536e-02, -2.0007e-02,  4.3521e-02,  1.2924e-02, -4.3184e-02,\n",
       "                       1.5073e-02,  2.5942e-02,  2.2440e-02,  3.8534e-02,  7.9144e-03,\n",
       "                       4.3153e-02,  2.9363e-02, -4.3269e-02, -9.1606e-03,  1.0777e-02,\n",
       "                       3.1842e-02,  9.3568e-04,  2.6247e-02, -3.9522e-02, -1.2286e-02,\n",
       "                       3.1478e-02,  3.4903e-02,  4.2170e-02,  2.1318e-02, -8.3580e-03,\n",
       "                       1.0788e-02,  9.3983e-03, -2.2712e-02])),\n",
       "             ('embedder_act.layers.1.3.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder_act.layers.1.3.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder_act.layers.1.3.normalizer.running_mean',\n",
       "              tensor([ 0.0113,  0.0076, -0.0186, -0.0071, -0.0098, -0.0005, -0.0132, -0.0097,\n",
       "                      -0.0102, -0.0127,  0.0169,  0.0160,  0.0023, -0.0069,  0.0184,  0.0075,\n",
       "                       0.0007,  0.0090, -0.0074,  0.0011,  0.0019,  0.0018,  0.0152,  0.0280,\n",
       "                       0.0059,  0.0171,  0.0080, -0.0234, -0.0331, -0.0119,  0.0079, -0.0204,\n",
       "                      -0.0032, -0.0122,  0.0044, -0.0059,  0.0180, -0.0118, -0.0013, -0.0020,\n",
       "                       0.0147, -0.0307, -0.0139, -0.0237, -0.0108,  0.0393, -0.0201, -0.0155,\n",
       "                      -0.0108, -0.0348,  0.0071, -0.0031, -0.0007, -0.0193, -0.0048,  0.0214,\n",
       "                       0.0060, -0.0116,  0.0103,  0.0218, -0.0071, -0.0005,  0.0053,  0.0139,\n",
       "                       0.0149,  0.0201, -0.0130, -0.0154, -0.0376, -0.0008,  0.0203,  0.0190,\n",
       "                      -0.0139,  0.0024,  0.0043, -0.0168,  0.0018,  0.0123, -0.0057,  0.0041,\n",
       "                      -0.0202, -0.0059, -0.0080,  0.0308, -0.0072,  0.0122,  0.0048,  0.0136,\n",
       "                      -0.0189,  0.0077, -0.0077,  0.0191, -0.0103,  0.0021,  0.0135,  0.0122,\n",
       "                      -0.0101,  0.0075,  0.0092, -0.0020, -0.0024, -0.0028, -0.0092,  0.0004,\n",
       "                      -0.0014, -0.0167,  0.0107,  0.0103,  0.0155, -0.0032, -0.0069,  0.0137,\n",
       "                      -0.0250,  0.0020,  0.0078,  0.0100,  0.0041,  0.0128, -0.0155,  0.0068,\n",
       "                       0.0002, -0.0004, -0.0033,  0.0037, -0.0286, -0.0161,  0.0213, -0.0068])),\n",
       "             ('embedder_act.layers.1.3.normalizer.running_var',\n",
       "              tensor([0.9787, 1.0245, 1.0248, 1.0319, 1.0064, 1.0375, 1.0042, 0.9867, 1.0358,\n",
       "                      0.9956, 1.0094, 0.9830, 1.0004, 0.9934, 0.9947, 0.9939, 0.9957, 1.0007,\n",
       "                      1.0144, 0.9972, 1.0168, 1.0364, 0.9912, 0.9720, 1.0407, 1.0159, 0.9703,\n",
       "                      0.9985, 1.0213, 0.9929, 1.0301, 1.0421, 0.9994, 1.0253, 1.0353, 1.0197,\n",
       "                      1.0014, 1.0273, 0.9963, 0.9931, 1.0145, 0.9823, 1.0021, 0.9900, 1.0457,\n",
       "                      1.0259, 1.0032, 1.0415, 1.0008, 1.0071, 0.9778, 1.0294, 1.0063, 1.0011,\n",
       "                      1.0126, 1.0379, 1.0199, 1.0209, 0.9997, 0.9829, 1.0601, 1.0321, 1.0082,\n",
       "                      0.9617, 0.9585, 1.0147, 1.0037, 1.0006, 0.9886, 1.0580, 0.9880, 1.0014,\n",
       "                      1.0174, 0.9825, 1.0158, 0.9959, 0.9934, 1.0007, 0.9964, 0.9863, 1.0229,\n",
       "                      1.0304, 0.9877, 0.9780, 1.0003, 0.9917, 0.9956, 1.0084, 0.9857, 1.0002,\n",
       "                      0.9967, 0.9827, 0.9981, 0.9836, 1.0415, 0.9817, 0.9927, 1.0123, 1.0696,\n",
       "                      1.0637, 0.9901, 0.9989, 1.0227, 1.0074, 0.9987, 1.0114, 0.9953, 1.0058,\n",
       "                      1.0070, 0.9815, 1.0045, 1.0359, 1.0233, 1.0130, 1.0311, 1.0292, 0.9823,\n",
       "                      1.0041, 0.9744, 1.0045, 1.0034, 0.9978, 1.0386, 1.0163, 1.0110, 1.0175,\n",
       "                      1.0232, 1.0033])),\n",
       "             ('embedder_act.layers.1.3.normalizer.num_batches_tracked',\n",
       "              tensor(1)),\n",
       "             ('embedder_act.layers.2.0.module.W_query',\n",
       "              tensor([[[ 8.6114e-02, -1.9922e-01, -1.9657e-01,  ..., -8.2056e-02,\n",
       "                         3.9758e-02,  2.1402e-01],\n",
       "                       [ 2.0376e-01, -2.3581e-02, -2.0885e-01,  ...,  1.6749e-01,\n",
       "                        -1.9941e-01,  9.3068e-02],\n",
       "                       [ 1.9651e-02,  1.2798e-01,  1.2832e-01,  ..., -1.4924e-01,\n",
       "                         1.7668e-01, -4.3264e-03],\n",
       "                       ...,\n",
       "                       [-1.0593e-01, -5.8520e-03,  1.3649e-01,  ...,  7.9944e-02,\n",
       "                        -1.0865e-01, -2.4774e-01],\n",
       "                       [-1.0058e-01, -1.3336e-01,  3.2879e-02,  ...,  6.6254e-02,\n",
       "                         2.9963e-03,  1.3128e-01],\n",
       "                       [-1.3212e-01, -1.0797e-01,  7.2031e-02,  ..., -1.0316e-02,\n",
       "                        -1.7121e-01,  6.2597e-02]],\n",
       "              \n",
       "                      [[-2.4144e-01,  2.0546e-01, -1.4091e-01,  ..., -3.8162e-02,\n",
       "                         1.8743e-02, -2.0106e-01],\n",
       "                       [ 2.1167e-01, -2.4124e-01, -6.1946e-02,  ..., -1.4551e-01,\n",
       "                         1.9356e-01, -1.6030e-01],\n",
       "                       [ 7.5272e-02, -1.9747e-01, -2.0362e-01,  ..., -8.1070e-02,\n",
       "                         1.0017e-01, -4.8724e-03],\n",
       "                       ...,\n",
       "                       [ 6.2264e-02, -2.3453e-01, -1.7366e-02,  ...,  4.8246e-03,\n",
       "                        -3.1155e-02, -2.3227e-01],\n",
       "                       [-1.9641e-02, -2.1125e-01,  1.5042e-01,  ..., -1.8863e-01,\n",
       "                        -3.1346e-02,  2.3194e-01],\n",
       "                       [ 1.0635e-02, -2.2442e-01,  1.7626e-01,  ...,  1.1421e-01,\n",
       "                        -4.6604e-02, -8.8990e-02]],\n",
       "              \n",
       "                      [[ 3.9922e-02, -1.4195e-03,  1.6727e-01,  ...,  1.9838e-03,\n",
       "                         7.0883e-02, -6.0708e-02],\n",
       "                       [-1.9027e-01,  2.4315e-01, -1.3303e-01,  ...,  2.2842e-01,\n",
       "                         1.2650e-01,  1.9377e-01],\n",
       "                       [-1.9308e-01, -9.2558e-02, -1.1391e-01,  ..., -2.1177e-01,\n",
       "                         1.2868e-01, -9.5607e-02],\n",
       "                       ...,\n",
       "                       [-1.9813e-01,  2.4446e-02, -1.1552e-01,  ...,  2.1205e-01,\n",
       "                        -1.7201e-01,  2.2637e-02],\n",
       "                       [-1.4730e-02, -2.2126e-01,  1.8628e-01,  ...,  2.2843e-01,\n",
       "                         2.3466e-01, -1.2748e-01],\n",
       "                       [ 1.6837e-01,  2.4598e-01,  6.2150e-02,  ...,  9.0906e-02,\n",
       "                        -1.0051e-01, -6.8847e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 9.4710e-03, -1.0665e-01,  2.0825e-01,  ...,  5.5060e-02,\n",
       "                         6.5383e-02, -1.1183e-01],\n",
       "                       [ 1.9839e-01, -2.6560e-02,  1.7134e-01,  ..., -6.1573e-02,\n",
       "                        -2.0167e-02, -1.1393e-01],\n",
       "                       [-1.2218e-02,  6.8754e-02,  1.2456e-01,  ..., -1.4592e-01,\n",
       "                         9.9821e-02,  1.2439e-01],\n",
       "                       ...,\n",
       "                       [-2.2106e-01, -1.9380e-01,  1.9341e-01,  ..., -1.8001e-01,\n",
       "                         2.0795e-01,  2.1731e-01],\n",
       "                       [ 1.4406e-01,  1.7860e-01, -8.7482e-02,  ...,  3.3064e-02,\n",
       "                         1.2097e-01, -6.1740e-02],\n",
       "                       [-6.5371e-02, -1.0716e-01, -2.3664e-02,  ..., -1.7450e-01,\n",
       "                        -1.8052e-01, -1.0271e-02]],\n",
       "              \n",
       "                      [[-1.7619e-01, -2.2751e-01, -1.9288e-04,  ..., -1.6526e-01,\n",
       "                        -2.4860e-01, -2.3379e-01],\n",
       "                       [-2.0748e-01,  7.6764e-02,  7.6076e-02,  ...,  4.6728e-02,\n",
       "                         1.5152e-02, -1.8163e-01],\n",
       "                       [-1.1747e-01,  6.4672e-02,  1.0852e-01,  ..., -5.6016e-03,\n",
       "                        -2.3756e-01, -6.3356e-02],\n",
       "                       ...,\n",
       "                       [-6.4961e-02,  1.6416e-01, -7.3878e-02,  ...,  1.4504e-01,\n",
       "                        -1.5539e-01,  9.6525e-02],\n",
       "                       [ 1.6519e-01, -2.1897e-02,  1.6868e-01,  ...,  1.9905e-01,\n",
       "                        -1.0633e-01,  2.4474e-01],\n",
       "                       [ 1.1890e-01, -1.8881e-01,  4.6809e-03,  ...,  9.4656e-02,\n",
       "                        -5.4552e-02, -1.2481e-01]],\n",
       "              \n",
       "                      [[-2.3857e-01,  5.9392e-02, -1.3719e-02,  ..., -2.3633e-01,\n",
       "                        -1.1816e-01,  9.8244e-02],\n",
       "                       [-2.1803e-01, -4.8789e-02, -5.3619e-02,  ...,  3.8990e-02,\n",
       "                        -6.3679e-03, -2.4593e-01],\n",
       "                       [-1.2957e-01, -1.1338e-01,  1.5429e-01,  ..., -1.9549e-01,\n",
       "                         3.9476e-02,  1.9541e-01],\n",
       "                       ...,\n",
       "                       [-3.9039e-02,  1.6802e-01, -1.4721e-01,  ..., -1.5706e-02,\n",
       "                        -9.1925e-02, -3.4320e-03],\n",
       "                       [-1.1439e-02, -1.3850e-01,  1.2049e-01,  ...,  1.1561e-01,\n",
       "                         2.3083e-01,  1.6660e-01],\n",
       "                       [ 1.3372e-01, -2.2956e-01, -2.4374e-01,  ..., -4.9822e-02,\n",
       "                        -2.4155e-01, -1.3679e-01]]])),\n",
       "             ('embedder_act.layers.2.0.module.W_key',\n",
       "              tensor([[[ 0.0895, -0.0618,  0.0576,  ..., -0.0579, -0.0960, -0.1886],\n",
       "                       [ 0.2495, -0.2188,  0.0064,  ...,  0.0119, -0.0698, -0.2454],\n",
       "                       [ 0.0186,  0.2456,  0.2371,  ...,  0.0609, -0.1238,  0.0193],\n",
       "                       ...,\n",
       "                       [-0.1706, -0.2129, -0.0964,  ..., -0.1646,  0.2225,  0.2464],\n",
       "                       [-0.1032, -0.0268,  0.0986,  ..., -0.0641,  0.0227,  0.0977],\n",
       "                       [ 0.0648,  0.0766, -0.2311,  ...,  0.1777,  0.2356, -0.1873]],\n",
       "              \n",
       "                      [[ 0.1207, -0.0223,  0.0147,  ..., -0.0809,  0.2486,  0.0224],\n",
       "                       [-0.1056, -0.1635,  0.1173,  ...,  0.1721,  0.0662,  0.0177],\n",
       "                       [-0.1250,  0.2171,  0.0044,  ...,  0.1289,  0.2399, -0.0963],\n",
       "                       ...,\n",
       "                       [-0.1888, -0.0451, -0.1326,  ...,  0.2429, -0.2219,  0.1914],\n",
       "                       [ 0.0923,  0.1243, -0.1408,  ...,  0.0039, -0.2015, -0.0209],\n",
       "                       [-0.0053, -0.1392, -0.0674,  ..., -0.2240,  0.1262, -0.0565]],\n",
       "              \n",
       "                      [[-0.1960,  0.0139,  0.1043,  ..., -0.1122, -0.0575,  0.1374],\n",
       "                       [-0.0910, -0.2281,  0.1594,  ..., -0.1018, -0.1739, -0.1451],\n",
       "                       [-0.0726, -0.2028,  0.0729,  ..., -0.1058,  0.0285, -0.0615],\n",
       "                       ...,\n",
       "                       [-0.1395,  0.1824, -0.1913,  ..., -0.1832,  0.1481,  0.1763],\n",
       "                       [ 0.1368,  0.0950, -0.1891,  ..., -0.0754, -0.0695, -0.1764],\n",
       "                       [ 0.2372,  0.0479,  0.1664,  ...,  0.2365,  0.0148,  0.1388]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0418,  0.1918,  0.1563,  ...,  0.0912,  0.1868, -0.0247],\n",
       "                       [-0.0999,  0.0278, -0.0423,  ...,  0.1215,  0.2147,  0.0999],\n",
       "                       [-0.0555,  0.0986, -0.1693,  ..., -0.0998, -0.1027,  0.0289],\n",
       "                       ...,\n",
       "                       [-0.1972,  0.2414, -0.0719,  ..., -0.0549,  0.2496,  0.0558],\n",
       "                       [-0.0127,  0.1047, -0.2091,  ...,  0.0764,  0.1771, -0.1183],\n",
       "                       [ 0.0560,  0.0328,  0.0438,  ...,  0.1732, -0.0879, -0.1904]],\n",
       "              \n",
       "                      [[ 0.1835,  0.0732, -0.1687,  ...,  0.0980,  0.1478, -0.0739],\n",
       "                       [-0.0474,  0.1358,  0.0476,  ...,  0.1170, -0.0297,  0.1360],\n",
       "                       [ 0.1960, -0.0269, -0.0405,  ...,  0.1290,  0.0436, -0.1267],\n",
       "                       ...,\n",
       "                       [ 0.0529, -0.1292,  0.1835,  ...,  0.0310,  0.0610, -0.2188],\n",
       "                       [-0.1276, -0.2385, -0.1735,  ...,  0.0080,  0.1490, -0.0341],\n",
       "                       [-0.1305,  0.0145, -0.1305,  ..., -0.0152,  0.0344,  0.0896]],\n",
       "              \n",
       "                      [[ 0.1743,  0.2301, -0.0759,  ..., -0.2132, -0.0751, -0.0535],\n",
       "                       [ 0.1990,  0.2391,  0.1386,  ...,  0.2347,  0.1753,  0.2140],\n",
       "                       [ 0.0326,  0.2337,  0.1514,  ..., -0.0583, -0.2303, -0.0782],\n",
       "                       ...,\n",
       "                       [ 0.0509, -0.0737, -0.1969,  ..., -0.2417,  0.2241,  0.1580],\n",
       "                       [ 0.1973,  0.0063,  0.1949,  ..., -0.0242, -0.0244,  0.2122],\n",
       "                       [ 0.1628,  0.1052,  0.1490,  ..., -0.0809, -0.0909,  0.2380]]])),\n",
       "             ('embedder_act.layers.2.0.module.W_val',\n",
       "              tensor([[[-0.0115, -0.2208, -0.0535,  ...,  0.2103, -0.0304,  0.1446],\n",
       "                       [-0.0493, -0.1576,  0.1572,  ...,  0.0281, -0.2021,  0.1305],\n",
       "                       [ 0.0629, -0.2249,  0.0078,  ..., -0.2065, -0.1684,  0.0008],\n",
       "                       ...,\n",
       "                       [-0.2469, -0.1365,  0.0441,  ...,  0.1953,  0.0208, -0.0535],\n",
       "                       [-0.0661,  0.0434,  0.1535,  ..., -0.0148, -0.1070,  0.0555],\n",
       "                       [ 0.0009,  0.1167,  0.2164,  ...,  0.1091,  0.0675, -0.1693]],\n",
       "              \n",
       "                      [[ 0.1973, -0.0323, -0.1313,  ...,  0.0743, -0.1082,  0.0554],\n",
       "                       [ 0.0077, -0.1818,  0.1803,  ..., -0.0334, -0.0778,  0.0572],\n",
       "                       [-0.1534, -0.0869,  0.1145,  ..., -0.0368,  0.1339,  0.0406],\n",
       "                       ...,\n",
       "                       [-0.1673,  0.1225,  0.1324,  ..., -0.1758, -0.2478, -0.2047],\n",
       "                       [ 0.1041, -0.1594,  0.1458,  ..., -0.2246, -0.0174, -0.1097],\n",
       "                       [-0.1981,  0.0417,  0.1417,  ...,  0.2092,  0.0515,  0.1539]],\n",
       "              \n",
       "                      [[ 0.0240, -0.1525, -0.1089,  ..., -0.0105,  0.1814,  0.0311],\n",
       "                       [ 0.1613,  0.2179, -0.0690,  ..., -0.0740,  0.1289,  0.0731],\n",
       "                       [ 0.2357,  0.1974, -0.2256,  ...,  0.1660,  0.1958,  0.0385],\n",
       "                       ...,\n",
       "                       [ 0.0577, -0.1499, -0.2418,  ..., -0.1098,  0.0818,  0.0149],\n",
       "                       [-0.0544, -0.1944,  0.1045,  ...,  0.0314,  0.0049,  0.2497],\n",
       "                       [-0.2043,  0.1228,  0.0826,  ..., -0.0797,  0.0898, -0.1846]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.1251,  0.0983,  0.1413,  ...,  0.2398,  0.2397,  0.0592],\n",
       "                       [-0.0993,  0.2189,  0.0781,  ...,  0.0783,  0.0957,  0.1876],\n",
       "                       [-0.0426,  0.2279,  0.0485,  ..., -0.0531,  0.1127,  0.1492],\n",
       "                       ...,\n",
       "                       [-0.1458,  0.1900, -0.0190,  ...,  0.1862,  0.0736, -0.1224],\n",
       "                       [-0.0312,  0.1765, -0.0636,  ...,  0.0438,  0.0204,  0.1961],\n",
       "                       [ 0.1646,  0.2478, -0.2196,  ..., -0.1048, -0.0343,  0.0036]],\n",
       "              \n",
       "                      [[ 0.1750, -0.1094,  0.1220,  ...,  0.1312,  0.2398,  0.1150],\n",
       "                       [ 0.1638,  0.0833, -0.1685,  ...,  0.0396,  0.1715, -0.0831],\n",
       "                       [-0.1364, -0.0341, -0.1312,  ...,  0.2238, -0.2420, -0.0619],\n",
       "                       ...,\n",
       "                       [-0.0548, -0.1610, -0.1036,  ..., -0.1460, -0.1080,  0.0276],\n",
       "                       [-0.1607, -0.1654,  0.1853,  ...,  0.0585, -0.1254, -0.1604],\n",
       "                       [-0.0580, -0.1365,  0.0753,  ..., -0.1705,  0.0238, -0.0034]],\n",
       "              \n",
       "                      [[ 0.1107,  0.0138, -0.2229,  ...,  0.1198, -0.0012, -0.0316],\n",
       "                       [-0.2033,  0.1203,  0.0327,  ...,  0.1387,  0.0646, -0.1467],\n",
       "                       [ 0.0046, -0.2149,  0.0896,  ..., -0.1953, -0.1358,  0.1000],\n",
       "                       ...,\n",
       "                       [ 0.0920, -0.0330,  0.0865,  ..., -0.1065, -0.1276, -0.0721],\n",
       "                       [-0.1202, -0.2361,  0.0981,  ...,  0.1385, -0.2207,  0.0327],\n",
       "                       [ 0.1876, -0.1931, -0.1784,  ...,  0.0972, -0.0774, -0.0367]]])),\n",
       "             ('embedder_act.layers.2.0.module.W_out',\n",
       "              tensor([[[-0.0707, -0.0223,  0.0621,  ..., -0.0224,  0.0770, -0.0184],\n",
       "                       [-0.0405,  0.0776, -0.0347,  ...,  0.0269, -0.0836,  0.0692],\n",
       "                       [-0.0522,  0.0770,  0.0744,  ..., -0.0576, -0.0389,  0.0377],\n",
       "                       ...,\n",
       "                       [ 0.0879,  0.0455,  0.0394,  ...,  0.0863, -0.0246, -0.0635],\n",
       "                       [-0.0395, -0.0032, -0.0307,  ..., -0.0275,  0.0220, -0.0223],\n",
       "                       [ 0.0704,  0.0827,  0.0164,  ..., -0.0277,  0.0799,  0.0364]],\n",
       "              \n",
       "                      [[-0.0257,  0.0582,  0.0057,  ...,  0.0015,  0.0667, -0.0052],\n",
       "                       [ 0.0750,  0.0869,  0.0098,  ..., -0.0087, -0.0379, -0.0033],\n",
       "                       [-0.0515,  0.0116, -0.0498,  ..., -0.0868, -0.0327, -0.0501],\n",
       "                       ...,\n",
       "                       [ 0.0817, -0.0255, -0.0695,  ..., -0.0613, -0.0777,  0.0615],\n",
       "                       [-0.0829, -0.0161,  0.0262,  ...,  0.0131,  0.0226,  0.0024],\n",
       "                       [ 0.0423,  0.0033,  0.0704,  ..., -0.0145, -0.0223,  0.0620]],\n",
       "              \n",
       "                      [[ 0.0404, -0.0020,  0.0295,  ..., -0.0516,  0.0646, -0.0300],\n",
       "                       [ 0.0404,  0.0207, -0.0792,  ..., -0.0080,  0.0803,  0.0815],\n",
       "                       [ 0.0080, -0.0230,  0.0599,  ..., -0.0366, -0.0609,  0.0777],\n",
       "                       ...,\n",
       "                       [ 0.0352,  0.0359, -0.0299,  ...,  0.0087,  0.0445,  0.0340],\n",
       "                       [ 0.0581,  0.0327, -0.0794,  ...,  0.0280, -0.0075, -0.0273],\n",
       "                       [-0.0254,  0.0839,  0.0813,  ...,  0.0678,  0.0646,  0.0057]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0222, -0.0430,  0.0719,  ..., -0.0411,  0.0642,  0.0207],\n",
       "                       [ 0.0191, -0.0204, -0.0360,  ..., -0.0064, -0.0170, -0.0764],\n",
       "                       [ 0.0428, -0.0765, -0.0863,  ...,  0.0372,  0.0112,  0.0819],\n",
       "                       ...,\n",
       "                       [ 0.0760,  0.0038,  0.0034,  ...,  0.0397, -0.0192, -0.0097],\n",
       "                       [ 0.0117, -0.0334,  0.0518,  ...,  0.0632,  0.0616,  0.0599],\n",
       "                       [-0.0453,  0.0039,  0.0841,  ..., -0.0305,  0.0816, -0.0269]],\n",
       "              \n",
       "                      [[ 0.0270,  0.0618, -0.0225,  ..., -0.0584, -0.0767, -0.0479],\n",
       "                       [ 0.0368,  0.0775,  0.0228,  ...,  0.0276,  0.0531,  0.0637],\n",
       "                       [-0.0534,  0.0217, -0.0069,  ..., -0.0594, -0.0260, -0.0659],\n",
       "                       ...,\n",
       "                       [-0.0409, -0.0747, -0.0494,  ..., -0.0696,  0.0588,  0.0268],\n",
       "                       [ 0.0086, -0.0025, -0.0004,  ...,  0.0146,  0.0561, -0.0159],\n",
       "                       [ 0.0095, -0.0377, -0.0879,  ...,  0.0017,  0.0420,  0.0365]],\n",
       "              \n",
       "                      [[-0.0026,  0.0618,  0.0882,  ...,  0.0456,  0.0252,  0.0402],\n",
       "                       [ 0.0182, -0.0322,  0.0616,  ...,  0.0166, -0.0222,  0.0542],\n",
       "                       [-0.0739, -0.0077, -0.0848,  ..., -0.0678, -0.0407,  0.0087],\n",
       "                       ...,\n",
       "                       [-0.0666,  0.0712,  0.0572,  ..., -0.0002,  0.0165,  0.0347],\n",
       "                       [ 0.0440, -0.0276, -0.0687,  ...,  0.0729,  0.0787, -0.0174],\n",
       "                       [-0.0643, -0.0015,  0.0348,  ..., -0.0042,  0.0062,  0.0636]]])),\n",
       "             ('embedder_act.layers.2.1.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder_act.layers.2.1.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder_act.layers.2.1.normalizer.running_mean',\n",
       "              tensor([ 1.2647e-02,  1.4750e-02,  1.9372e-02,  4.4949e-03,  1.4704e-02,\n",
       "                      -3.6738e-02,  1.1385e-02,  1.0470e-02,  2.8689e-03,  2.4194e-02,\n",
       "                      -1.2402e-02,  1.3419e-02,  3.1528e-03,  1.5042e-02, -4.8960e-03,\n",
       "                       1.9105e-02,  1.1643e-03,  5.6945e-03, -1.7038e-02, -3.8766e-03,\n",
       "                      -8.2573e-03,  7.2705e-03, -4.4738e-03, -4.8868e-03,  4.9131e-03,\n",
       "                       1.7162e-02, -3.5375e-03,  8.5882e-03,  6.0294e-03,  1.0198e-02,\n",
       "                      -9.4077e-03, -7.7616e-03,  4.6964e-03,  8.7553e-03, -4.0546e-04,\n",
       "                       1.4230e-02, -4.7546e-04,  1.0369e-02, -1.5925e-02, -1.0923e-03,\n",
       "                      -1.8359e-03,  2.0208e-02,  1.0855e-03,  4.3342e-03,  8.9834e-03,\n",
       "                      -6.1308e-03, -1.2169e-02, -1.7167e-02, -1.6270e-02,  1.4752e-02,\n",
       "                      -1.4993e-02,  1.8232e-03, -5.6907e-04, -3.9325e-03,  8.2924e-03,\n",
       "                       1.3304e-02, -6.6551e-03,  2.6997e-03, -7.9377e-04, -1.6265e-03,\n",
       "                      -1.7542e-03,  2.5286e-03, -2.5761e-03,  5.2123e-03,  8.4457e-03,\n",
       "                      -1.1731e-02, -7.9252e-03,  1.2295e-02, -1.2447e-02,  1.2848e-02,\n",
       "                       5.1405e-03, -1.7141e-02,  5.6515e-03,  1.5146e-02, -2.9385e-03,\n",
       "                      -4.1508e-03,  2.6047e-03,  2.1930e-02, -1.1828e-02, -1.3187e-02,\n",
       "                       2.1322e-02,  1.7535e-03, -1.0666e-02, -8.9000e-03, -2.0225e-02,\n",
       "                      -6.0555e-03, -3.1622e-02,  2.6963e-03,  1.0024e-02, -2.6275e-03,\n",
       "                       5.4055e-03, -1.1983e-02, -6.1579e-03,  1.3901e-02, -1.1676e-02,\n",
       "                      -3.2508e-03, -1.2431e-02,  8.2506e-03,  6.0461e-03, -2.8635e-02,\n",
       "                      -9.7660e-03,  2.4539e-03,  5.9726e-04, -1.8496e-02, -1.3693e-02,\n",
       "                       3.0371e-03,  3.4390e-03,  2.4272e-03, -1.0759e-02, -1.5948e-02,\n",
       "                       8.1261e-03, -8.3906e-03,  3.5618e-03,  1.5889e-02,  7.9615e-03,\n",
       "                       1.2985e-04,  1.1651e-02,  5.5061e-03, -1.1422e-02,  5.2279e-03,\n",
       "                       1.1564e-02,  3.8073e-03, -2.7396e-03, -4.4632e-06,  8.4672e-03,\n",
       "                       1.0929e-02,  2.0788e-02, -7.9327e-04])),\n",
       "             ('embedder_act.layers.2.1.normalizer.running_var',\n",
       "              tensor([1.0533, 1.1313, 1.0068, 1.0066, 1.0907, 1.1072, 1.1228, 1.1001, 0.9725,\n",
       "                      0.9950, 1.0600, 1.0627, 1.1056, 0.9122, 1.0916, 1.0902, 1.1125, 1.1802,\n",
       "                      0.9877, 0.9550, 1.0946, 0.9804, 0.9614, 0.9370, 1.1678, 1.0182, 1.0004,\n",
       "                      1.2922, 1.1650, 1.0463, 1.0923, 1.0902, 1.0084, 1.1122, 1.0508, 1.0840,\n",
       "                      0.9474, 1.0520, 0.9921, 0.9536, 0.9715, 1.0397, 1.0359, 0.9515, 1.0655,\n",
       "                      1.2080, 1.0945, 1.0727, 1.0764, 0.9785, 0.9744, 0.9351, 1.1185, 1.0104,\n",
       "                      0.9955, 1.0739, 1.0572, 1.0606, 0.9538, 1.4309, 0.9420, 1.1516, 1.0549,\n",
       "                      1.0356, 1.0416, 1.0634, 0.9914, 1.0672, 1.0260, 1.0441, 1.0579, 1.0398,\n",
       "                      1.0364, 1.1257, 1.0902, 1.0216, 1.0593, 1.0589, 1.0842, 1.1391, 1.0628,\n",
       "                      1.0767, 0.9530, 0.9567, 1.0143, 1.1279, 0.9911, 0.9892, 1.0104, 1.0768,\n",
       "                      1.2298, 0.9753, 1.0922, 1.2312, 1.0476, 1.1389, 1.0095, 0.9955, 1.0288,\n",
       "                      1.0493, 1.0119, 1.0942, 0.9709, 0.9800, 1.0689, 1.1065, 1.1111, 1.0176,\n",
       "                      1.0393, 1.0719, 1.1870, 1.2002, 0.9568, 1.1275, 0.9638, 1.0548, 1.1374,\n",
       "                      0.9813, 1.0255, 1.1072, 0.9444, 1.0298, 0.9806, 0.9861, 1.0765, 1.0286,\n",
       "                      1.0575, 1.0487])),\n",
       "             ('embedder_act.layers.2.1.normalizer.num_batches_tracked',\n",
       "              tensor(1)),\n",
       "             ('embedder_act.layers.2.2.module.0.weight',\n",
       "              tensor([[-0.0237,  0.0595, -0.0037,  ...,  0.0825, -0.0359, -0.0068],\n",
       "                      [ 0.0791, -0.0264,  0.0396,  ...,  0.0480, -0.0847, -0.0536],\n",
       "                      [ 0.0042, -0.0657, -0.0091,  ..., -0.0500, -0.0089, -0.0268],\n",
       "                      ...,\n",
       "                      [ 0.0032,  0.0504,  0.0609,  ...,  0.0710,  0.0403,  0.0307],\n",
       "                      [ 0.0472,  0.0775, -0.0538,  ...,  0.0639,  0.0152,  0.0814],\n",
       "                      [-0.0659,  0.0237, -0.0655,  ...,  0.0838, -0.0371, -0.0255]])),\n",
       "             ('embedder_act.layers.2.2.module.0.bias',\n",
       "              tensor([ 0.0159, -0.0183,  0.0068, -0.0044, -0.0703, -0.0600, -0.0725, -0.0111,\n",
       "                       0.0399,  0.0638, -0.0693,  0.0007, -0.0584,  0.0216, -0.0725,  0.0634,\n",
       "                       0.0513, -0.0449, -0.0107, -0.0113, -0.0322,  0.0136,  0.0333, -0.0359,\n",
       "                       0.0199,  0.0195, -0.0215, -0.0416,  0.0236,  0.0199, -0.0076,  0.0016,\n",
       "                      -0.0108, -0.0437,  0.0292, -0.0850, -0.0536,  0.0235,  0.0321, -0.0540,\n",
       "                      -0.0768,  0.0030,  0.0368,  0.0358,  0.0102, -0.0839, -0.0847, -0.0240,\n",
       "                      -0.0244,  0.0678,  0.0161,  0.0258, -0.0565, -0.0129,  0.0777, -0.0489,\n",
       "                       0.0788, -0.0094,  0.0485, -0.0856,  0.0741,  0.0616,  0.0495,  0.0545,\n",
       "                       0.0325,  0.0103,  0.0877, -0.0592, -0.0245,  0.0074, -0.0723,  0.0056,\n",
       "                       0.0420, -0.0599, -0.0325, -0.0481,  0.0223,  0.0701, -0.0633,  0.0098,\n",
       "                      -0.0356, -0.0754,  0.0308,  0.0009, -0.0638,  0.0189, -0.0850,  0.0638,\n",
       "                       0.0636, -0.0588, -0.0318,  0.0425,  0.0683,  0.0171, -0.0359,  0.0097,\n",
       "                      -0.0567, -0.0741, -0.0050, -0.0368,  0.0573, -0.0094, -0.0662, -0.0201,\n",
       "                      -0.0251, -0.0544,  0.0434,  0.0133, -0.0699, -0.0620, -0.0821, -0.0419,\n",
       "                      -0.0337, -0.0496,  0.0835,  0.0403,  0.0092, -0.0231,  0.0726, -0.0371,\n",
       "                      -0.0646,  0.0001,  0.0780,  0.0468,  0.0067,  0.0573, -0.0783, -0.0557,\n",
       "                       0.0801,  0.0167,  0.0381, -0.0761, -0.0511, -0.0166, -0.0771,  0.0044,\n",
       "                       0.0315, -0.0258,  0.0503,  0.0197, -0.0433,  0.0464, -0.0006, -0.0307,\n",
       "                       0.0761, -0.0287,  0.0752, -0.0484, -0.0019, -0.0308,  0.0390,  0.0020,\n",
       "                      -0.0633,  0.0870, -0.0365, -0.0388,  0.0143,  0.0091, -0.0008, -0.0777,\n",
       "                      -0.0004, -0.0299, -0.0622,  0.0293, -0.0847, -0.0638, -0.0397,  0.0439,\n",
       "                      -0.0701, -0.0303,  0.0652,  0.0568, -0.0319, -0.0561,  0.0493, -0.0058,\n",
       "                      -0.0653,  0.0604, -0.0026,  0.0446, -0.0603,  0.0585, -0.0322,  0.0224,\n",
       "                       0.0466,  0.0317,  0.0204, -0.0066, -0.0006,  0.0153,  0.0769,  0.0067,\n",
       "                      -0.0640,  0.0035, -0.0391,  0.0690, -0.0031,  0.0380,  0.0869,  0.0130,\n",
       "                      -0.0774, -0.0714, -0.0090, -0.0768,  0.0789,  0.0809, -0.0712,  0.0702,\n",
       "                       0.0651, -0.0519, -0.0540, -0.0802, -0.0322, -0.0002, -0.0361,  0.0432,\n",
       "                      -0.0686,  0.0254, -0.0013,  0.0106, -0.0054,  0.0353, -0.0261,  0.0399,\n",
       "                      -0.0473, -0.0618,  0.0472,  0.0799, -0.0469,  0.0498, -0.0577,  0.0402,\n",
       "                       0.0775, -0.0331, -0.0853,  0.0226,  0.0861,  0.0394, -0.0852,  0.0500,\n",
       "                      -0.0271, -0.0697, -0.0596, -0.0252, -0.0797,  0.0135, -0.0183, -0.0644,\n",
       "                       0.0177, -0.0820, -0.0688,  0.0556,  0.0683, -0.0058,  0.0110, -0.0103,\n",
       "                       0.0881,  0.0032, -0.0668,  0.0291, -0.0323, -0.0144, -0.0115, -0.0282,\n",
       "                      -0.0057, -0.0737,  0.0454, -0.0567,  0.0521, -0.0214, -0.0223, -0.0233,\n",
       "                      -0.0695, -0.0284,  0.0653, -0.0721, -0.0150,  0.0110,  0.0806,  0.0496,\n",
       "                       0.0115,  0.0852,  0.0096,  0.0303,  0.0478, -0.0740,  0.0058, -0.0361,\n",
       "                       0.0428, -0.0380,  0.0664,  0.0884,  0.0149,  0.0001,  0.0047,  0.0582,\n",
       "                      -0.0503, -0.0487,  0.0339,  0.0491,  0.0082, -0.0861,  0.0833, -0.0161,\n",
       "                      -0.0074, -0.0644,  0.0378, -0.0102,  0.0596, -0.0661, -0.0169,  0.0626,\n",
       "                       0.0419, -0.0273, -0.0023, -0.0725, -0.0783, -0.0790, -0.0131, -0.0253,\n",
       "                      -0.0542,  0.0170, -0.0043,  0.0674, -0.0454,  0.0608, -0.0342,  0.0320,\n",
       "                       0.0655, -0.0030,  0.0764, -0.0409, -0.0008, -0.0165, -0.0261,  0.0619,\n",
       "                      -0.0025,  0.0773, -0.0731,  0.0754,  0.0324,  0.0069,  0.0313, -0.0021,\n",
       "                       0.0503,  0.0581,  0.0848,  0.0454, -0.0488, -0.0622, -0.0672,  0.0143,\n",
       "                      -0.0812, -0.0282, -0.0344,  0.0530,  0.0068, -0.0252,  0.0746, -0.0394,\n",
       "                       0.0515, -0.0732,  0.0352, -0.0103,  0.0068,  0.0358, -0.0051,  0.0164,\n",
       "                      -0.0028, -0.0860, -0.0011,  0.0138, -0.0184, -0.0167, -0.0042, -0.0426,\n",
       "                       0.0536,  0.0618, -0.0593, -0.0001,  0.0810, -0.0125,  0.0030, -0.0287,\n",
       "                      -0.0276, -0.0212,  0.0515,  0.0270,  0.0182,  0.0023,  0.0829,  0.0374,\n",
       "                      -0.0234,  0.0749, -0.0640,  0.0856,  0.0812,  0.0101,  0.0552, -0.0357,\n",
       "                      -0.0301, -0.0301, -0.0226,  0.0135,  0.0662,  0.0408,  0.0791,  0.0644,\n",
       "                       0.0288,  0.0721, -0.0803, -0.0737, -0.0828, -0.0489, -0.0508, -0.0441,\n",
       "                       0.0816, -0.0220,  0.0856,  0.0525, -0.0415,  0.0263, -0.0472,  0.0220,\n",
       "                      -0.0332,  0.0229,  0.0713, -0.0769,  0.0124,  0.0326, -0.0593,  0.0835,\n",
       "                       0.0068, -0.0122,  0.0838, -0.0638, -0.0015,  0.0550,  0.0010,  0.0073,\n",
       "                      -0.0472, -0.0515,  0.0385,  0.0808,  0.0486,  0.0300,  0.0822,  0.0042,\n",
       "                      -0.0822,  0.0058,  0.0374,  0.0845, -0.0520,  0.0327,  0.0447, -0.0650,\n",
       "                       0.0114, -0.0807,  0.0354, -0.0034,  0.0337,  0.0613,  0.0745,  0.0522,\n",
       "                      -0.0306,  0.0367, -0.0173,  0.0719, -0.0039,  0.0845, -0.0255,  0.0706,\n",
       "                      -0.0417,  0.0790,  0.0532, -0.0104,  0.0070,  0.0154,  0.0454,  0.0697,\n",
       "                      -0.0353, -0.0188,  0.0698,  0.0749, -0.0434, -0.0212,  0.0846,  0.0149,\n",
       "                      -0.0536,  0.0194, -0.0619,  0.0138, -0.0123,  0.0477,  0.0737,  0.0082,\n",
       "                       0.0180, -0.0479, -0.0529,  0.0575, -0.0845,  0.0461, -0.0013,  0.0379,\n",
       "                      -0.0555, -0.0269, -0.0276,  0.0526, -0.0582,  0.0181,  0.0381,  0.0638])),\n",
       "             ('embedder_act.layers.2.2.module.2.weight',\n",
       "              tensor([[ 0.0085, -0.0403, -0.0192,  ...,  0.0206, -0.0015,  0.0151],\n",
       "                      [-0.0042,  0.0305,  0.0343,  ...,  0.0155,  0.0034,  0.0117],\n",
       "                      [-0.0311, -0.0036,  0.0372,  ...,  0.0101,  0.0382,  0.0163],\n",
       "                      ...,\n",
       "                      [-0.0013,  0.0037, -0.0247,  ..., -0.0074, -0.0401,  0.0323],\n",
       "                      [-0.0260, -0.0388,  0.0073,  ...,  0.0078,  0.0243, -0.0127],\n",
       "                      [-0.0174, -0.0006,  0.0372,  ...,  0.0313, -0.0402, -0.0276]])),\n",
       "             ('embedder_act.layers.2.2.module.2.bias',\n",
       "              tensor([-0.0114,  0.0271, -0.0421, -0.0238, -0.0013,  0.0294,  0.0426, -0.0215,\n",
       "                      -0.0093,  0.0128, -0.0168,  0.0231, -0.0194, -0.0396, -0.0420,  0.0389,\n",
       "                       0.0334,  0.0344,  0.0087,  0.0165, -0.0343,  0.0169,  0.0104,  0.0047,\n",
       "                      -0.0196, -0.0118, -0.0079, -0.0117,  0.0371, -0.0343, -0.0133, -0.0036,\n",
       "                       0.0369, -0.0118, -0.0102,  0.0040,  0.0390,  0.0243, -0.0274, -0.0028,\n",
       "                      -0.0398,  0.0403,  0.0343, -0.0113,  0.0234, -0.0170, -0.0271,  0.0206,\n",
       "                       0.0318,  0.0322,  0.0092,  0.0408,  0.0072, -0.0425,  0.0350, -0.0005,\n",
       "                       0.0038, -0.0291,  0.0269, -0.0191, -0.0181,  0.0271,  0.0020, -0.0105,\n",
       "                      -0.0091,  0.0168,  0.0101, -0.0086,  0.0190, -0.0250,  0.0368, -0.0401,\n",
       "                      -0.0321,  0.0196,  0.0294, -0.0007,  0.0339, -0.0124, -0.0436, -0.0010,\n",
       "                      -0.0209, -0.0319, -0.0357, -0.0428, -0.0441, -0.0346, -0.0315,  0.0287,\n",
       "                      -0.0031, -0.0081, -0.0308, -0.0114,  0.0048,  0.0360, -0.0101,  0.0037,\n",
       "                      -0.0117,  0.0194,  0.0262,  0.0017,  0.0091,  0.0394,  0.0332, -0.0101,\n",
       "                      -0.0374, -0.0320,  0.0335,  0.0316,  0.0124, -0.0012,  0.0344,  0.0314,\n",
       "                       0.0101, -0.0123,  0.0109,  0.0168, -0.0080,  0.0416,  0.0298,  0.0307,\n",
       "                      -0.0134,  0.0086, -0.0108, -0.0371,  0.0078,  0.0101,  0.0367, -0.0156])),\n",
       "             ('embedder_act.layers.2.3.normalizer.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('embedder_act.layers.2.3.normalizer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('embedder_act.layers.2.3.normalizer.running_mean',\n",
       "              tensor([-0.0063,  0.0165, -0.0059, -0.0155, -0.0041,  0.0025,  0.0049, -0.0166,\n",
       "                       0.0052,  0.0149, -0.0129, -0.0022,  0.0245, -0.0183, -0.0064,  0.0167,\n",
       "                       0.0209,  0.0130,  0.0314, -0.0244,  0.0117,  0.0217, -0.0096,  0.0086,\n",
       "                      -0.0027, -0.0007, -0.0103, -0.0098,  0.0047, -0.0190,  0.0063,  0.0140,\n",
       "                       0.0211,  0.0067, -0.0126,  0.0115, -0.0241, -0.0086, -0.0116, -0.0199,\n",
       "                       0.0054, -0.0110,  0.0094,  0.0010,  0.0037, -0.0101,  0.0070, -0.0025,\n",
       "                       0.0078,  0.0023,  0.0228,  0.0006, -0.0010, -0.0052, -0.0193, -0.0072,\n",
       "                       0.0252, -0.0029,  0.0204,  0.0181, -0.0091,  0.0020, -0.0155, -0.0027,\n",
       "                       0.0025, -0.0166, -0.0052, -0.0166,  0.0187, -0.0211,  0.0137, -0.0389,\n",
       "                       0.0042,  0.0038,  0.0070,  0.0134,  0.0033, -0.0170,  0.0061, -0.0090,\n",
       "                      -0.0165, -0.0139, -0.0106, -0.0145,  0.0060, -0.0150,  0.0147,  0.0035,\n",
       "                       0.0053, -0.0045, -0.0064,  0.0008,  0.0181, -0.0161, -0.0112, -0.0169,\n",
       "                      -0.0084,  0.0069, -0.0349,  0.0009, -0.0126, -0.0014,  0.0090, -0.0082,\n",
       "                      -0.0171,  0.0129,  0.0128,  0.0260,  0.0372, -0.0005,  0.0097, -0.0303,\n",
       "                       0.0114, -0.0120,  0.0063, -0.0152,  0.0039,  0.0022, -0.0086, -0.0004,\n",
       "                       0.0191, -0.0130,  0.0049, -0.0233,  0.0053, -0.0099, -0.0210,  0.0124])),\n",
       "             ('embedder_act.layers.2.3.normalizer.running_var',\n",
       "              tensor([0.9954, 1.0322, 1.0104, 1.0064, 0.9836, 1.0048, 1.0069, 0.9875, 0.9787,\n",
       "                      0.9978, 0.9902, 0.9652, 1.0086, 1.0029, 1.0157, 0.9969, 0.9994, 1.0062,\n",
       "                      1.0036, 1.0138, 1.0198, 1.0030, 0.9859, 1.0132, 1.0165, 1.0113, 1.0187,\n",
       "                      1.0399, 1.0187, 0.9999, 1.0132, 1.0063, 1.0349, 0.9913, 1.0007, 0.9924,\n",
       "                      1.0436, 1.0096, 1.0043, 0.9844, 0.9979, 0.9846, 1.0058, 0.9993, 1.0109,\n",
       "                      1.0083, 1.0032, 0.9819, 1.0075, 0.9999, 1.0033, 1.0174, 0.9720, 1.0460,\n",
       "                      1.0047, 1.0212, 0.9949, 1.0057, 1.0122, 1.0189, 1.0137, 1.0044, 0.9894,\n",
       "                      1.0127, 0.9685, 1.0126, 0.9969, 1.0097, 0.9860, 0.9788, 1.0054, 1.0219,\n",
       "                      1.0151, 0.9897, 1.0014, 1.0022, 0.9654, 1.0190, 1.0170, 0.9888, 1.0356,\n",
       "                      0.9941, 1.0057, 0.9973, 1.0044, 1.0062, 0.9933, 1.0225, 0.9983, 1.0034,\n",
       "                      1.0060, 1.0017, 1.0085, 1.0151, 0.9868, 1.0036, 0.9894, 1.0227, 1.0091,\n",
       "                      1.0209, 1.0195, 0.9968, 0.9925, 1.0208, 1.0094, 1.0108, 1.0386, 0.9865,\n",
       "                      1.0478, 0.9925, 1.0041, 1.0569, 0.9939, 1.0153, 1.0411, 1.0184, 1.0448,\n",
       "                      1.0038, 1.0280, 1.0516, 0.9889, 1.0262, 1.0330, 0.9864, 1.0072, 1.0273,\n",
       "                      1.0068, 1.0017])),\n",
       "             ('embedder_act.layers.2.3.normalizer.num_batches_tracked',\n",
       "              tensor(1)),\n",
       "             ('project_node_embeddings.weight',\n",
       "              tensor([[ 0.0248,  0.0027,  0.0381,  ...,  0.0396, -0.0514,  0.0529],\n",
       "                      [-0.0406,  0.0330,  0.0324,  ...,  0.0144, -0.0161,  0.0876],\n",
       "                      [ 0.0346,  0.0470, -0.0043,  ..., -0.0296,  0.0030,  0.0031],\n",
       "                      ...,\n",
       "                      [ 0.0871, -0.0835, -0.0758,  ...,  0.0173,  0.0321,  0.0129],\n",
       "                      [-0.0312,  0.0217, -0.0079,  ...,  0.0334, -0.0325,  0.0731],\n",
       "                      [-0.0509,  0.0327, -0.0023,  ...,  0.0277,  0.0034, -0.0504]])),\n",
       "             ('project_fixed_context.weight',\n",
       "              tensor([[ 0.0066,  0.0882,  0.0502,  ..., -0.0511, -0.0801,  0.0311],\n",
       "                      [-0.0367, -0.0576, -0.0446,  ..., -0.0310, -0.0776,  0.0416],\n",
       "                      [-0.0801,  0.0795, -0.0449,  ..., -0.0848, -0.0205, -0.0509],\n",
       "                      ...,\n",
       "                      [-0.0287,  0.0384, -0.0535,  ...,  0.0158,  0.0219, -0.0061],\n",
       "                      [-0.0803, -0.0163, -0.0680,  ...,  0.0599, -0.0264,  0.0129],\n",
       "                      [-0.0038, -0.0649,  0.0376,  ..., -0.0867,  0.0618,  0.0564]])),\n",
       "             ('project_step_context.weight',\n",
       "              tensor([[ 0.0208, -0.0071,  0.0452,  ..., -0.0182,  0.0350,  0.0355],\n",
       "                      [ 0.0277,  0.0559,  0.0335,  ...,  0.0497,  0.0268,  0.0218],\n",
       "                      [-0.0448,  0.0193, -0.0262,  ...,  0.0065, -0.0554, -0.0045],\n",
       "                      ...,\n",
       "                      [ 0.0360,  0.0381,  0.0553,  ...,  0.0003, -0.0199,  0.0517],\n",
       "                      [ 0.0565,  0.0203, -0.0602,  ...,  0.0186, -0.0481,  0.0073],\n",
       "                      [ 0.0028,  0.0094, -0.0102,  ..., -0.0183,  0.0388,  0.0036]])),\n",
       "             ('project_out.weight',\n",
       "              tensor([[-0.0693,  0.0584, -0.0229,  ..., -0.0278, -0.0009, -0.0364],\n",
       "                      [-0.0754, -0.0298,  0.0447,  ...,  0.0554, -0.0747,  0.0235],\n",
       "                      [ 0.0581, -0.0306,  0.0525,  ...,  0.0785, -0.0799, -0.0569],\n",
       "                      ...,\n",
       "                      [ 0.0344,  0.0727, -0.0651,  ...,  0.0619, -0.0035,  0.0347],\n",
       "                      [-0.0878,  0.0352, -0.0081,  ..., -0.0076, -0.0478, -0.0687],\n",
       "                      [ 0.0796, -0.0247,  0.0867,  ..., -0.0393, -0.0146, -0.0738]])),\n",
       "             ('discriminator.0.weight',\n",
       "              tensor([[ 0.0166,  0.0139, -0.0026,  ..., -0.0177, -0.0018,  0.0137],\n",
       "                      [ 0.0006,  0.0091, -0.0061,  ..., -0.0073, -0.0067,  0.0088],\n",
       "                      [-0.0178, -0.0171, -0.0190,  ..., -0.0044,  0.0077, -0.0102],\n",
       "                      ...,\n",
       "                      [ 0.0136,  0.0041,  0.0141,  ..., -0.0114,  0.0114, -0.0058],\n",
       "                      [-0.0042,  0.0174,  0.0119,  ...,  0.0149, -0.0085,  0.0172],\n",
       "                      [ 0.0080,  0.0149,  0.0044,  ...,  0.0071,  0.0061,  0.0028]])),\n",
       "             ('discriminator.0.bias',\n",
       "              tensor([ 0.0191, -0.0040,  0.0019,  ..., -0.0189,  0.0070, -0.0041])),\n",
       "             ('discriminator.2.weight',\n",
       "              tensor([[-0.0162,  0.0148, -0.0161,  ..., -0.0175, -0.0020, -0.0121]])),\n",
       "             ('discriminator.2.bias', tensor([0.0123]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd370d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement copy (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for copy\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -U copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42d727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
